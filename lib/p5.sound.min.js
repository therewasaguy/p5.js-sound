/*! p5.sound.min.js v0.3.9 2018-09-24 */
/**
 *  p5.sound extends p5 with <a href="http://caniuse.com/audio-api"
 *  target="_blank">Web Audio</a> functionality including audio input,
 *  playback, analysis and synthesis.
 *  <br/><br/>
 *  <a href="#/p5.SoundFile"><b>p5.SoundFile</b></a>: Load and play sound files.<br/>
 *  <a href="#/p5.Amplitude"><b>p5.Amplitude</b></a>: Get the current volume of a sound.<br/>
 *  <a href="#/p5.AudioIn"><b>p5.AudioIn</b></a>: Get sound from an input source, typically
 *    a computer microphone.<br/>
 *  <a href="#/p5.FFT"><b>p5.FFT</b></a>: Analyze the frequency of sound. Returns
 *    results from the frequency spectrum or time domain (waveform).<br/>
 *  <a href="#/p5.Oscillator"><b>p5.Oscillator</b></a>: Generate Sine,
 *    Triangle, Square and Sawtooth waveforms. Base class of
 *    <a href="#/p5.Noise">p5.Noise</a> and <a href="#/p5.Pulse">p5.Pulse</a>.
 *    <br/>
 *  <a href="#/p5.Envelope"><b>p5.Envelope</b></a>: An Envelope is a series
 *    of fades over time. Often used to control an object's
 *    output gain level as an "ADSR Envelope" (Attack, Decay,
 *    Sustain, Release). Can also modulate other parameters.<br/>
 *  <a href="#/p5.Delay"><b>p5.Delay</b></a>: A delay effect with
 *    parameters for feedback, delayTime, and lowpass filter.<br/>
 *  <a href="#/p5.Filter"><b>p5.Filter</b></a>: Filter the frequency range of a
 *    sound.
 *  <br/>
 *  <a href="#/p5.Reverb"><b>p5.Reverb</b></a>: Add reverb to a sound by specifying
 *    duration and decay. <br/>
 *  <b><a href="#/p5.Convolver">p5.Convolver</a>:</b> Extends
 *  <a href="#/p5.Reverb">p5.Reverb</a> to simulate the sound of real
 *    physical spaces through convolution.<br/>
 *  <b><a href="#/p5.SoundRecorder">p5.SoundRecorder</a></b>: Record sound for playback
 *    / save the .wav file.
 *  <b><a href="#/p5.Phrase">p5.Phrase</a></b>, <b><a href="#/p5.Part">p5.Part</a></b> and
 *  <b><a href="#/p5.Score">p5.Score</a></b>: Compose musical sequences.
 *  <br/><br/>
 *  p5.sound is on <a href="https://github.com/therewasaguy/p5.sound/">GitHub</a>.
 *  Download the latest version
 *  <a href="https://github.com/therewasaguy/p5.sound/blob/master/lib/p5.sound.js">here</a>.
 *
 *  @module p5.sound
 *  @submodule p5.sound
 *  @for p5.sound
 *  @main
 */

/**
 *  p5.sound 
 *  https://p5js.org/reference/#/libraries/p5.sound
 *
 *  From the Processing Foundation and contributors
 *  https://github.com/processing/p5.js-sound/graphs/contributors
 *
 *  MIT License (MIT)
 *  https://github.com/processing/p5.js-sound/blob/master/LICENSE
 *
 *  Some of the many audio libraries & resources that inspire p5.sound:
 *   - TONE.js (c) Yotam Mann. Licensed under The MIT License (MIT). https://github.com/TONEnoTONE/Tone.js
 *   - buzz.js (c) Jay Salvat. Licensed under The MIT License (MIT). http://buzz.jaysalvat.com/
 *   - Boris Smus Web Audio API book, 2013. Licensed under the Apache License http://www.apache.org/licenses/LICENSE-2.0
 *   - wavesurfer.js https://github.com/katspaugh/wavesurfer.js
 *   - Web Audio Components by Jordan Santell https://github.com/web-audio-components
 *   - Wilm Thoben's Sound library for Processing https://github.com/processing/processing/tree/master/java/libraries/sound
 *
 *   Web Audio API: http://w3.org/TR/webaudio/
 */

(function (root, factory) {
  if (typeof define === 'function' && define.amd)
    define('p5.sound', ['p5'], function (p5) { (factory(p5));});
  else if (typeof exports === 'object')
    factory(require('../p5'));
  else
    factory(root['p5']);
}(this, function (p5) {
  
var shims;
'use strict';
shims = function () {
    (function () {
        function fixSetTarget(param) {
            if (!param)
                return;
            if (!param.setTargetAtTime)
                param.setTargetAtTime = param.setTargetValueAtTime;
        }
        if (window.hasOwnProperty('webkitAudioContext') && !window.hasOwnProperty('AudioContext')) {
            window.AudioContext = window.webkitAudioContext;
            if (typeof AudioContext.prototype.createGain !== 'function')
                AudioContext.prototype.createGain = AudioContext.prototype.createGainNode;
            if (typeof AudioContext.prototype.createDelay !== 'function')
                AudioContext.prototype.createDelay = AudioContext.prototype.createDelayNode;
            if (typeof AudioContext.prototype.createScriptProcessor !== 'function')
                AudioContext.prototype.createScriptProcessor = AudioContext.prototype.createJavaScriptNode;
            if (typeof AudioContext.prototype.createPeriodicWave !== 'function')
                AudioContext.prototype.createPeriodicWave = AudioContext.prototype.createWaveTable;
            AudioContext.prototype.internal_createGain = AudioContext.prototype.createGain;
            AudioContext.prototype.createGain = function () {
                var node = this.internal_createGain();
                fixSetTarget(node.gain);
                return node;
            };
            AudioContext.prototype.internal_createDelay = AudioContext.prototype.createDelay;
            AudioContext.prototype.createDelay = function (maxDelayTime) {
                var node = maxDelayTime ? this.internal_createDelay(maxDelayTime) : this.internal_createDelay();
                fixSetTarget(node.delayTime);
                return node;
            };
            AudioContext.prototype.internal_createBufferSource = AudioContext.prototype.createBufferSource;
            AudioContext.prototype.createBufferSource = function () {
                var node = this.internal_createBufferSource();
                if (!node.start) {
                    node.start = function (when, offset, duration) {
                        if (offset || duration)
                            this.noteGrainOn(when || 0, offset, duration);
                        else
                            this.noteOn(when || 0);
                    };
                } else {
                    node.internal_start = node.start;
                    node.start = function (when, offset, duration) {
                        if (typeof duration !== 'undefined')
                            node.internal_start(when || 0, offset, duration);
                        else
                            node.internal_start(when || 0, offset || 0);
                    };
                }
                if (!node.stop) {
                    node.stop = function (when) {
                        this.noteOff(when || 0);
                    };
                } else {
                    node.internal_stop = node.stop;
                    node.stop = function (when) {
                        node.internal_stop(when || 0);
                    };
                }
                fixSetTarget(node.playbackRate);
                return node;
            };
            AudioContext.prototype.internal_createDynamicsCompressor = AudioContext.prototype.createDynamicsCompressor;
            AudioContext.prototype.createDynamicsCompressor = function () {
                var node = this.internal_createDynamicsCompressor();
                fixSetTarget(node.threshold);
                fixSetTarget(node.knee);
                fixSetTarget(node.ratio);
                fixSetTarget(node.reduction);
                fixSetTarget(node.attack);
                fixSetTarget(node.release);
                return node;
            };
            AudioContext.prototype.internal_createBiquadFilter = AudioContext.prototype.createBiquadFilter;
            AudioContext.prototype.createBiquadFilter = function () {
                var node = this.internal_createBiquadFilter();
                fixSetTarget(node.frequency);
                fixSetTarget(node.detune);
                fixSetTarget(node.Q);
                fixSetTarget(node.gain);
                return node;
            };
            if (typeof AudioContext.prototype.createOscillator !== 'function') {
                AudioContext.prototype.internal_createOscillator = AudioContext.prototype.createOscillator;
                AudioContext.prototype.createOscillator = function () {
                    var node = this.internal_createOscillator();
                    if (!node.start) {
                        node.start = function (when) {
                            this.noteOn(when || 0);
                        };
                    } else {
                        node.internal_start = node.start;
                        node.start = function (when) {
                            node.internal_start(when || 0);
                        };
                    }
                    if (!node.stop) {
                        node.stop = function (when) {
                            this.noteOff(when || 0);
                        };
                    } else {
                        node.internal_stop = node.stop;
                        node.stop = function (when) {
                            node.internal_stop(when || 0);
                        };
                    }
                    if (!node.setPeriodicWave)
                        node.setPeriodicWave = node.setWaveTable;
                    fixSetTarget(node.frequency);
                    fixSetTarget(node.detune);
                    return node;
                };
            }
        }
        if (window.hasOwnProperty('webkitOfflineAudioContext') && !window.hasOwnProperty('OfflineAudioContext')) {
            window.OfflineAudioContext = window.webkitOfflineAudioContext;
        }
    }(window));
    navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia || navigator.msGetUserMedia;
    var el = document.createElement('audio');
    p5.prototype.isSupported = function () {
        return !!el.canPlayType;
    };
    var isOGGSupported = function () {
        return !!el.canPlayType && el.canPlayType('audio/ogg; codecs="vorbis"');
    };
    var isMP3Supported = function () {
        return !!el.canPlayType && el.canPlayType('audio/mpeg;');
    };
    var isWAVSupported = function () {
        return !!el.canPlayType && el.canPlayType('audio/wav; codecs="1"');
    };
    var isAACSupported = function () {
        return !!el.canPlayType && (el.canPlayType('audio/x-m4a;') || el.canPlayType('audio/aac;'));
    };
    var isAIFSupported = function () {
        return !!el.canPlayType && el.canPlayType('audio/x-aiff;');
    };
    p5.prototype.isFileSupported = function (extension) {
        switch (extension.toLowerCase()) {
        case 'mp3':
            return isMP3Supported();
        case 'wav':
            return isWAVSupported();
        case 'ogg':
            return isOGGSupported();
        case 'aac':
        case 'm4a':
        case 'mp4':
            return isAACSupported();
        case 'aif':
        case 'aiff':
            return isAIFSupported();
        default:
            return false;
        }
    };
}();
!function(t,e){"object"==typeof exports&&"object"==typeof module?module.exports=e():"function"==typeof define&&define.amd?define('unmuteButton',[],e):"object"==typeof exports?exports.UnmuteButton=e():t.UnmuteButton=e()}(window,function(){return function(t){var e={};function n(i){if(e[i])return e[i].exports;var o=e[i]={i:i,l:!1,exports:{}};return t[i].call(o.exports,o,o.exports,n),o.l=!0,o.exports}return n.m=t,n.c=e,n.d=function(t,e,i){n.o(t,e)||Object.defineProperty(t,e,{configurable:!1,enumerable:!0,get:i})},n.r=function(t){Object.defineProperty(t,"__esModule",{value:!0})},n.n=function(t){var e=t&&t.__esModule?function(){return t.default}:function(){return t};return n.d(e,"a",e),e},n.o=function(t,e){return Object.prototype.hasOwnProperty.call(t,e)},n.p="",n(n.s=15)}([function(t,e,n){(function(i){var o,r;
/**
 *  Tone.js
 *  @author Yotam Mann
 *  @license http://opensource.org/licenses/MIT MIT License
 *  @copyright 2014-2018 Yotam Mann
 */o=[n(32)],void 0===(r=function(t){"use strict";var e=function(){if(!(this instanceof e))throw new Error("constructor needs to be called with the 'new' keyword")};return e.prototype.toString=function(){for(var t in e){var n=t[0].match(/^[A-Z]$/),i=e[t]===this.constructor;if(e.isFunction(e[t])&&n&&i)return t}return"Tone"},e.prototype.dispose=function(){return this},e.prototype.set=function(t,n,i){if(e.isObject(t))i=n;else if(e.isString(t)){var o={};o[t]=n,t=o}t:for(var r in t){n=t[r];var s=this;if(-1!==r.indexOf(".")){for(var a=r.split("."),u=0;u<a.length-1;u++)if((s=s[a[u]])instanceof e){a.splice(0,u+1);var c=a.join(".");s.set(c,n);continue t}r=a[a.length-1]}var p=s[r];e.isUndef(p)||(e.Signal&&p instanceof e.Signal||e.Param&&p instanceof e.Param?p.value!==n&&(e.isUndef(i)?p.value=n:p.rampTo(n,i)):p instanceof AudioParam?p.value!==n&&(p.value=n):e.TimeBase&&p instanceof e.TimeBase?s[r]=n:p instanceof e?p.set(n):p!==n&&(s[r]=n))}return this},e.prototype.get=function(t){e.isUndef(t)?t=this._collectDefaults(this.constructor):e.isString(t)&&(t=[t]);for(var n={},i=0;i<t.length;i++){var o=t[i],r=this,s=n;if(-1!==o.indexOf(".")){for(var a=o.split("."),u=0;u<a.length-1;u++){var c=a[u];s[c]=s[c]||{},s=s[c],r=r[c]}o=a[a.length-1]}var p=r[o];e.isObject(t[o])?s[o]=p.get():e.Signal&&p instanceof e.Signal?s[o]=p.value:e.Param&&p instanceof e.Param?s[o]=p.value:p instanceof AudioParam?s[o]=p.value:p instanceof e?s[o]=p.get():!e.isFunction(p)&&e.isDefined(p)&&(s[o]=p)}return n},e.prototype._collectDefaults=function(t){var n=[];if(e.isDefined(t.defaults)&&(n=Object.keys(t.defaults)),e.isDefined(t._super))for(var i=this._collectDefaults(t._super),o=0;o<i.length;o++)-1===n.indexOf(i[o])&&n.push(i[o]);return n},e.defaults=function(t,n,i){var o={};if(1===t.length&&e.isObject(t[0]))o=t[0];else for(var r=0;r<n.length;r++)o[n[r]]=t[r];return e.isDefined(i.defaults)?e.defaultArg(o,i.defaults):e.isObject(i)?e.defaultArg(o,i):o},e.defaultArg=function(t,n){if(e.isObject(t)&&e.isObject(n)){var i={};for(var o in t)i[o]=e.defaultArg(n[o],t[o]);for(var r in n)i[r]=e.defaultArg(t[r],n[r]);return i}return e.isUndef(t)?n:t},e.prototype.log=function(){if(this.debug||this.toString()===e.global.TONE_DEBUG_CLASS){var t=Array.from(arguments);t.unshift(this.toString()+":"),
//# sourceMappingURL=unmute.js.map;
var audiocontext;
'use strict';
audiocontext = function () {
    var audiocontext = new window.AudioContext();
    var unmuteButton = unmuteButton;
    console.log(unmuteButton);
    p5.prototype.getAudioContext = function () {
        return audiocontext;
    };
    p5.prototype.unmute = function () {
    };
    return audiocontext;
}(unmuteButton);
var master;
'use strict';
master = function () {
    var Master = function () {
        var audiocontext = p5.prototype.getAudioContext();
        this.input = audiocontext.createGain();
        this.output = audiocontext.createGain();
        this.limiter = audiocontext.createDynamicsCompressor();
        this.limiter.threshold.value = -3;
        this.limiter.ratio.value = 20;
        this.limiter.knee.value = 1;
        this.audiocontext = audiocontext;
        this.output.disconnect();
        this.input.connect(this.limiter);
        this.limiter.connect(this.output);
        this.meter = audiocontext.createGain();
        this.fftMeter = audiocontext.createGain();
        this.output.connect(this.meter);
        this.output.connect(this.fftMeter);
        this.output.connect(this.audiocontext.destination);
        this.soundArray = [];
        this.parts = [];
        this.extensions = [];
    };
    var p5sound = new Master();
    p5.prototype.getMasterVolume = function () {
        return p5sound.output.gain.value;
    };
    p5.prototype.masterVolume = function (vol, rampTime, tFromNow) {
        if (typeof vol === 'number') {
            var rampTime = rampTime || 0;
            var tFromNow = tFromNow || 0;
            var now = p5sound.audiocontext.currentTime;
            var currentVol = p5sound.output.gain.value;
            p5sound.output.gain.cancelScheduledValues(now + tFromNow);
            p5sound.output.gain.linearRampToValueAtTime(currentVol, now + tFromNow);
            p5sound.output.gain.linearRampToValueAtTime(vol, now + tFromNow + rampTime);
        } else if (vol) {
            vol.connect(p5sound.output.gain);
        } else {
            return p5sound.output.gain;
        }
    };
    p5.prototype.soundOut = p5.soundOut = p5sound;
    p5.soundOut._silentNode = p5sound.audiocontext.createGain();
    p5.soundOut._silentNode.gain.value = 0;
    p5.soundOut._silentNode.connect(p5sound.audiocontext.destination);
    return p5sound;
}();
var helpers;
'use strict';
helpers = function () {
    var p5sound = master;
    p5.prototype.sampleRate = function () {
        return p5sound.audiocontext.sampleRate;
    };
    p5.prototype.freqToMidi = function (f) {
        var mathlog2 = Math.log(f / 440) / Math.log(2);
        var m = Math.round(12 * mathlog2) + 69;
        return m;
    };
    var midiToFreq = p5.prototype.midiToFreq = function (m) {
        return 440 * Math.pow(2, (m - 69) / 12);
    };
    var noteToFreq = function (note) {
        if (typeof note !== 'string') {
            return note;
        }
        var wholeNotes = {
            A: 21,
            B: 23,
            C: 24,
            D: 26,
            E: 28,
            F: 29,
            G: 31
        };
        var value = wholeNotes[note[0].toUpperCase()];
        var octave = ~~note.slice(-1);
        value += 12 * (octave - 1);
        switch (note[1]) {
        case '#':
            value += 1;
            break;
        case 'b':
            value -= 1;
            break;
        default:
            break;
        }
        return midiToFreq(value);
    };
    p5.prototype.soundFormats = function () {
        p5sound.extensions = [];
        for (var i = 0; i < arguments.length; i++) {
            arguments[i] = arguments[i].toLowerCase();
            if ([
                    'mp3',
                    'wav',
                    'ogg',
                    'm4a',
                    'aac'
                ].indexOf(arguments[i]) > -1) {
                p5sound.extensions.push(arguments[i]);
            } else {
                throw arguments[i] + ' is not a valid sound format!';
            }
        }
    };
    p5.prototype.disposeSound = function () {
        for (var i = 0; i < p5sound.soundArray.length; i++) {
            p5sound.soundArray[i].dispose();
        }
    };
    p5.prototype.registerMethod('remove', p5.prototype.disposeSound);
    p5.prototype._checkFileFormats = function (paths) {
        var path;
        if (typeof paths === 'string') {
            path = paths;
            var extTest = path.split('.').pop();
            if ([
                    'mp3',
                    'wav',
                    'ogg',
                    'm4a',
                    'aac'
                ].indexOf(extTest) > -1) {
                if (p5.prototype.isFileSupported(extTest)) {
                    path = path;
                } else {
                    var pathSplit = path.split('.');
                    var pathCore = pathSplit[pathSplit.length - 1];
                    for (var i = 0; i < p5sound.extensions.length; i++) {
                        var extension = p5sound.extensions[i];
                        var supported = p5.prototype.isFileSupported(extension);
                        if (supported) {
                            pathCore = '';
                            if (pathSplit.length === 2) {
                                pathCore += pathSplit[0];
                            }
                            for (var i = 1; i <= pathSplit.length - 2; i++) {
                                var p = pathSplit[i];
                                pathCore += '.' + p;
                            }
                            path = pathCore += '.';
                            path = path += extension;
                            break;
                        }
                    }
                }
            } else {
                for (var i = 0; i < p5sound.extensions.length; i++) {
                    var extension = p5sound.extensions[i];
                    var supported = p5.prototype.isFileSupported(extension);
                    if (supported) {
                        path = path + '.' + extension;
                        break;
                    }
                }
            }
        } else if (typeof paths === 'object') {
            for (var i = 0; i < paths.length; i++) {
                var extension = paths[i].split('.').pop();
                var supported = p5.prototype.isFileSupported(extension);
                if (supported) {
                    path = paths[i];
                    break;
                }
            }
        }
        return path;
    };
    p5.prototype._mathChain = function (o, math, thisChain, nextChain, type) {
        for (var i in o.mathOps) {
            if (o.mathOps[i] instanceof type) {
                o.mathOps[i].dispose();
                thisChain = i;
                if (thisChain < o.mathOps.length - 1) {
                    nextChain = o.mathOps[i + 1];
                }
            }
        }
        o.mathOps[thisChain - 1].disconnect();
        o.mathOps[thisChain - 1].connect(math);
        math.connect(nextChain);
        o.mathOps[thisChain] = math;
        return o;
    };
    function convertToWav(audioBuffer) {
        var leftChannel, rightChannel;
        leftChannel = audioBuffer.getChannelData(0);
        if (audioBuffer.numberOfChannels > 1) {
            rightChannel = audioBuffer.getChannelData(1);
        } else {
            rightChannel = leftChannel;
        }
        var interleaved = interleave(leftChannel, rightChannel);
        var buffer = new window.ArrayBuffer(44 + interleaved.length * 2);
        var view = new window.DataView(buffer);
        writeUTFBytes(view, 0, 'RIFF');
        view.setUint32(4, 36 + interleaved.length * 2, true);
        writeUTFBytes(view, 8, 'WAVE');
        writeUTFBytes(view, 12, 'fmt ');
        view.setUint32(16, 16, true);
        view.setUint16(20, 1, true);
        view.setUint16(22, 2, true);
        view.setUint32(24, 44100, true);
        view.setUint32(28, 44100 * 4, true);
        view.setUint16(32, 4, true);
        view.setUint16(34, 16, true);
        writeUTFBytes(view, 36, 'data');
        view.setUint32(40, interleaved.length * 2, true);
        var lng = interleaved.length;
        var index = 44;
        var volume = 1;
        for (var i = 0; i < lng; i++) {
            view.setInt16(index, interleaved[i] * (32767 * volume), true);
            index += 2;
        }
        return view;
    }
    function interleave(leftChannel, rightChannel) {
        var length = leftChannel.length + rightChannel.length;
        var result = new Float32Array(length);
        var inputIndex = 0;
        for (var index = 0; index < length;) {
            result[index++] = leftChannel[inputIndex];
            result[index++] = rightChannel[inputIndex];
            inputIndex++;
        }
        return result;
    }
    function writeUTFBytes(view, offset, string) {
        var lng = string.length;
        for (var i = 0; i < lng; i++) {
            view.setUint8(offset + i, string.charCodeAt(i));
        }
    }
    return {
        convertToWav: convertToWav,
        midiToFreq: midiToFreq,
        noteToFreq: noteToFreq
    };
}(master);
var errorHandler;
'use strict';
errorHandler = function () {
    var CustomError = function (name, errorTrace, failedPath) {
        var err = new Error();
        var tempStack, splitStack;
        err.name = name;
        err.originalStack = err.stack + errorTrace;
        tempStack = err.stack + errorTrace;
        err.failedPath = failedPath;
        var splitStack = tempStack.split('\n');
        splitStack = splitStack.filter(function (ln) {
            return !ln.match(/(p5.|native code|globalInit)/g);
        });
        err.stack = splitStack.join('\n');
        return err;
    };
    return CustomError;
}();
var panner;
'use strict';
panner = function () {
    var p5sound = master;
    var ac = p5sound.audiocontext;
    if (typeof ac.createStereoPanner !== 'undefined') {
        p5.Panner = function (input, output) {
            this.stereoPanner = this.input = ac.createStereoPanner();
            input.connect(this.stereoPanner);
            this.stereoPanner.connect(output);
        };
        p5.Panner.prototype.pan = function (val, tFromNow) {
            var time = tFromNow || 0;
            var t = ac.currentTime + time;
            this.stereoPanner.pan.linearRampToValueAtTime(val, t);
        };
        p5.Panner.prototype.inputChannels = function () {
        };
        p5.Panner.prototype.connect = function (obj) {
            this.stereoPanner.connect(obj);
        };
        p5.Panner.prototype.disconnect = function () {
            if (this.stereoPanner) {
                this.stereoPanner.disconnect();
            }
        };
    } else {
        p5.Panner = function (input, output, numInputChannels) {
            this.input = ac.createGain();
            input.connect(this.input);
            this.left = ac.createGain();
            this.right = ac.createGain();
            this.left.channelInterpretation = 'discrete';
            this.right.channelInterpretation = 'discrete';
            if (numInputChannels > 1) {
                this.splitter = ac.createChannelSplitter(2);
                this.input.connect(this.splitter);
                this.splitter.connect(this.left, 1);
                this.splitter.connect(this.right, 0);
            } else {
                this.input.connect(this.left);
                this.input.connect(this.right);
            }
            this.output = ac.createChannelMerger(2);
            this.left.connect(this.output, 0, 1);
            this.right.connect(this.output, 0, 0);
            this.output.connect(output);
        };
        p5.Panner.prototype.pan = function (val, tFromNow) {
            var time = tFromNow || 0;
            var t = ac.currentTime + time;
            var v = (val + 1) / 2;
            var rightVal = Math.cos(v * Math.PI / 2);
            var leftVal = Math.sin(v * Math.PI / 2);
            this.left.gain.linearRampToValueAtTime(leftVal, t);
            this.right.gain.linearRampToValueAtTime(rightVal, t);
        };
        p5.Panner.prototype.inputChannels = function (numChannels) {
            if (numChannels === 1) {
                this.input.disconnect();
                this.input.connect(this.left);
                this.input.connect(this.right);
            } else if (numChannels === 2) {
                if (typeof (this.splitter === 'undefined')) {
                    this.splitter = ac.createChannelSplitter(2);
                }
                this.input.disconnect();
                this.input.connect(this.splitter);
                this.splitter.connect(this.left, 1);
                this.splitter.connect(this.right, 0);
            }
        };
        p5.Panner.prototype.connect = function (obj) {
            this.output.connect(obj);
        };
        p5.Panner.prototype.disconnect = function () {
            if (this.output) {
                this.output.disconnect();
            }
        };
    }
}(master);
var soundfile;
'use strict';
soundfile = function () {
    var CustomError = errorHandler;
    var p5sound = master;
    var ac = p5sound.audiocontext;
    var midiToFreq = helpers.midiToFreq;
    var convertToWav = helpers.convertToWav;
    p5.SoundFile = function (paths, onload, onerror, whileLoading) {
        if (typeof paths !== 'undefined') {
            if (typeof paths === 'string' || typeof paths[0] === 'string') {
                var path = p5.prototype._checkFileFormats(paths);
                this.url = path;
            } else if (typeof paths === 'object') {
                if (!(window.File && window.FileReader && window.FileList && window.Blob)) {
                    throw 'Unable to load file because the File API is not supported';
                }
            }
            if (paths.file) {
                paths = paths.file;
            }
            this.file = paths;
        }
        this._onended = function () {
        };
        this._looping = false;
        this._playing = false;
        this._paused = false;
        this._pauseTime = 0;
        this._cues = [];
        this._cueIDCounter = 0;
        this._lastPos = 0;
        this._counterNode = null;
        this._scopeNode = null;
        this.bufferSourceNodes = [];
        this.bufferSourceNode = null;
        this.buffer = null;
        this.playbackRate = 1;
        this.input = p5sound.audiocontext.createGain();
        this.output = p5sound.audiocontext.createGain();
        this.reversed = false;
        this.startTime = 0;
        this.endTime = null;
        this.pauseTime = 0;
        this.mode = 'sustain';
        this.startMillis = null;
        this.panPosition = 0;
        this.panner = new p5.Panner(this.output, p5sound.input, 2);
        if (this.url || this.file) {
            this.load(onload, onerror);
        }
        p5sound.soundArray.push(this);
        if (typeof whileLoading === 'function') {
            this._whileLoading = whileLoading;
        } else {
            this._whileLoading = function () {
            };
        }
    };
    p5.prototype.registerPreloadMethod('loadSound', p5.prototype);
    p5.prototype.loadSound = function (path, callback, onerror, whileLoading) {
        if (window.location.origin.indexOf('file://') > -1 && window.cordova === 'undefined') {
            window.alert('This sketch may require a server to load external files. Please see http://bit.ly/1qcInwS');
        }
        var self = this;
        var s = new p5.SoundFile(path, function () {
            if (typeof callback === 'function') {
                callback.apply(self, arguments);
            }
            if (typeof self._decrementPreload === 'function') {
                self._decrementPreload();
            }
        }, onerror, whileLoading);
        return s;
    };
    p5.SoundFile.prototype.load = function (callback, errorCallback) {
        var self = this;
        var errorTrace = new Error().stack;
        if (this.url !== undefined && this.url !== '') {
            var request = new XMLHttpRequest();
            request.addEventListener('progress', function (evt) {
                self._updateProgress(evt);
            }, false);
            request.open('GET', this.url, true);
            request.responseType = 'arraybuffer';
            request.onload = function () {
                if (request.status === 200) {
                    if (!self.panner)
                        return;
                    ac.decodeAudioData(request.response, function (buff) {
                        if (!self.panner)
                            return;
                        self.buffer = buff;
                        self.panner.inputChannels(buff.numberOfChannels);
                        if (callback) {
                            callback(self);
                        }
                    }, function () {
                        if (!self.panner)
                            return;
                        var err = new CustomError('decodeAudioData', errorTrace, self.url);
                        var msg = 'AudioContext error at decodeAudioData for ' + self.url;
                        if (errorCallback) {
                            err.msg = msg;
                            errorCallback(err);
                        } else {
                            console.error(msg + '\n The error stack trace includes: \n' + err.stack);
                        }
                    });
                } else {
                    if (!self.panner)
                        return;
                    var err = new CustomError('loadSound', errorTrace, self.url);
                    var msg = 'Unable to load ' + self.url + '. The request status was: ' + request.status + ' (' + request.statusText + ')';
                    if (errorCallback) {
                        err.message = msg;
                        errorCallback(err);
                    } else {
                        console.error(msg + '\n The error stack trace includes: \n' + err.stack);
                    }
                }
            };
            request.onerror = function () {
                var err = new CustomError('loadSound', errorTrace, self.url);
                var msg = 'There was no response from the server at ' + self.url + '. Check the url and internet connectivity.';
                if (errorCallback) {
                    err.message = msg;
                    errorCallback(err);
                } else {
                    console.error(msg + '\n The error stack trace includes: \n' + err.stack);
                }
            };
            request.send();
        } else if (this.file !== undefined) {
            var reader = new FileReader();
            reader.onload = function () {
                if (!self.panner)
                    return;
                ac.decodeAudioData(reader.result, function (buff) {
                    if (!self.panner)
                        return;
                    self.buffer = buff;
                    self.panner.inputChannels(buff.numberOfChannels);
                    if (callback) {
                        callback(self);
                    }
                });
            };
            reader.onerror = function (e) {
                if (!self.panner)
                    return;
                if (onerror) {
                    onerror(e);
                }
            };
            reader.readAsArrayBuffer(this.file);
        }
    };
    p5.SoundFile.prototype._updateProgress = function (evt) {
        if (evt.lengthComputable) {
            var percentComplete = evt.loaded / evt.total * 0.99;
            this._whileLoading(percentComplete, evt);
        } else {
            this._whileLoading('size unknown');
        }
    };
    p5.SoundFile.prototype.isLoaded = function () {
        if (this.buffer) {
            return true;
        } else {
            return false;
        }
    };
    p5.SoundFile.prototype.play = function (startTime, rate, amp, _cueStart, duration) {
        if (!this.output) {
            console.warn('SoundFile.play() called after dispose');
            return;
        }
        var self = this;
        var now = p5sound.audiocontext.currentTime;
        var cueStart, cueEnd;
        var time = startTime || 0;
        if (time < 0) {
            time = 0;
        }
        time = time + now;
        if (typeof rate !== 'undefined') {
            this.rate(rate);
        }
        if (typeof amp !== 'undefined') {
            this.setVolume(amp);
        }
        if (this.buffer) {
            this._pauseTime = 0;
            if (this.mode === 'restart' && this.buffer && this.bufferSourceNode) {
                this.bufferSourceNode.stop(time);
                this._counterNode.stop(time);
            }
            if (this.mode === 'untildone' && this.isPlaying()) {
                return;
            }
            this.bufferSourceNode = this._initSourceNode();
            delete this._counterNode;
            this._counterNode = this._initCounterNode();
            if (_cueStart) {
                if (_cueStart >= 0 && _cueStart < this.buffer.duration) {
                    cueStart = _cueStart;
                } else {
                    throw 'start time out of range';
                }
            } else {
                cueStart = 0;
            }
            if (duration) {
                duration = duration <= this.buffer.duration - cueStart ? duration : this.buffer.duration;
            }
            if (this._paused) {
                this.bufferSourceNode.start(time, this.pauseTime, duration);
                this._counterNode.start(time, this.pauseTime, duration);
            } else {
                this.bufferSourceNode.start(time, cueStart, duration);
                this._counterNode.start(time, cueStart, duration);
            }
            this._playing = true;
            this._paused = false;
            this.bufferSourceNodes.push(this.bufferSourceNode);
            this.bufferSourceNode._arrayIndex = this.bufferSourceNodes.length - 1;
            var clearOnEnd = function () {
                this._playing = false;
                this.removeEventListener('ended', clearOnEnd, false);
                self._onended(self);
                self.bufferSourceNodes.forEach(function (n, i) {
                    if (n._playing === false) {
                        self.bufferSourceNodes.splice(i);
                    }
                });
                if (self.bufferSourceNodes.length === 0) {
                    self._playing = false;
                }
            };
            this.bufferSourceNode.onended = clearOnEnd;
        } else {
            throw 'not ready to play file, buffer has yet to load. Try preload()';
        }
        this.bufferSourceNode.loop = this._looping;
        this._counterNode.loop = this._looping;
        if (this._looping === true) {
            cueEnd = duration ? duration : cueStart - 1e-15;
            this.bufferSourceNode.loopStart = cueStart;
            this.bufferSourceNode.loopEnd = cueEnd;
            this._counterNode.loopStart = cueStart;
            this._counterNode.loopEnd = cueEnd;
        }
    };
    p5.SoundFile.prototype.playMode = function (str) {
        var s = str.toLowerCase();
        if (s === 'restart' && this.buffer && this.bufferSourceNode) {
            for (var i = 0; i < this.bufferSourceNodes.length - 1; i++) {
                var now = p5sound.audiocontext.currentTime;
                this.bufferSourceNodes[i].stop(now);
            }
        }
        if (s === 'restart' || s === 'sustain' || s === 'untildone') {
            this.mode = s;
        } else {
            throw 'Invalid play mode. Must be either "restart" or "sustain"';
        }
    };
    p5.SoundFile.prototype.pause = function (startTime) {
        var now = p5sound.audiocontext.currentTime;
        var time = startTime || 0;
        var pTime = time + now;
        if (this.isPlaying() && this.buffer && this.bufferSourceNode) {
            this.pauseTime = this.currentTime();
            this.bufferSourceNode.stop(pTime);
            this._counterNode.stop(pTime);
            this._paused = true;
            this._playing = false;
            this._pauseTime = this.currentTime();
        } else {
            this._pauseTime = 0;
        }
    };
    p5.SoundFile.prototype.loop = function (startTime, rate, amp, loopStart, duration) {
        this._looping = true;
        this.play(startTime, rate, amp, loopStart, duration);
    };
    p5.SoundFile.prototype.setLoop = function (bool) {
        if (bool === true) {
            this._looping = true;
        } else if (bool === false) {
            this._looping = false;
        } else {
            throw 'Error: setLoop accepts either true or false';
        }
        if (this.bufferSourceNode) {
            this.bufferSourceNode.loop = this._looping;
            this._counterNode.loop = this._looping;
        }
    };
    p5.SoundFile.prototype.isLooping = function () {
        if (!this.bufferSourceNode) {
            return false;
        }
        if (this._looping === true && this.isPlaying() === true) {
            return true;
        }
        return false;
    };
    p5.SoundFile.prototype.isPlaying = function () {
        return this._playing;
    };
    p5.SoundFile.prototype.isPaused = function () {
        return this._paused;
    };
    p5.SoundFile.prototype.stop = function (timeFromNow) {
        var time = timeFromNow || 0;
        if (this.mode === 'sustain' || this.mode === 'untildone') {
            this.stopAll(time);
            this._playing = false;
            this.pauseTime = 0;
            this._paused = false;
        } else if (this.buffer && this.bufferSourceNode) {
            var now = p5sound.audiocontext.currentTime;
            var t = time || 0;
            this.pauseTime = 0;
            this.bufferSourceNode.stop(now + t);
            this._counterNode.stop(now + t);
            this._playing = false;
            this._paused = false;
        }
    };
    p5.SoundFile.prototype.stopAll = function (_time) {
        var now = p5sound.audiocontext.currentTime;
        var time = _time || 0;
        if (this.buffer && this.bufferSourceNode) {
            for (var i = 0; i < this.bufferSourceNodes.length; i++) {
                if (typeof this.bufferSourceNodes[i] !== undefined) {
                    try {
                        this.bufferSourceNodes[i].onended = function () {
                        };
                        this.bufferSourceNodes[i].stop(now + time);
                    } catch (e) {
                    }
                }
            }
            this._counterNode.stop(now + time);
            this._onended(this);
        }
    };
    p5.SoundFile.prototype.setVolume = function (vol, _rampTime, _tFromNow) {
        if (typeof vol === 'number') {
            var rampTime = _rampTime || 0;
            var tFromNow = _tFromNow || 0;
            var now = p5sound.audiocontext.currentTime;
            var currentVol = this.output.gain.value;
            this.output.gain.cancelScheduledValues(now + tFromNow);
            this.output.gain.linearRampToValueAtTime(currentVol, now + tFromNow);
            this.output.gain.linearRampToValueAtTime(vol, now + tFromNow + rampTime);
        } else if (vol) {
            vol.connect(this.output.gain);
        } else {
            return this.output.gain;
        }
    };
    p5.SoundFile.prototype.amp = p5.SoundFile.prototype.setVolume;
    p5.SoundFile.prototype.fade = p5.SoundFile.prototype.setVolume;
    p5.SoundFile.prototype.getVolume = function () {
        return this.output.gain.value;
    };
    p5.SoundFile.prototype.pan = function (pval, tFromNow) {
        this.panPosition = pval;
        this.panner.pan(pval, tFromNow);
    };
    p5.SoundFile.prototype.getPan = function () {
        return this.panPosition;
    };
    p5.SoundFile.prototype.rate = function (playbackRate) {
        var reverse = false;
        if (typeof playbackRate === 'undefined') {
            return this.playbackRate;
        }
        this.playbackRate = playbackRate;
        if (playbackRate === 0) {
            playbackRate = 1e-13;
        } else if (playbackRate < 0 && !this.reversed) {
            playbackRate = Math.abs(playbackRate);
            reverse = true;
        } else if (playbackRate > 0 && this.reversed) {
            reverse = true;
        }
        if (this.bufferSourceNode) {
            var now = p5sound.audiocontext.currentTime;
            this.bufferSourceNode.playbackRate.cancelScheduledValues(now);
            this.bufferSourceNode.playbackRate.linearRampToValueAtTime(Math.abs(playbackRate), now);
            this._counterNode.playbackRate.cancelScheduledValues(now);
            this._counterNode.playbackRate.linearRampToValueAtTime(Math.abs(playbackRate), now);
        }
        if (reverse) {
            this.reverseBuffer();
        }
        return this.playbackRate;
    };
    p5.SoundFile.prototype.setPitch = function (num) {
        var newPlaybackRate = midiToFreq(num) / midiToFreq(60);
        this.rate(newPlaybackRate);
    };
    p5.SoundFile.prototype.getPlaybackRate = function () {
        return this.playbackRate;
    };
    p5.SoundFile.prototype.duration = function () {
        if (this.buffer) {
            return this.buffer.duration;
        } else {
            return 0;
        }
    };
    p5.SoundFile.prototype.currentTime = function () {
        return this.reversed ? Math.abs(this._lastPos - this.buffer.length) / ac.sampleRate : this._lastPos / ac.sampleRate;
    };
    p5.SoundFile.prototype.jump = function (cueTime, duration) {
        if (cueTime < 0 || cueTime > this.buffer.duration) {
            throw 'jump time out of range';
        }
        if (duration > this.buffer.duration - cueTime) {
            throw 'end time out of range';
        }
        var cTime = cueTime || 0;
        var dur = duration || undefined;
        if (this.isPlaying()) {
            this.stop(0);
        }
        this.play(0, this.playbackRate, this.output.gain.value, cTime, dur);
    };
    p5.SoundFile.prototype.channels = function () {
        return this.buffer.numberOfChannels;
    };
    p5.SoundFile.prototype.sampleRate = function () {
        return this.buffer.sampleRate;
    };
    p5.SoundFile.prototype.frames = function () {
        return this.buffer.length;
    };
    p5.SoundFile.prototype.getPeaks = function (length) {
        if (this.buffer) {
            if (!length) {
                length = window.width * 5;
            }
            if (this.buffer) {
                var buffer = this.buffer;
                var sampleSize = buffer.length / length;
                var sampleStep = ~~(sampleSize / 10) || 1;
                var channels = buffer.numberOfChannels;
                var peaks = new Float32Array(Math.round(length));
                for (var c = 0; c < channels; c++) {
                    var chan = buffer.getChannelData(c);
                    for (var i = 0; i < length; i++) {
                        var start = ~~(i * sampleSize);
                        var end = ~~(start + sampleSize);
                        var max = 0;
                        for (var j = start; j < end; j += sampleStep) {
                            var value = chan[j];
                            if (value > max) {
                                max = value;
                            } else if (-value > max) {
                                max = value;
                            }
                        }
                        if (c === 0 || Math.abs(max) > peaks[i]) {
                            peaks[i] = max;
                        }
                    }
                }
                return peaks;
            }
        } else {
            throw 'Cannot load peaks yet, buffer is not loaded';
        }
    };
    p5.SoundFile.prototype.reverseBuffer = function () {
        if (this.buffer) {
            var currentPos = this._lastPos / ac.sampleRate;
            var curVol = this.getVolume();
            this.setVolume(0, 0.001);
            const numChannels = this.buffer.numberOfChannels;
            for (var i = 0; i < numChannels; i++) {
                this.buffer.getChannelData(i).reverse();
            }
            this.reversed = !this.reversed;
            if (currentPos) {
                this.jump(this.duration() - currentPos);
            }
            this.setVolume(curVol, 0.001);
        } else {
            throw 'SoundFile is not done loading';
        }
    };
    p5.SoundFile.prototype.onended = function (callback) {
        this._onended = callback;
        return this;
    };
    p5.SoundFile.prototype.add = function () {
    };
    p5.SoundFile.prototype.dispose = function () {
        var now = p5sound.audiocontext.currentTime;
        var index = p5sound.soundArray.indexOf(this);
        p5sound.soundArray.splice(index, 1);
        this.stop(now);
        if (this.buffer && this.bufferSourceNode) {
            for (var i = 0; i < this.bufferSourceNodes.length - 1; i++) {
                if (this.bufferSourceNodes[i] !== null) {
                    this.bufferSourceNodes[i].disconnect();
                    try {
                        this.bufferSourceNodes[i].stop(now);
                    } catch (e) {
                        console.warning('no buffer source node to dispose');
                    }
                    this.bufferSourceNodes[i] = null;
                }
            }
            if (this.isPlaying()) {
                try {
                    this._counterNode.stop(now);
                } catch (e) {
                    console.log(e);
                }
                this._counterNode = null;
            }
        }
        if (this.output) {
            this.output.disconnect();
            this.output = null;
        }
        if (this.panner) {
            this.panner.disconnect();
            this.panner = null;
        }
    };
    p5.SoundFile.prototype.connect = function (unit) {
        if (!unit) {
            this.panner.connect(p5sound.input);
        } else {
            if (unit.hasOwnProperty('input')) {
                this.panner.connect(unit.input);
            } else {
                this.panner.connect(unit);
            }
        }
    };
    p5.SoundFile.prototype.disconnect = function () {
        if (this.panner) {
            this.panner.disconnect();
        }
    };
    p5.SoundFile.prototype.getLevel = function () {
        console.warn('p5.SoundFile.getLevel has been removed from the library. Use p5.Amplitude instead');
    };
    p5.SoundFile.prototype.setPath = function (p, callback) {
        var path = p5.prototype._checkFileFormats(p);
        this.url = path;
        this.load(callback);
    };
    p5.SoundFile.prototype.setBuffer = function (buf) {
        var numChannels = buf.length;
        var size = buf[0].length;
        var newBuffer = ac.createBuffer(numChannels, size, ac.sampleRate);
        if (!(buf[0] instanceof Float32Array)) {
            buf[0] = new Float32Array(buf[0]);
        }
        for (var channelNum = 0; channelNum < numChannels; channelNum++) {
            var channel = newBuffer.getChannelData(channelNum);
            channel.set(buf[channelNum]);
        }
        this.buffer = newBuffer;
        this.panner.inputChannels(numChannels);
    };
    var _createCounterBuffer = function (buffer) {
        const len = buffer.length;
        const audioBuf = ac.createBuffer(1, buffer.length, ac.sampleRate);
        const arrayBuffer = audioBuf.getChannelData(0);
        for (var index = 0; index < len; index++) {
            arrayBuffer[index] = index;
        }
        return audioBuf;
    };
    p5.SoundFile.prototype._initCounterNode = function () {
        var self = this;
        var now = ac.currentTime;
        var cNode = ac.createBufferSource();
        if (self._scopeNode) {
            self._scopeNode.disconnect();
            delete self._scopeNode.onaudioprocess;
            delete self._scopeNode;
        }
        self._scopeNode = ac.createScriptProcessor(256, 1, 1);
        cNode.buffer = _createCounterBuffer(self.buffer);
        cNode.playbackRate.setValueAtTime(self.playbackRate, now);
        cNode.connect(self._scopeNode);
        self._scopeNode.connect(p5.soundOut._silentNode);
        self._scopeNode.onaudioprocess = function (processEvent) {
            var inputBuffer = processEvent.inputBuffer.getChannelData(0);
            self._lastPos = inputBuffer[inputBuffer.length - 1] || 0;
            self._onTimeUpdate(self._lastPos);
        };
        return cNode;
    };
    p5.SoundFile.prototype._initSourceNode = function () {
        var bufferSourceNode = ac.createBufferSource();
        bufferSourceNode.buffer = this.buffer;
        bufferSourceNode.playbackRate.value = this.playbackRate;
        bufferSourceNode.connect(this.output);
        return bufferSourceNode;
    };
    p5.SoundFile.prototype.processPeaks = function (callback, _initThreshold, _minThreshold, _minPeaks) {
        var bufLen = this.buffer.length;
        var sampleRate = this.buffer.sampleRate;
        var buffer = this.buffer;
        var allPeaks = [];
        var initialThreshold = _initThreshold || 0.9, threshold = initialThreshold, minThreshold = _minThreshold || 0.22, minPeaks = _minPeaks || 200;
        var offlineContext = new window.OfflineAudioContext(1, bufLen, sampleRate);
        var source = offlineContext.createBufferSource();
        source.buffer = buffer;
        var filter = offlineContext.createBiquadFilter();
        filter.type = 'lowpass';
        source.connect(filter);
        filter.connect(offlineContext.destination);
        source.start(0);
        offlineContext.startRendering();
        offlineContext.oncomplete = function (e) {
            if (!self.panner)
                return;
            var filteredBuffer = e.renderedBuffer;
            var bufferData = filteredBuffer.getChannelData(0);
            do {
                allPeaks = getPeaksAtThreshold(bufferData, threshold);
                threshold -= 0.005;
            } while (Object.keys(allPeaks).length < minPeaks && threshold >= minThreshold);
            var intervalCounts = countIntervalsBetweenNearbyPeaks(allPeaks);
            var groups = groupNeighborsByTempo(intervalCounts, filteredBuffer.sampleRate);
            var topTempos = groups.sort(function (intA, intB) {
                return intB.count - intA.count;
            }).splice(0, 5);
            this.tempo = topTempos[0].tempo;
            var bpmVariance = 5;
            var tempoPeaks = getPeaksAtTopTempo(allPeaks, topTempos[0].tempo, filteredBuffer.sampleRate, bpmVariance);
            callback(tempoPeaks);
        };
    };
    var Peak = function (amp, i) {
        this.sampleIndex = i;
        this.amplitude = amp;
        this.tempos = [];
        this.intervals = [];
    };
    function getPeaksAtThreshold(data, threshold) {
        var peaksObj = {};
        var length = data.length;
        for (var i = 0; i < length; i++) {
            if (data[i] > threshold) {
                var amp = data[i];
                var peak = new Peak(amp, i);
                peaksObj[i] = peak;
                i += 6000;
            }
            i++;
        }
        return peaksObj;
    }
    function countIntervalsBetweenNearbyPeaks(peaksObj) {
        var intervalCounts = [];
        var peaksArray = Object.keys(peaksObj).sort();
        for (var index = 0; index < peaksArray.length; index++) {
            for (var i = 0; i < 10; i++) {
                var startPeak = peaksObj[peaksArray[index]];
                var endPeak = peaksObj[peaksArray[index + i]];
                if (startPeak && endPeak) {
                    var startPos = startPeak.sampleIndex;
                    var endPos = endPeak.sampleIndex;
                    var interval = endPos - startPos;
                    if (interval > 0) {
                        startPeak.intervals.push(interval);
                    }
                    var foundInterval = intervalCounts.some(function (intervalCount) {
                        if (intervalCount.interval === interval) {
                            intervalCount.count++;
                            return intervalCount;
                        }
                    });
                    if (!foundInterval) {
                        intervalCounts.push({
                            interval: interval,
                            count: 1
                        });
                    }
                }
            }
        }
        return intervalCounts;
    }
    function groupNeighborsByTempo(intervalCounts, sampleRate) {
        var tempoCounts = [];
        intervalCounts.forEach(function (intervalCount) {
            try {
                var theoreticalTempo = Math.abs(60 / (intervalCount.interval / sampleRate));
                theoreticalTempo = mapTempo(theoreticalTempo);
                var foundTempo = tempoCounts.some(function (tempoCount) {
                    if (tempoCount.tempo === theoreticalTempo)
                        return tempoCount.count += intervalCount.count;
                });
                if (!foundTempo) {
                    if (isNaN(theoreticalTempo)) {
                        return;
                    }
                    tempoCounts.push({
                        tempo: Math.round(theoreticalTempo),
                        count: intervalCount.count
                    });
                }
            } catch (e) {
                throw e;
            }
        });
        return tempoCounts;
    }
    function getPeaksAtTopTempo(peaksObj, tempo, sampleRate, bpmVariance) {
        var peaksAtTopTempo = [];
        var peaksArray = Object.keys(peaksObj).sort();
        for (var i = 0; i < peaksArray.length; i++) {
            var key = peaksArray[i];
            var peak = peaksObj[key];
            for (var j = 0; j < peak.intervals.length; j++) {
                var intervalBPM = Math.round(Math.abs(60 / (peak.intervals[j] / sampleRate)));
                intervalBPM = mapTempo(intervalBPM);
                if (Math.abs(intervalBPM - tempo) < bpmVariance) {
                    peaksAtTopTempo.push(peak.sampleIndex / sampleRate);
                }
            }
        }
        peaksAtTopTempo = peaksAtTopTempo.filter(function (peakTime, index, arr) {
            var dif = arr[index + 1] - peakTime;
            if (dif > 0.01) {
                return true;
            }
        });
        return peaksAtTopTempo;
    }
    function mapTempo(theoreticalTempo) {
        if (!isFinite(theoreticalTempo) || theoreticalTempo === 0) {
            return;
        }
        while (theoreticalTempo < 90)
            theoreticalTempo *= 2;
        while (theoreticalTempo > 180 && theoreticalTempo > 90)
            theoreticalTempo /= 2;
        return theoreticalTempo;
    }
    var Cue = function (callback, time, id, val) {
        this.callback = callback;
        this.time = time;
        this.id = id;
        this.val = val;
    };
    p5.SoundFile.prototype.addCue = function (time, callback, val) {
        var id = this._cueIDCounter++;
        var cue = new Cue(callback, time, id, val);
        this._cues.push(cue);
        return id;
    };
    p5.SoundFile.prototype.removeCue = function (id) {
        var cueLength = this._cues.length;
        for (var i = 0; i < cueLength; i++) {
            var cue = this._cues[i];
            if (cue.id === id) {
                this._cues.splice(i, 1);
                break;
            }
        }
        if (this._cues.length === 0) {
        }
    };
    p5.SoundFile.prototype.clearCues = function () {
        this._cues = [];
    };
    p5.SoundFile.prototype._onTimeUpdate = function (position) {
        var playbackTime = position / this.buffer.sampleRate;
        var cueLength = this._cues.length;
        for (var i = 0; i < cueLength; i++) {
            var cue = this._cues[i];
            var callbackTime = cue.time;
            var val = cue.val;
            if (this._prevTime < callbackTime && callbackTime <= playbackTime) {
                cue.callback(val);
            }
        }
        this._prevTime = playbackTime;
    };
    p5.SoundFile.prototype.save = function (fileName) {
        const dataView = convertToWav(this.buffer);
        p5.prototype.saveSound([dataView], fileName, 'wav');
    };
    p5.SoundFile.prototype.getBlob = function () {
        const dataView = convertToWav(this.buffer);
        return new Blob([dataView], { type: 'audio/wav' });
    };
}(errorHandler, master, helpers, helpers);
var amplitude;
'use strict';
amplitude = function () {
    var p5sound = master;
    p5.Amplitude = function (smoothing) {
        this.bufferSize = 2048;
        this.audiocontext = p5sound.audiocontext;
        this.processor = this.audiocontext.createScriptProcessor(this.bufferSize, 2, 1);
        this.input = this.processor;
        this.output = this.audiocontext.createGain();
        this.smoothing = smoothing || 0;
        this.volume = 0;
        this.average = 0;
        this.stereoVol = [
            0,
            0
        ];
        this.stereoAvg = [
            0,
            0
        ];
        this.stereoVolNorm = [
            0,
            0
        ];
        this.volMax = 0.001;
        this.normalize = false;
        this.processor.onaudioprocess = this._audioProcess.bind(this);
        this.processor.connect(this.output);
        this.output.gain.value = 0;
        this.output.connect(this.audiocontext.destination);
        p5sound.meter.connect(this.processor);
        p5sound.soundArray.push(this);
    };
    p5.Amplitude.prototype.setInput = function (source, smoothing) {
        p5sound.meter.disconnect();
        if (smoothing) {
            this.smoothing = smoothing;
        }
        if (source == null) {
            console.log('Amplitude input source is not ready! Connecting to master output instead');
            p5sound.meter.connect(this.processor);
        } else if (source instanceof p5.Signal) {
            source.output.connect(this.processor);
        } else if (source) {
            source.connect(this.processor);
            this.processor.disconnect();
            this.processor.connect(this.output);
        } else {
            p5sound.meter.connect(this.processor);
        }
    };
    p5.Amplitude.prototype.connect = function (unit) {
        if (unit) {
            if (unit.hasOwnProperty('input')) {
                this.output.connect(unit.input);
            } else {
                this.output.connect(unit);
            }
        } else {
            this.output.connect(this.panner.connect(p5sound.input));
        }
    };
    p5.Amplitude.prototype.disconnect = function () {
        if (this.output) {
            this.output.disconnect();
        }
    };
    p5.Amplitude.prototype._audioProcess = function (event) {
        for (var channel = 0; channel < event.inputBuffer.numberOfChannels; channel++) {
            var inputBuffer = event.inputBuffer.getChannelData(channel);
            var bufLength = inputBuffer.length;
            var total = 0;
            var sum = 0;
            var x;
            for (var i = 0; i < bufLength; i++) {
                x = inputBuffer[i];
                if (this.normalize) {
                    total += Math.max(Math.min(x / this.volMax, 1), -1);
                    sum += Math.max(Math.min(x / this.volMax, 1), -1) * Math.max(Math.min(x / this.volMax, 1), -1);
                } else {
                    total += x;
                    sum += x * x;
                }
            }
            var average = total / bufLength;
            var rms = Math.sqrt(sum / bufLength);
            this.stereoVol[channel] = Math.max(rms, this.stereoVol[channel] * this.smoothing);
            this.stereoAvg[channel] = Math.max(average, this.stereoVol[channel] * this.smoothing);
            this.volMax = Math.max(this.stereoVol[channel], this.volMax);
        }
        var self = this;
        var volSum = this.stereoVol.reduce(function (previousValue, currentValue, index) {
            self.stereoVolNorm[index - 1] = Math.max(Math.min(self.stereoVol[index - 1] / self.volMax, 1), 0);
            self.stereoVolNorm[index] = Math.max(Math.min(self.stereoVol[index] / self.volMax, 1), 0);
            return previousValue + currentValue;
        });
        this.volume = volSum / this.stereoVol.length;
        this.volNorm = Math.max(Math.min(this.volume / this.volMax, 1), 0);
    };
    p5.Amplitude.prototype.getLevel = function (channel) {
        if (typeof channel !== 'undefined') {
            if (this.normalize) {
                return this.stereoVolNorm[channel];
            } else {
                return this.stereoVol[channel];
            }
        } else if (this.normalize) {
            return this.volNorm;
        } else {
            return this.volume;
        }
    };
    p5.Amplitude.prototype.toggleNormalize = function (bool) {
        if (typeof bool === 'boolean') {
            this.normalize = bool;
        } else {
            this.normalize = !this.normalize;
        }
    };
    p5.Amplitude.prototype.smooth = function (s) {
        if (s >= 0 && s < 1) {
            this.smoothing = s;
        } else {
            console.log('Error: smoothing must be between 0 and 1');
        }
    };
    p5.Amplitude.prototype.dispose = function () {
        var index = p5sound.soundArray.indexOf(this);
        p5sound.soundArray.splice(index, 1);
        if (this.input) {
            this.input.disconnect();
            delete this.input;
        }
        if (this.output) {
            this.output.disconnect();
            delete this.output;
        }
        delete this.processor;
    };
}(master);
var fft;
'use strict';
fft = function () {
    var p5sound = master;
    p5.FFT = function (smoothing, bins) {
        this.input = this.analyser = p5sound.audiocontext.createAnalyser();
        Object.defineProperties(this, {
            bins: {
                get: function () {
                    return this.analyser.fftSize / 2;
                },
                set: function (b) {
                    this.analyser.fftSize = b * 2;
                },
                configurable: true,
                enumerable: true
            },
            smoothing: {
                get: function () {
                    return this.analyser.smoothingTimeConstant;
                },
                set: function (s) {
                    this.analyser.smoothingTimeConstant = s;
                },
                configurable: true,
                enumerable: true
            }
        });
        this.smooth(smoothing);
        this.bins = bins || 1024;
        p5sound.fftMeter.connect(this.analyser);
        this.freqDomain = new Uint8Array(this.analyser.frequencyBinCount);
        this.timeDomain = new Uint8Array(this.analyser.frequencyBinCount);
        this.bass = [
            20,
            140
        ];
        this.lowMid = [
            140,
            400
        ];
        this.mid = [
            400,
            2600
        ];
        this.highMid = [
            2600,
            5200
        ];
        this.treble = [
            5200,
            14000
        ];
        p5sound.soundArray.push(this);
    };
    p5.FFT.prototype.setInput = function (source) {
        if (!source) {
            p5sound.fftMeter.connect(this.analyser);
        } else {
            if (source.output) {
                source.output.connect(this.analyser);
            } else if (source.connect) {
                source.connect(this.analyser);
            }
            p5sound.fftMeter.disconnect();
        }
    };
    p5.FFT.prototype.waveform = function () {
        var bins, mode, normalArray;
        for (var i = 0; i < arguments.length; i++) {
            if (typeof arguments[i] === 'number') {
                bins = arguments[i];
                this.analyser.fftSize = bins * 2;
            }
            if (typeof arguments[i] === 'string') {
                mode = arguments[i];
            }
        }
        if (mode && !p5.prototype._isSafari()) {
            timeToFloat(this, this.timeDomain);
            this.analyser.getFloatTimeDomainData(this.timeDomain);
            return this.timeDomain;
        } else {
            timeToInt(this, this.timeDomain);
            this.analyser.getByteTimeDomainData(this.timeDomain);
            var normalArray = new Array();
            for (var j = 0; j < this.timeDomain.length; j++) {
                var scaled = p5.prototype.map(this.timeDomain[j], 0, 255, -1, 1);
                normalArray.push(scaled);
            }
            return normalArray;
        }
    };
    p5.FFT.prototype.analyze = function () {
        var mode;
        for (var i = 0; i < arguments.length; i++) {
            if (typeof arguments[i] === 'number') {
                this.bins = arguments[i];
                this.analyser.fftSize = this.bins * 2;
            }
            if (typeof arguments[i] === 'string') {
                mode = arguments[i];
            }
        }
        if (mode && mode.toLowerCase() === 'db') {
            freqToFloat(this);
            this.analyser.getFloatFrequencyData(this.freqDomain);
            return this.freqDomain;
        } else {
            freqToInt(this, this.freqDomain);
            this.analyser.getByteFrequencyData(this.freqDomain);
            var normalArray = Array.apply([], this.freqDomain);
            normalArray.length === this.analyser.fftSize;
            normalArray.constructor === Array;
            return normalArray;
        }
    };
    p5.FFT.prototype.getEnergy = function (frequency1, frequency2) {
        var nyquist = p5sound.audiocontext.sampleRate / 2;
        if (frequency1 === 'bass') {
            frequency1 = this.bass[0];
            frequency2 = this.bass[1];
        } else if (frequency1 === 'lowMid') {
            frequency1 = this.lowMid[0];
            frequency2 = this.lowMid[1];
        } else if (frequency1 === 'mid') {
            frequency1 = this.mid[0];
            frequency2 = this.mid[1];
        } else if (frequency1 === 'highMid') {
            frequency1 = this.highMid[0];
            frequency2 = this.highMid[1];
        } else if (frequency1 === 'treble') {
            frequency1 = this.treble[0];
            frequency2 = this.treble[1];
        }
        if (typeof frequency1 !== 'number') {
            throw 'invalid input for getEnergy()';
        } else if (!frequency2) {
            var index = Math.round(frequency1 / nyquist * this.freqDomain.length);
            return this.freqDomain[index];
        } else if (frequency1 && frequency2) {
            if (frequency1 > frequency2) {
                var swap = frequency2;
                frequency2 = frequency1;
                frequency1 = swap;
            }
            var lowIndex = Math.round(frequency1 / nyquist * this.freqDomain.length);
            var highIndex = Math.round(frequency2 / nyquist * this.freqDomain.length);
            var total = 0;
            var numFrequencies = 0;
            for (var i = lowIndex; i <= highIndex; i++) {
                total += this.freqDomain[i];
                numFrequencies += 1;
            }
            var toReturn = total / numFrequencies;
            return toReturn;
        } else {
            throw 'invalid input for getEnergy()';
        }
    };
    p5.FFT.prototype.getFreq = function (freq1, freq2) {
        console.log('getFreq() is deprecated. Please use getEnergy() instead.');
        var x = this.getEnergy(freq1, freq2);
        return x;
    };
    p5.FFT.prototype.getCentroid = function () {
        var nyquist = p5sound.audiocontext.sampleRate / 2;
        var cumulative_sum = 0;
        var centroid_normalization = 0;
        for (var i = 0; i < this.freqDomain.length; i++) {
            cumulative_sum += i * this.freqDomain[i];
            centroid_normalization += this.freqDomain[i];
        }
        var mean_freq_index = 0;
        if (centroid_normalization !== 0) {
            mean_freq_index = cumulative_sum / centroid_normalization;
        }
        var spec_centroid_freq = mean_freq_index * (nyquist / this.freqDomain.length);
        return spec_centroid_freq;
    };
    p5.FFT.prototype.smooth = function (s) {
        if (typeof s !== 'undefined') {
            this.smoothing = s;
        }
        return this.smoothing;
    };
    p5.FFT.prototype.dispose = function () {
        var index = p5sound.soundArray.indexOf(this);
        p5sound.soundArray.splice(index, 1);
        if (this.analyser) {
            this.analyser.disconnect();
            delete this.analyser;
        }
    };
    p5.FFT.prototype.linAverages = function (N) {
        var N = N || 16;
        var spectrum = this.freqDomain;
        var spectrumLength = spectrum.length;
        var spectrumStep = Math.floor(spectrumLength / N);
        var linearAverages = new Array(N);
        var groupIndex = 0;
        for (var specIndex = 0; specIndex < spectrumLength; specIndex++) {
            linearAverages[groupIndex] = linearAverages[groupIndex] !== undefined ? (linearAverages[groupIndex] + spectrum[specIndex]) / 2 : spectrum[specIndex];
            if (specIndex % spectrumStep === spectrumStep - 1) {
                groupIndex++;
            }
        }
        return linearAverages;
    };
    p5.FFT.prototype.logAverages = function (octaveBands) {
        var nyquist = p5sound.audiocontext.sampleRate / 2;
        var spectrum = this.freqDomain;
        var spectrumLength = spectrum.length;
        var logAverages = new Array(octaveBands.length);
        var octaveIndex = 0;
        for (var specIndex = 0; specIndex < spectrumLength; specIndex++) {
            var specIndexFrequency = Math.round(specIndex * nyquist / this.freqDomain.length);
            if (specIndexFrequency > octaveBands[octaveIndex].hi) {
                octaveIndex++;
            }
            logAverages[octaveIndex] = logAverages[octaveIndex] !== undefined ? (logAverages[octaveIndex] + spectrum[specIndex]) / 2 : spectrum[specIndex];
        }
        return logAverages;
    };
    p5.FFT.prototype.getOctaveBands = function (N, fCtr0) {
        var N = N || 3;
        var fCtr0 = fCtr0 || 15.625;
        var octaveBands = [];
        var lastFrequencyBand = {
            lo: fCtr0 / Math.pow(2, 1 / (2 * N)),
            ctr: fCtr0,
            hi: fCtr0 * Math.pow(2, 1 / (2 * N))
        };
        octaveBands.push(lastFrequencyBand);
        var nyquist = p5sound.audiocontext.sampleRate / 2;
        while (lastFrequencyBand.hi < nyquist) {
            var newFrequencyBand = {};
            newFrequencyBand.lo = lastFrequencyBand.hi;
            newFrequencyBand.ctr = lastFrequencyBand.ctr * Math.pow(2, 1 / N);
            newFrequencyBand.hi = newFrequencyBand.ctr * Math.pow(2, 1 / (2 * N));
            octaveBands.push(newFrequencyBand);
            lastFrequencyBand = newFrequencyBand;
        }
        return octaveBands;
    };
    var freqToFloat = function (fft) {
        if (fft.freqDomain instanceof Float32Array === false) {
            fft.freqDomain = new Float32Array(fft.analyser.frequencyBinCount);
        }
    };
    var freqToInt = function (fft) {
        if (fft.freqDomain instanceof Uint8Array === false) {
            fft.freqDomain = new Uint8Array(fft.analyser.frequencyBinCount);
        }
    };
    var timeToFloat = function (fft) {
        if (fft.timeDomain instanceof Float32Array === false) {
            fft.timeDomain = new Float32Array(fft.analyser.frequencyBinCount);
        }
    };
    var timeToInt = function (fft) {
        if (fft.timeDomain instanceof Uint8Array === false) {
            fft.timeDomain = new Uint8Array(fft.analyser.frequencyBinCount);
        }
    };
}(master);
/**
 *  Tone.js
 *  @author Yotam Mann
 *  @license http://opensource.org/licenses/MIT MIT License
 *  @copyright 2014-2017 Yotam Mann
 */
define('Tone/core/Tone',[],function(){

	"use strict";

	///////////////////////////////////////////////////////////////////////////
	//	TONE
	///////////////////////////////////////////////////////////////////////////

	/**
	 *  @class  Tone is the base class of all other classes. It provides 
	 *          a lot of methods and functionality to all classes that extend
	 *          it. 
	 *  
	 *  @constructor
	 *  @alias Tone
	 *  @param {number} [inputs=1] the number of input nodes
	 *  @param {number} [outputs=1] the number of output nodes
	 */
	var Tone = function(inputs, outputs){

		/**
		 *  the input node(s)
		 *  @type {GainNode|Array}
		 */
		if (this.isUndef(inputs) || inputs === 1){
			this.input = this.context.createGain();
		} else if (inputs > 1){
			this.input = new Array(inputs);
		}

		/**
		 *  the output node(s)
		 *  @type {GainNode|Array}
		 */
		if (this.isUndef(outputs) || outputs === 1){
			this.output = this.context.createGain();
		} else if (outputs > 1){
			this.output = new Array(inputs);
		}
	};

	/**
	 *  Set the parameters at once. Either pass in an
	 *  object mapping parameters to values, or to set a
	 *  single parameter, by passing in a string and value.
	 *  The last argument is an optional ramp time which 
	 *  will ramp any signal values to their destination value
	 *  over the duration of the rampTime.
	 *  @param {Object|string} params
	 *  @param {number=} value
	 *  @param {Time=} rampTime
	 *  @returns {Tone} this
	 *  @example
	 * //set values using an object
	 * filter.set({
	 * 	"frequency" : 300,
	 * 	"type" : highpass
	 * });
	 *  @example
	 * filter.set("type", "highpass");
	 *  @example
	 * //ramp to the value 220 over 3 seconds. 
	 * oscillator.set({
	 * 	"frequency" : 220
	 * }, 3);
	 */
	Tone.prototype.set = function(params, value, rampTime){
		if (this.isObject(params)){
			rampTime = value;
		} else if (this.isString(params)){
			var tmpObj = {};
			tmpObj[params] = value;
			params = tmpObj;
		}

		paramLoop:
		for (var attr in params){
			value = params[attr];
			var parent = this;
			if (attr.indexOf(".") !== -1){
				var attrSplit = attr.split(".");
				for (var i = 0; i < attrSplit.length - 1; i++){
					parent = parent[attrSplit[i]];
					if (parent instanceof Tone) {
						attrSplit.splice(0,i+1);
						var innerParam = attrSplit.join(".");
						parent.set(innerParam, value);
						continue paramLoop;
					}
				}
				attr = attrSplit[attrSplit.length - 1];
			}
			var param = parent[attr];
			if (this.isUndef(param)){
				continue;
			}
			if ((Tone.Signal && param instanceof Tone.Signal) || 
					(Tone.Param && param instanceof Tone.Param)){
				if (param.value !== value){
					if (this.isUndef(rampTime)){
						param.value = value;
					} else {
						param.rampTo(value, rampTime);
					}
				}
			} else if (param instanceof AudioParam){
				if (param.value !== value){
					param.value = value;
				}				
			} else if (param instanceof Tone){
				param.set(value);
			} else if (param !== value){
				parent[attr] = value;
			}
		}
		return this;
	};

	/**
	 *  Get the object's attributes. Given no arguments get
	 *  will return all available object properties and their corresponding
	 *  values. Pass in a single attribute to retrieve or an array
	 *  of attributes. The attribute strings can also include a "."
	 *  to access deeper properties.
	 *  @example
	 * osc.get();
	 * //returns {"type" : "sine", "frequency" : 440, ...etc}
	 *  @example
	 * osc.get("type");
	 * //returns { "type" : "sine"}
	 * @example
	 * //use dot notation to access deep properties
	 * synth.get(["envelope.attack", "envelope.release"]);
	 * //returns {"envelope" : {"attack" : 0.2, "release" : 0.4}}
	 *  @param {Array=|string|undefined} params the parameters to get, otherwise will return 
	 *  					                  all available.
	 *  @returns {Object}
	 */
	Tone.prototype.get = function(params){
		if (this.isUndef(params)){
			params = this._collectDefaults(this.constructor);
		} else if (this.isString(params)){
			params = [params];
		} 
		var ret = {};
		for (var i = 0; i < params.length; i++){
			var attr = params[i];
			var parent = this;
			var subRet = ret;
			if (attr.indexOf(".") !== -1){
				var attrSplit = attr.split(".");
				for (var j = 0; j < attrSplit.length - 1; j++){
					var subAttr = attrSplit[j];
					subRet[subAttr] = subRet[subAttr] || {};
					subRet = subRet[subAttr];
					parent = parent[subAttr];
				}
				attr = attrSplit[attrSplit.length - 1];
			}
			var param = parent[attr];
			if (this.isObject(params[attr])){
				subRet[attr] = param.get();
			} else if (Tone.Signal && param instanceof Tone.Signal){
				subRet[attr] = param.value;
			} else if (Tone.Param && param instanceof Tone.Param){
				subRet[attr] = param.value;
			} else if (param instanceof AudioParam){
				subRet[attr] = param.value;
			} else if (param instanceof Tone){
				subRet[attr] = param.get();
			} else if (!this.isFunction(param) && !this.isUndef(param)){
				subRet[attr] = param;
			} 
		}
		return ret;
	};

	/**
	 *  collect all of the default attributes in one
	 *  @private
	 *  @param {function} constr the constructor to find the defaults from
	 *  @return {Array} all of the attributes which belong to the class
	 */
	Tone.prototype._collectDefaults = function(constr){
		var ret = [];
		if (!this.isUndef(constr.defaults)){
			ret = Object.keys(constr.defaults);
		}
		if (!this.isUndef(constr._super)){
			var superDefs = this._collectDefaults(constr._super);
			//filter out repeats
			for (var i = 0; i < superDefs.length; i++){
				if (ret.indexOf(superDefs[i]) === -1){
					ret.push(superDefs[i]);
				}
			}
		}
		return ret;
	};

	/**
	 *  @returns {string} returns the name of the class as a string
	 */
	Tone.prototype.toString = function(){
		for (var className in Tone){
			var isLetter = className[0].match(/^[A-Z]$/);
			var sameConstructor =  Tone[className] === this.constructor;
			if (this.isFunction(Tone[className]) && isLetter && sameConstructor){
				return className;
			}
		}
		return "Tone";
	};

	///////////////////////////////////////////////////////////////////////////
	//	CLASS VARS
	///////////////////////////////////////////////////////////////////////////

	/**
	 *  The number of inputs feeding into the AudioNode. 
	 *  For source nodes, this will be 0.
	 *  @memberOf Tone#
	 *  @name numberOfInputs
	 *  @readOnly
	 */
	Object.defineProperty(Tone.prototype, "numberOfInputs", {
		get : function(){
			if (this.input){
				if (this.isArray(this.input)){
					return this.input.length;
				} else {
					return 1;
				}
			} else {
				return 0;
			}
		}
	});

	/**
	 *  The number of outputs coming out of the AudioNode. 
	 *  For source nodes, this will be 0.
	 *  @memberOf Tone#
	 *  @name numberOfInputs
	 *  @readOnly
	 */
	Object.defineProperty(Tone.prototype, "numberOfOutputs", {
		get : function(){
			if (this.output){
				if (this.isArray(this.output)){
					return this.output.length;
				} else {
					return 1;
				}
			} else {
				return 0;
			}
		}
	});
	
	///////////////////////////////////////////////////////////////////////////
	//	CONNECTIONS
	///////////////////////////////////////////////////////////////////////////

	/**
	 *  disconnect and dispose
	 *  @returns {Tone} this
	 */
	Tone.prototype.dispose = function(){
		if (!this.isUndef(this.input)){
			if (this.input instanceof AudioNode){
				this.input.disconnect();
			} 
			this.input = null;
		}
		if (!this.isUndef(this.output)){
			if (this.output instanceof AudioNode){
				this.output.disconnect();
			} 
			this.output = null;
		}
		return this;
	};

	/**
	 *  connect the output of a ToneNode to an AudioParam, AudioNode, or ToneNode
	 *  @param  {Tone | AudioParam | AudioNode} unit 
	 *  @param {number} [outputNum=0] optionally which output to connect from
	 *  @param {number} [inputNum=0] optionally which input to connect to
	 *  @returns {Tone} this
	 */
	Tone.prototype.connect = function(unit, outputNum, inputNum){
		if (Array.isArray(this.output)){
			outputNum = this.defaultArg(outputNum, 0);
			this.output[outputNum].connect(unit, 0, inputNum);
		} else {
			this.output.connect(unit, outputNum, inputNum);
		}
		return this;
	};

	/**
	 *  disconnect the output
	 *  @param {Number|AudioNode} output Either the output index to disconnect
	 *                                   if the output is an array, or the
	 *                                   node to disconnect from.
	 *  @returns {Tone} this
	 */
	Tone.prototype.disconnect = function(destination, outputNum, inputNum){
		if (this.isArray(this.output)){
			if (this.isNumber(destination)){
				this.output[destination].disconnect();
			} else {
				outputNum = this.defaultArg(outputNum, 0);
				this.output[outputNum].disconnect(destination, 0, inputNum);
			}
		} else {
			this.output.disconnect.apply(this.output, arguments);
		}
	};

	/**
	 *  connect together all of the arguments in series
	 *  @param {...AudioParam|Tone|AudioNode} nodes
	 *  @returns {Tone} this
	 */
	Tone.prototype.connectSeries = function(){
		if (arguments.length > 1){
			var currentUnit = arguments[0];
			for (var i = 1; i < arguments.length; i++){
				var toUnit = arguments[i];
				currentUnit.connect(toUnit);
				currentUnit = toUnit;
			}
		}
		return this;
	};

	/**
	 *  Connect the output of this node to the rest of the nodes in series.
	 *  @example
	 *  //connect a node to an effect, panVol and then to the master output
	 *  node.chain(effect, panVol, Tone.Master);
	 *  @param {...AudioParam|Tone|AudioNode} nodes
	 *  @returns {Tone} this
	 */
	Tone.prototype.chain = function(){
		if (arguments.length > 0){
			var currentUnit = this;
			for (var i = 0; i < arguments.length; i++){
				var toUnit = arguments[i];
				currentUnit.connect(toUnit);
				currentUnit = toUnit;
			}
		}
		return this;
	};

	/**
	 *  connect the output of this node to the rest of the nodes in parallel.
	 *  @param {...AudioParam|Tone|AudioNode} nodes
	 *  @returns {Tone} this
	 */
	Tone.prototype.fan = function(){
		if (arguments.length > 0){
			for (var i = 0; i < arguments.length; i++){
				this.connect(arguments[i]);
			}
		}
		return this;
	};

	//give native nodes chain and fan methods
	AudioNode.prototype.chain = Tone.prototype.chain;
	AudioNode.prototype.fan = Tone.prototype.fan;

	///////////////////////////////////////////////////////////////////////////
	//	UTILITIES / HELPERS / MATHS
	///////////////////////////////////////////////////////////////////////////

	/**
	 *  If the `given` parameter is undefined, use the `fallback`. 
	 *  If both `given` and `fallback` are object literals, it will
	 *  return a deep copy which includes all of the parameters from both 
	 *  objects. If a parameter is undefined in given, it will return
	 *  the fallback property. 
	 *  <br><br>
	 *  WARNING: if object is self referential, it will go into an an 
	 *  infinite recursive loop.
	 *  
	 *  @param  {*} given    
	 *  @param  {*} fallback 
	 *  @return {*}          
	 */
	Tone.prototype.defaultArg = function(given, fallback){
		if (this.isObject(given) && this.isObject(fallback)){
			var ret = {};
			//make a deep copy of the given object
			for (var givenProp in given) {
				ret[givenProp] = this.defaultArg(fallback[givenProp], given[givenProp]);
			}
			for (var fallbackProp in fallback) {
				ret[fallbackProp] = this.defaultArg(given[fallbackProp], fallback[fallbackProp]);
			}
			return ret;
		} else {
			return this.isUndef(given) ? fallback : given;
		}
	};

	/**
	 *  returns the args as an options object with given arguments
	 *  mapped to the names provided. 
	 *
	 *  if the args given is an array containing only one object, it is assumed
	 *  that that's already the options object and will just return it. 
	 *  
	 *  @param  {Array} values  the 'arguments' object of the function
	 *  @param  {Array} keys the names of the arguments as they
	 *                                 should appear in the options object
	 *  @param {Object=} defaults optional defaults to mixin to the returned 
	 *                            options object                              
	 *  @return {Object}       the options object with the names mapped to the arguments
	 */
	Tone.prototype.optionsObject = function(values, keys, defaults){
		var options = {};
		if (values.length === 1 && this.isObject(values[0])){
			options = values[0];
		} else {
			for (var i = 0; i < keys.length; i++){
				options[keys[i]] = values[i];
			}
		}
		if (!this.isUndef(defaults)){
			return this.defaultArg(options, defaults);
		} else {
			return options;
		}
	};

	///////////////////////////////////////////////////////////////////////////
	// TYPE CHECKING
	///////////////////////////////////////////////////////////////////////////

	/**
	 *  test if the arg is undefined
	 *  @param {*} arg the argument to test
	 *  @returns {boolean} true if the arg is undefined
	 *  @function
	 */
	Tone.prototype.isUndef = function(val){
		return typeof val === "undefined";
	};

	/**
	 *  test if the arg is a function
	 *  @param {*} arg the argument to test
	 *  @returns {boolean} true if the arg is a function
	 *  @function
	 */
	Tone.prototype.isFunction = function(val){
		return typeof val === "function";
	};

	/**
	 *  Test if the argument is a number.
	 *  @param {*} arg the argument to test
	 *  @returns {boolean} true if the arg is a number
	 */
	Tone.prototype.isNumber = function(arg){
		return (typeof arg === "number");
	};

	/**
	 *  Test if the given argument is an object literal (i.e. `{}`);
	 *  @param {*} arg the argument to test
	 *  @returns {boolean} true if the arg is an object literal.
	 */
	Tone.prototype.isObject = function(arg){
		return (Object.prototype.toString.call(arg) === "[object Object]" && arg.constructor === Object);
	};

	/**
	 *  Test if the argument is a boolean.
	 *  @param {*} arg the argument to test
	 *  @returns {boolean} true if the arg is a boolean
	 */
	Tone.prototype.isBoolean = function(arg){
		return (typeof arg === "boolean");
	};

	/**
	 *  Test if the argument is an Array
	 *  @param {*} arg the argument to test
	 *  @returns {boolean} true if the arg is an array
	 */
	Tone.prototype.isArray = function(arg){
		return (Array.isArray(arg));
	};

	/**
	 *  Test if the argument is a string.
	 *  @param {*} arg the argument to test
	 *  @returns {boolean} true if the arg is a string
	 */
	Tone.prototype.isString = function(arg){
		return (typeof arg === "string");
	};

 	/**
	 *  An empty function.
	 *  @static
	 */
	Tone.noOp = function(){};

	/**
	 *  Make the property not writable. Internal use only. 
	 *  @private
	 *  @param  {string}  property  the property to make not writable
	 */
	Tone.prototype._readOnly = function(property){
		if (Array.isArray(property)){
			for (var i = 0; i < property.length; i++){
				this._readOnly(property[i]);
			}
		} else {
			Object.defineProperty(this, property, { 
				writable: false,
				enumerable : true,
			});
		}
	};

	/**
	 *  Make an attribute writeable. Interal use only. 
	 *  @private
	 *  @param  {string}  property  the property to make writable
	 */
	Tone.prototype._writable = function(property){
		if (Array.isArray(property)){
			for (var i = 0; i < property.length; i++){
				this._writable(property[i]);
			}
		} else {
			Object.defineProperty(this, property, { 
				writable: true,
			});
		}
	};

	/**
	 * Possible play states. 
	 * @enum {string}
	 */
	Tone.State = {
		Started : "started",
		Stopped : "stopped",
		Paused : "paused",
 	};

	///////////////////////////////////////////////////////////////////////////
	// CONVERSIONS
	///////////////////////////////////////////////////////////////////////////

	/**
	 *  Equal power gain scale. Good for cross-fading.
	 *  @param  {NormalRange} percent (0-1)
	 *  @return {Number}         output gain (0-1)
	 */
	Tone.prototype.equalPowerScale = function(percent){
		var piFactor = 0.5 * Math.PI;
		return Math.sin(percent * piFactor);
	};

	/**
	 *  Convert decibels into gain.
	 *  @param  {Decibels} db
	 *  @return {Number}   
	 */
	Tone.prototype.dbToGain = function(db) {
		return Math.pow(2, db / 6);
	};

	/**
	 *  Convert gain to decibels.
	 *  @param  {Number} gain (0-1)
	 *  @return {Decibels}   
	 */
	Tone.prototype.gainToDb = function(gain) {
		return  20 * (Math.log(gain) / Math.LN10);
	};

	/**
	 *  Convert an interval (in semitones) to a frequency ratio.
	 *  @param  {Interval} interval the number of semitones above the base note
	 *  @return {number}          the frequency ratio
	 *  @example
	 * tone.intervalToFrequencyRatio(0); // 1
	 * tone.intervalToFrequencyRatio(12); // 2
	 * tone.intervalToFrequencyRatio(-12); // 0.5
	 */
	Tone.prototype.intervalToFrequencyRatio = function(interval){
		return Math.pow(2,(interval/12));
	};

	///////////////////////////////////////////////////////////////////////////
	//	TIMING
	///////////////////////////////////////////////////////////////////////////

	/**
	 *  Return the current time of the AudioContext clock.
	 *  @return {Number} the currentTime from the AudioContext
	 */
	Tone.prototype.now = function(){
		return Tone.context.now();
	};

	/**
	 *  Return the current time of the AudioContext clock.
	 *  @return {Number} the currentTime from the AudioContext
	 *  @static
	 */
	Tone.now = function(){
		return Tone.context.now();
	};

	///////////////////////////////////////////////////////////////////////////
	//	INHERITANCE
	///////////////////////////////////////////////////////////////////////////

	/**
	 *  have a child inherit all of Tone's (or a parent's) prototype
	 *  to inherit the parent's properties, make sure to call 
	 *  Parent.call(this) in the child's constructor
	 *
	 *  based on closure library's inherit function
	 *
	 *  @static
	 *  @param  {function} 	child  
	 *  @param  {function=} parent (optional) parent to inherit from
	 *                             if no parent is supplied, the child
	 *                             will inherit from Tone
	 */
	Tone.extend = function(child, parent){
		if (Tone.prototype.isUndef(parent)){
			parent = Tone;
		}
		function TempConstructor(){}
		TempConstructor.prototype = parent.prototype;
		child.prototype = new TempConstructor();
		/** @override */
		child.prototype.constructor = child;
		child._super = parent;
	};

	///////////////////////////////////////////////////////////////////////////
	//	CONTEXT
	///////////////////////////////////////////////////////////////////////////

	/**
	 *  The private audio context shared by all Tone Nodes. 
	 *  @private
	 *  @type {Tone.Context|undefined}
	 */
	var audioContext;

	/**
	 *  A static pointer to the audio context accessible as Tone.context. 
	 *  @type {Tone.Context}
	 *  @name context
	 *  @memberOf Tone
	 */
	Object.defineProperty(Tone, "context", {
		get : function(){
			return audioContext;
		},
		set : function(context){
			if (Tone.Context && context instanceof Tone.Context){
				audioContext = context;
			} else {
				audioContext = new Tone.Context(context);
			}
			//initialize the new audio context
			if (Tone.Context){
				Tone.Context.emit("init", audioContext);
			}
		}
	});

	/**
	 *  The AudioContext
	 *  @type {Tone.Context}
	 *  @name context
	 *  @memberOf Tone#
	 *  @readOnly
	 */
	Object.defineProperty(Tone.prototype, "context", {
		get : function(){
			return Tone.context;
		}
	});

	/**
	 *  Tone automatically creates a context on init, but if you are working
	 *  with other libraries which also create an AudioContext, it can be
	 *  useful to set your own. If you are going to set your own context, 
	 *  be sure to do it at the start of your code, before creating any objects.
	 *  @static
	 *  @param {AudioContext} ctx The new audio context to set
	 */
	Tone.setContext = function(ctx){
		Tone.context = ctx;
	};

	/**
	 *  The number of seconds of 1 processing block (128 samples)
	 *  @type {Number}
	 *  @name blockTime
	 *  @memberOf Tone#
	 *  @readOnly
	 */
	Object.defineProperty(Tone.prototype, "blockTime", {
		get : function(){
			return 128 / this.context.sampleRate;
		}
	});

	/**
	 *  The duration in seconds of one sample.
	 *  @type {Number}
	 *  @name sampleTime
	 *  @memberOf Tone#
	 *  @readOnly
	 */
	Object.defineProperty(Tone.prototype, "sampleTime", {
		get : function(){
			return 1 / this.context.sampleRate;
		}
	});

	/**
	 *  Whether or not all the technologies that Tone.js relies on are supported by the current browser. 
	 *  @type {Boolean}
	 *  @name supported
	 *  @memberOf Tone
	 *  @readOnly
	 */
	Object.defineProperty(Tone, "supported", {
		get : function(){
			var hasAudioContext = window.hasOwnProperty("AudioContext") || window.hasOwnProperty("webkitAudioContext");
			var hasPromises = window.hasOwnProperty("Promise");
			var hasWorkers = window.hasOwnProperty("Worker");
			return hasAudioContext && hasPromises && hasWorkers;
		}
	});

	Tone.version = "r10";

	// allow optional silencing of this log
	if (!window.TONE_SILENCE_VERSION_LOGGING) {
		
	}

	return Tone;
});

define('Tone/signal/SignalBase',["Tone/core/Tone"], function(Tone){

	"use strict";

	/**
	 *  @class  Base class for all Signals. Used Internally. 
	 *
	 *  @constructor
	 *  @extends {Tone}
	 */
	Tone.SignalBase = function(){};

	Tone.extend(Tone.SignalBase);

	/**
	 *  When signals connect to other signals or AudioParams, 
	 *  they take over the output value of that signal or AudioParam. 
	 *  For all other nodes, the behavior is the same as a default <code>connect</code>. 
	 *
	 *  @override
	 *  @param {AudioParam|AudioNode|Tone.Signal|Tone} node 
	 *  @param {number} [outputNumber=0] The output number to connect from.
	 *  @param {number} [inputNumber=0] The input number to connect to.
	 *  @returns {Tone.SignalBase} this
	 */
	Tone.SignalBase.prototype.connect = function(node, outputNumber, inputNumber){
		//zero it out so that the signal can have full control
		if ((Tone.Signal && Tone.Signal === node.constructor) || 
				(Tone.Param && Tone.Param === node.constructor) || 
				(Tone.TimelineSignal && Tone.TimelineSignal === node.constructor)){
			//cancel changes
			node._param.cancelScheduledValues(0);
			//reset the value
			node._param.value = 0;
			//mark the value as overridden
			node.overridden = true;
		} else if (node instanceof AudioParam){
			node.cancelScheduledValues(0);
			node.value = 0;
		} 
		Tone.prototype.connect.call(this, node, outputNumber, inputNumber);
		return this;
	};

	return Tone.SignalBase;
});
define('Tone/signal/WaveShaper',["Tone/core/Tone", "Tone/signal/SignalBase"], function(Tone){

	"use strict";

	/**
	 *  @class Wraps the native Web Audio API 
	 *         [WaveShaperNode](http://webaudio.github.io/web-audio-api/#the-waveshapernode-interface).
	 *
	 *  @extends {Tone.SignalBase}
	 *  @constructor
	 *  @param {function|Array|Number} mapping The function used to define the values. 
	 *                                    The mapping function should take two arguments: 
	 *                                    the first is the value at the current position 
	 *                                    and the second is the array position. 
	 *                                    If the argument is an array, that array will be
	 *                                    set as the wave shaping function. The input
	 *                                    signal is an AudioRange [-1, 1] value and the output
	 *                                    signal can take on any numerical values. 
	 *                                    
	 *  @param {Number} [bufferLen=1024] The length of the WaveShaperNode buffer.
	 *  @example
	 * var timesTwo = new Tone.WaveShaper(function(val){
	 * 	return val * 2;
	 * }, 2048);
	 *  @example
	 * //a waveshaper can also be constructed with an array of values
	 * var invert = new Tone.WaveShaper([1, -1]);
	 */
	Tone.WaveShaper = function(mapping, bufferLen){

		/**
		 *  the waveshaper
		 *  @type {WaveShaperNode}
		 *  @private
		 */
		this._shaper = this.input = this.output = this.context.createWaveShaper();

		/**
		 *  the waveshapers curve
		 *  @type {Float32Array}
		 *  @private
		 */
		this._curve = null;

		if (Array.isArray(mapping)){
			this.curve = mapping;
		} else if (isFinite(mapping) || this.isUndef(mapping)){
			this._curve = new Float32Array(this.defaultArg(mapping, 1024));
		} else if (this.isFunction(mapping)){
			this._curve = new Float32Array(this.defaultArg(bufferLen, 1024));
			this.setMap(mapping);
		} 
	};

	Tone.extend(Tone.WaveShaper, Tone.SignalBase);

	/**
	 *  Uses a mapping function to set the value of the curve. 
	 *  @param {function} mapping The function used to define the values. 
	 *                            The mapping function take two arguments: 
	 *                            the first is the value at the current position 
	 *                            which goes from -1 to 1 over the number of elements
	 *                            in the curve array. The second argument is the array position. 
	 *  @returns {Tone.WaveShaper} this
	 *  @example
	 * //map the input signal from [-1, 1] to [0, 10]
	 * shaper.setMap(function(val, index){
	 * 	return (val + 1) * 5;
	 * })
	 */
	Tone.WaveShaper.prototype.setMap = function(mapping){
		for (var i = 0, len = this._curve.length; i < len; i++){
			var normalized = (i / (len - 1)) * 2 - 1;
			this._curve[i] = mapping(normalized, i);
		}
		this._shaper.curve = this._curve;
		return this;
	};

	/**
	 * The array to set as the waveshaper curve. For linear curves
	 * array length does not make much difference, but for complex curves
	 * longer arrays will provide smoother interpolation. 
	 * @memberOf Tone.WaveShaper#
	 * @type {Array}
	 * @name curve
	 */
	Object.defineProperty(Tone.WaveShaper.prototype, "curve", {
		get : function(){
			return this._shaper.curve;
		},
		set : function(mapping){
			this._curve = new Float32Array(mapping);
			this._shaper.curve = this._curve;
		}
	});

	/**
	 * Specifies what type of oversampling (if any) should be used when 
	 * applying the shaping curve. Can either be "none", "2x" or "4x". 
	 * @memberOf Tone.WaveShaper#
	 * @type {string}
	 * @name oversample
	 */
	Object.defineProperty(Tone.WaveShaper.prototype, "oversample", {
		get : function(){
			return this._shaper.oversample;
		},
		set : function(oversampling){
			if (["none", "2x", "4x"].indexOf(oversampling) !== -1){
				this._shaper.oversample = oversampling;
			} else {
				throw new RangeError("Tone.WaveShaper: oversampling must be either 'none', '2x', or '4x'");
			}
		}
	});

	/**
	 *  Clean up.
	 *  @returns {Tone.WaveShaper} this
	 */
	Tone.WaveShaper.prototype.dispose = function(){
		Tone.prototype.dispose.call(this);
		this._shaper.disconnect();
		this._shaper = null;
		this._curve = null;
		return this;
	};

	return Tone.WaveShaper;
});
define('Tone/type/TimeBase',["Tone/core/Tone"], function (Tone) {

	/**
	 *  @class Tone.TimeBase is a flexible encoding of time
	 *         which can be evaluated to and from a string.
	 *         Parsing code modified from https://code.google.com/p/tapdigit/
	 *         Copyright 2011 2012 Ariya Hidayat, New BSD License
	 *  @extends {Tone}
	 *  @param  {Time}  val    The time value as a number or string
	 *  @param  {String=}  units  Unit values
	 *  @example
	 * Tone.TimeBase(4, "n")
	 * Tone.TimeBase(2, "t")
	 * Tone.TimeBase("2t").add("1m")
	 * Tone.TimeBase("2t + 1m");
	 */
	Tone.TimeBase = function(val, units){

		//allows it to be constructed with or without 'new'
		if (this instanceof Tone.TimeBase) {

			/**
			 *  Any expressions parsed from the Time
			 *  @type  {Array}
			 *  @private
			 */
			this._expr = this._noOp;

			if (val instanceof Tone.TimeBase){
				this.copy(val);
			} else if (!this.isUndef(units) || this.isNumber(val)){
				//default units
				units = this.defaultArg(units, this._defaultUnits);
				var method = this._primaryExpressions[units].method;
				this._expr = method.bind(this, val);
			} else if (this.isString(val)){
				this.set(val);
			} else if (this.isUndef(val)){
				//default expression
				this._expr = this._defaultExpr();
			}
		} else {

			return new Tone.TimeBase(val, units);
		}
	};

	Tone.extend(Tone.TimeBase);

	/**
	 *  Repalce the current time value with the value
	 *  given by the expression string.
	 *  @param  {String}  exprString
	 *  @return {Tone.TimeBase} this
	 */
	Tone.TimeBase.prototype.set = function(exprString){
		this._expr = this._parseExprString(exprString);
		return this;
	};

	/**
	 *  Return a clone of the TimeBase object.
	 *  @return  {Tone.TimeBase} The new cloned Tone.TimeBase
	 */
	Tone.TimeBase.prototype.clone = function(){
		var instance = new this.constructor();
		instance.copy(this);
		return instance;
	};

	/**
	 *  Copies the value of time to this Time
	 *  @param {Tone.TimeBase} time
	 *  @return  {TimeBase}
	 */
	Tone.TimeBase.prototype.copy = function(time){
		var val = time._expr();
		return this.set(val);
	};

	///////////////////////////////////////////////////////////////////////////
	//	ABSTRACT SYNTAX TREE PARSER
	///////////////////////////////////////////////////////////////////////////

	/**
	 *  All the primary expressions.
	 *  @private
	 *  @type  {Object}
	 */
	Tone.TimeBase.prototype._primaryExpressions = {
		"n" : {
			regexp : /^(\d+)n/i,
			method : function(value){
				value = parseInt(value);
				if (value === 1){
					return this._beatsToUnits(this._timeSignature());
				} else {
					return this._beatsToUnits(4 / value);
				}
			}
		},
		"t" : {
			regexp : /^(\d+)t/i,
			method : function(value){
				value = parseInt(value);
				return this._beatsToUnits(8 / (parseInt(value) * 3));
			}
		},
		"m" : {
			regexp : /^(\d+)m/i,
			method : function(value){
				return this._beatsToUnits(parseInt(value) * this._timeSignature());
			}
		},
		"i" : {
			regexp : /^(\d+)i/i,
			method : function(value){
				return this._ticksToUnits(parseInt(value));
			}
		},
		"hz" : {
			regexp : /^(\d+(?:\.\d+)?)hz/i,
			method : function(value){
				return this._frequencyToUnits(parseFloat(value));
			}
		},
		"tr" : {
			regexp : /^(\d+(?:\.\d+)?):(\d+(?:\.\d+)?):?(\d+(?:\.\d+)?)?/,
			method : function(m, q, s){
				var total = 0;
				if (m && m !== "0"){
					total += this._beatsToUnits(this._timeSignature() * parseFloat(m));
				}
				if (q && q !== "0"){
					total += this._beatsToUnits(parseFloat(q));
				}
				if (s && s !== "0"){
					total += this._beatsToUnits(parseFloat(s) / 4);
				}
				return total;
			}
		},
		"s" : {
			regexp : /^(\d+(?:\.\d+)?s)/,
			method : function(value){
				return this._secondsToUnits(parseFloat(value));
			}
		},
		"samples" : {
			regexp : /^(\d+)samples/,
			method : function(value){
				return parseInt(value) / this.context.sampleRate;
			}
		},
		"default" : {
			regexp : /^(\d+(?:\.\d+)?)/,
			method : function(value){
				return this._primaryExpressions[this._defaultUnits].method.call(this, value);
			}
		}
	};

	/**
	 *  All the binary expressions that TimeBase can accept.
	 *  @private
	 *  @type  {Object}
	 */
	Tone.TimeBase.prototype._binaryExpressions = {
		"+" : {
			regexp : /^\+/,
			precedence : 2,
			method : function(lh, rh){
				return lh() + rh();
			}
		},
		"-" : {
			regexp : /^\-/,
			precedence : 2,
			method : function(lh, rh){
				return lh() - rh();
			}
		},
		"*" : {
			regexp : /^\*/,
			precedence : 1,
			method : function(lh, rh){
				return lh() * rh();
			}
		},
		"/" : {
			regexp : /^\//,
			precedence : 1,
			method : function(lh, rh){
				return lh() / rh();
			}
		}
	};

	/**
	 *  All the unary expressions.
	 *  @private
	 *  @type  {Object}
	 */
	Tone.TimeBase.prototype._unaryExpressions = {
		"neg" : {
			regexp : /^\-/,
			method : function(lh){
				return -lh();
			}
		}
	};

	/**
	 *  Syntactic glue which holds expressions together
	 *  @private
	 *  @type  {Object}
	 */
	Tone.TimeBase.prototype._syntaxGlue = {
		"(" : {
			regexp : /^\(/
		},
		")" : {
			regexp : /^\)/
		}
	};

	/**
	 *  tokenize the expression based on the Expressions object
	 *  @param   {string} expr 
	 *  @return  {Object}      returns two methods on the tokenized list, next and peek
	 *  @private
	 */
	Tone.TimeBase.prototype._tokenize = function(expr){
		var position = -1;
		var tokens = [];

		while(expr.length > 0){
			expr = expr.trim();
			var token = getNextToken(expr, this);
			tokens.push(token);
			expr = expr.substr(token.value.length);
		}

		function getNextToken(expr, context){
			var expressions = ["_binaryExpressions", "_unaryExpressions", "_primaryExpressions", "_syntaxGlue"];
			for (var i = 0; i < expressions.length; i++){
				var group = context[expressions[i]];
				for (var opName in group){
					var op = group[opName];
					var reg = op.regexp;
					var match = expr.match(reg);
					if (match !== null){
						return {
							method : op.method,
							precedence : op.precedence,
							regexp : op.regexp,
							value : match[0],
						};
					}
				}
			}
			throw new SyntaxError("Tone.TimeBase: Unexpected token "+expr);
		}

		return {
			next : function(){
				return tokens[++position];
			},
			peek : function(){
				return tokens[position + 1];
			}
		};
	};

	/**
	 *  Given a token, find the value within the groupName
	 *  @param {Object} token
	 *  @param {String} groupName
	 *  @param {Number} precedence
	 *  @private
	 */
	Tone.TimeBase.prototype._matchGroup = function(token, group, prec) {
		var ret = false;
		if (!this.isUndef(token)){
			for (var opName in group){
				var op = group[opName];
				if (op.regexp.test(token.value)){
					if (!this.isUndef(prec)){
						if(op.precedence === prec){	
							return op;
						}
					} else {
						return op;
					}
				}
			}
		}
		return ret;
	};

	/**
	 *  Match a binary expression given the token and the precedence
	 *  @param {Lexer} lexer
	 *  @param {Number} precedence
	 *  @private
	 */
	Tone.TimeBase.prototype._parseBinary = function(lexer, precedence){
		if (this.isUndef(precedence)){
			precedence = 2;
		}
		var expr;
		if (precedence < 0){
			expr = this._parseUnary(lexer);
		} else {
			expr = this._parseBinary(lexer, precedence - 1);
		}
		var token = lexer.peek();
		while (token && this._matchGroup(token, this._binaryExpressions, precedence)){
			token = lexer.next();
			expr = token.method.bind(this, expr, this._parseBinary(lexer, precedence - 1));
			token = lexer.peek();
		}
		return expr;
	};

	/**
	 *  Match a unary expression.
	 *  @param {Lexer} lexer
	 *  @private
	 */
	Tone.TimeBase.prototype._parseUnary = function(lexer){
		var token, expr;
		token = lexer.peek();
		var op = this._matchGroup(token, this._unaryExpressions);
		if (op) {
			token = lexer.next();
			expr = this._parseUnary(lexer);
			return op.method.bind(this, expr);
		}
		return this._parsePrimary(lexer);
	};

	/**
	 *  Match a primary expression (a value).
	 *  @param {Lexer} lexer
	 *  @private
	 */
	Tone.TimeBase.prototype._parsePrimary = function(lexer){
		var token, expr;
		token = lexer.peek();
		if (this.isUndef(token)) {
			throw new SyntaxError("Tone.TimeBase: Unexpected end of expression");
		}
		if (this._matchGroup(token, this._primaryExpressions)) {
			token = lexer.next();
			var matching = token.value.match(token.regexp);
			return token.method.bind(this, matching[1], matching[2], matching[3]);
		}
		if (token && token.value === "("){
			lexer.next();
			expr = this._parseBinary(lexer);
			token = lexer.next();
			if (!(token && token.value === ")")) {
				throw new SyntaxError("Expected )");
			}
			return expr;
		}
		throw new SyntaxError("Tone.TimeBase: Cannot process token " + token.value);
	};

	/**
	 *  Recursively parse the string expression into a syntax tree.
	 *  @param   {string} expr 
	 *  @return  {Function} the bound method to be evaluated later
	 *  @private
	 */
	Tone.TimeBase.prototype._parseExprString = function(exprString){
		if (!this.isString(exprString)){
			exprString = exprString.toString();
		}
		var lexer = this._tokenize(exprString);
		var tree = this._parseBinary(lexer);
		return tree;
	};

	///////////////////////////////////////////////////////////////////////////
	//	DEFAULTS
	///////////////////////////////////////////////////////////////////////////

	/**
	 *  The initial expression value
	 *  @return  {Number}  The initial value 0
	 *  @private
	 */
	Tone.TimeBase.prototype._noOp = function(){
		return 0;
	};

	/**
	 *  The default expression value if no arguments are given
	 *  @private
	 */
	Tone.TimeBase.prototype._defaultExpr = function(){
		return this._noOp;
	};

	/**
	 *  The default units if none are given.
	 *  @private
	 */
	Tone.TimeBase.prototype._defaultUnits = "s";

	///////////////////////////////////////////////////////////////////////////
	//	UNIT CONVERSIONS
	///////////////////////////////////////////////////////////////////////////

	/**
	 *  Returns the value of a frequency in the current units
	 *  @param {Frequency} freq
	 *  @return  {Number}
	 *  @private
	 */
	Tone.TimeBase.prototype._frequencyToUnits = function(freq){
		return 1/freq;
	};

	/**
	 *  Return the value of the beats in the current units
	 *  @param {Number} beats
	 *  @return  {Number}
	 *  @private
	 */
	Tone.TimeBase.prototype._beatsToUnits = function(beats){
		return (60 / Tone.Transport.bpm.value) * beats;
	};

	/**
	 *  Returns the value of a second in the current units
	 *  @param {Seconds} seconds
	 *  @return  {Number}
	 *  @private
	 */
	Tone.TimeBase.prototype._secondsToUnits = function(seconds){
		return seconds;
	};

	/**
	 *  Returns the value of a tick in the current time units
	 *  @param {Ticks} ticks
	 *  @return  {Number}
	 *  @private
	 */
	Tone.TimeBase.prototype._ticksToUnits = function(ticks){
		return ticks * (this._beatsToUnits(1) / Tone.Transport.PPQ);
	};

	/**
	 *  Return the time signature.
	 *  @return  {Number}
	 *  @private
	 */
	Tone.TimeBase.prototype._timeSignature = function(){
		return Tone.Transport.timeSignature;
	};

	///////////////////////////////////////////////////////////////////////////
	//	EXPRESSIONS
	///////////////////////////////////////////////////////////////////////////

	/**
	 *  Push an expression onto the expression list
	 *  @param  {Time}  val
	 *  @param  {String}  type
	 *  @param  {String}  units
	 *  @return  {Tone.TimeBase} 
	 *  @private
	 */
	Tone.TimeBase.prototype._pushExpr = function(val, name, units){
		//create the expression
		if (!(val instanceof Tone.TimeBase)){
			val = new this.constructor(val, units);
		}
		this._expr = this._binaryExpressions[name].method.bind(this, this._expr, val._expr);
		return this;
	};

	/**
	 *  Add to the current value.
	 *  @param  {Time}  val    The value to add
	 *  @param  {String=}  units  Optional units to use with the value.
	 *  @return  {Tone.TimeBase}  this
	 *  @example
	 * Tone.TimeBase("2m").add("1m"); //"3m"
	 */
	Tone.TimeBase.prototype.add = function(val, units){
		return this._pushExpr(val, "+", units);
	};

	/**
	 *  Subtract the value from the current time.
	 *  @param  {Time}  val    The value to subtract
	 *  @param  {String=}  units  Optional units to use with the value.
	 *  @return  {Tone.TimeBase}  this
	 *  @example
	 * Tone.TimeBase("2m").sub("1m"); //"1m"
	 */
	Tone.TimeBase.prototype.sub = function(val, units){
		return this._pushExpr(val, "-", units);
	};

	/**
	 *  Multiply the current value by the given time.
	 *  @param  {Time}  val    The value to multiply
	 *  @param  {String=}  units  Optional units to use with the value.
	 *  @return  {Tone.TimeBase}  this
	 *  @example
	 * Tone.TimeBase("2m").mult("2"); //"4m"
	 */
	Tone.TimeBase.prototype.mult = function(val, units){
		return this._pushExpr(val, "*", units);
	};

	/**
	 *  Divide the current value by the given time.
	 *  @param  {Time}  val    The value to divide by
	 *  @param  {String=}  units  Optional units to use with the value.
	 *  @return  {Tone.TimeBase}  this
	 *  @example
	 * Tone.TimeBase("2m").div(2); //"1m"
	 */
	Tone.TimeBase.prototype.div = function(val, units){
		return this._pushExpr(val, "/", units);
	};

	/**
	 *  Evaluate the time value. Returns the time
	 *  in seconds.
	 *  @return  {Seconds} 
	 */
	Tone.TimeBase.prototype.valueOf = function(){
		return this._expr();
	};

	/**
	 *  Clean up
	 *  @return {Tone.TimeBase} this
	 */
	Tone.TimeBase.prototype.dispose = function(){
		this._expr = null;
	};

	return Tone.TimeBase;
});
define('Tone/type/Time',["Tone/core/Tone", "Tone/type/TimeBase"], function (Tone) {

	/**
	 *  @class Tone.Time is a primitive type for encoding Time values. 
	 *         Eventually all time values are evaluated to seconds
	 *         using the `eval` method. Tone.Time can be constructed
	 *         with or without the `new` keyword. Tone.Time can be passed
	 *         into the parameter of any method which takes time as an argument. 
	 *  @constructor
	 *  @extends {Tone.TimeBase}
	 *  @param  {String|Number}  val    The time value.
	 *  @param  {String=}  units  The units of the value.
	 *  @example
	 * var t = Tone.Time("4n");//encodes a quarter note
	 * t.mult(4); // multiply that value by 4
	 * t.toNotation(); //returns "1m"
	 */
	Tone.Time = function(val, units){
		if (this instanceof Tone.Time){

			/**
			 *  If the current clock time should
			 *  be added to the output
			 *  @type  {Boolean}
			 *  @private
			 */
			this._plusNow = false;
			
			Tone.TimeBase.call(this, val, units);

		} else {
			return new Tone.Time(val, units);
		}
	};

	Tone.extend(Tone.Time, Tone.TimeBase);

	//clone the expressions so that 
	//we can add more without modifying the original
	Tone.Time.prototype._unaryExpressions = Object.create(Tone.TimeBase.prototype._unaryExpressions);

	/*
	 *  Adds an additional unary expression
	 *  which quantizes values to the next subdivision
	 *  @type {Object}
	 *  @private
	 */
	Tone.Time.prototype._unaryExpressions.quantize = {
		regexp : /^@/,
		method : function(rh){
			return Tone.Transport.nextSubdivision(rh());
		}
	};

	/*
	 *  Adds an additional unary expression
	 *  which adds the current clock time.
	 *  @type {Object}
	 *  @private
	 */
	Tone.Time.prototype._unaryExpressions.now = {
		regexp : /^\+/,
		method : function(lh){
			this._plusNow = true;
			return lh();
		}
	};

	/**
	 *  Quantize the time by the given subdivision. Optionally add a
	 *  percentage which will move the time value towards the ideal
	 *  quantized value by that percentage. 
	 *  @param  {Number|Time}  val    The subdivision to quantize to
	 *  @param  {NormalRange}  [percent=1]  Move the time value
	 *                                   towards the quantized value by
	 *                                   a percentage.
	 *  @return  {Tone.Time}  this
	 *  @example
	 * Tone.Time(21).quantize(2) //returns 22
	 * Tone.Time(0.6).quantize("4n", 0.5) //returns 0.55
	 */
	Tone.Time.prototype.quantize = function(subdiv, percent){
		percent = this.defaultArg(percent, 1);
		this._expr = function(expr, subdivision, percent){
			expr = expr();
			subdivision = subdivision.toSeconds();
			var multiple = Math.round(expr / subdivision);
			var ideal = multiple * subdivision;
			var diff = ideal - expr;
			return expr + diff * percent;
		}.bind(this, this._expr, new this.constructor(subdiv), percent);
		return this;
	};

	/**
	 *  Adds the clock time to the time expression at the 
	 *  moment of evaluation. 
	 *  @return  {Tone.Time}  this
	 */
	Tone.Time.prototype.addNow = function(){
		this._plusNow = true;
		return this;
	};

	/**
	 *  @override
	 *  Override the default value return when no arguments are passed in.
	 *  The default value is 'now'
	 *  @private
	 */
	Tone.Time.prototype._defaultExpr = function(){
		this._plusNow = true;
		return this._noOp;
	};

	/**
	 *  Copies the value of time to this Time
	 *  @param {Tone.Time} time
	 *  @return  {Time}
	 */
	Tone.Time.prototype.copy = function(time){
		Tone.TimeBase.prototype.copy.call(this, time);
		this._plusNow = time._plusNow;
		return this;
	};

	//CONVERSIONS//////////////////////////////////////////////////////////////

	/**
	 *  Convert a Time to Notation. Values will be thresholded to the nearest 128th note. 
	 *  @return {Notation} 
	 *  @example
	 * //if the Transport is at 120bpm:
	 * Tone.Time(2).toNotation();//returns "1m"
	 */
	Tone.Time.prototype.toNotation = function(){
		var time = this.toSeconds();
		var testNotations = ["1m", "2n", "4n", "8n", "16n", "32n", "64n", "128n"];
		var retNotation = this._toNotationHelper(time, testNotations);
		//try the same thing but with tripelets
		var testTripletNotations = ["1m", "2n", "2t", "4n", "4t", "8n", "8t", "16n", "16t", "32n", "32t", "64n", "64t", "128n"];
		var retTripletNotation = this._toNotationHelper(time, testTripletNotations);
		//choose the simpler expression of the two
		if (retTripletNotation.split("+").length < retNotation.split("+").length){
			return retTripletNotation;
		} else {
			return retNotation;
		}
	};

	/**
	 *  Helper method for Tone.toNotation
	 *  @param {Number} units 
	 *  @param {Array} testNotations
	 *  @return {String}
	 *  @private
	 */
	Tone.Time.prototype._toNotationHelper = function(units, testNotations){
		//the threshold is the last value in the array
		var threshold = this._notationToUnits(testNotations[testNotations.length - 1]);
		var retNotation = "";
		for (var i = 0; i < testNotations.length; i++){
			var notationTime = this._notationToUnits(testNotations[i]);
			//account for floating point errors (i.e. round up if the value is 0.999999)
			var multiple = units / notationTime;
			var floatingPointError = 0.000001;
			if (1 - multiple % 1 < floatingPointError){
				multiple += floatingPointError;
			}
			multiple = Math.floor(multiple);
			if (multiple > 0){
				if (multiple === 1){
					retNotation += testNotations[i];
				} else {
					retNotation += multiple.toString() + "*" + testNotations[i];
				}
				units -= multiple * notationTime;
				if (units < threshold){
					break;
				} else {
					retNotation += " + ";
				}
			}
		}
		if (retNotation === ""){
			retNotation = "0";
		}
		return retNotation;
	};

	/**
	 *  Convert a notation value to the current units
	 *  @param  {Notation}  notation 
	 *  @return  {Number} 
	 *  @private
	 */
	Tone.Time.prototype._notationToUnits = function(notation){
		var primaryExprs = this._primaryExpressions;
		var notationExprs = [primaryExprs.n, primaryExprs.t, primaryExprs.m];
		for (var i = 0; i < notationExprs.length; i++){
			var expr = notationExprs[i];
			var match = notation.match(expr.regexp);
			if (match){
				return expr.method.call(this, match[1]);
			}
		}
	};

	/**
	 *  Return the time encoded as Bars:Beats:Sixteenths.
	 *  @return  {BarsBeatsSixteenths}
	 */
	Tone.Time.prototype.toBarsBeatsSixteenths = function(){
		var quarterTime = this._beatsToUnits(1);
		var quarters = this.toSeconds() / quarterTime;
		var measures = Math.floor(quarters / this._timeSignature());
		var sixteenths = (quarters % 1) * 4;
		quarters = Math.floor(quarters) % this._timeSignature();
		sixteenths = sixteenths.toString();
		if (sixteenths.length > 3){
			sixteenths = parseFloat(sixteenths).toFixed(3);
		}
		var progress = [measures, quarters, sixteenths];
		return progress.join(":");
	};

	/**
	 *  Return the time in ticks.
	 *  @return  {Ticks}
	 */
	Tone.Time.prototype.toTicks = function(){
		var quarterTime = this._beatsToUnits(1);
		var quarters = this.valueOf() / quarterTime;
		return Math.floor(quarters * Tone.Transport.PPQ);
	};

	/**
	 *  Return the time in samples
	 *  @return  {Samples}  
	 */
	Tone.Time.prototype.toSamples = function(){
		return this.toSeconds() * this.context.sampleRate;
	};

	/**
	 *  Return the time as a frequency value
	 *  @return  {Frequency} 
	 *  @example
	 * Tone.Time(2).toFrequency(); //0.5
	 */
	Tone.Time.prototype.toFrequency = function(){
		return 1/this.toSeconds();
	};

	/**
	 *  Return the time in seconds.
	 *  @return  {Seconds} 
	 */
	Tone.Time.prototype.toSeconds = function(){
		return this.valueOf();
	};

	/**
	 *  Return the time in milliseconds.
	 *  @return  {Milliseconds} 
	 */
	Tone.Time.prototype.toMilliseconds = function(){
		return this.toSeconds() * 1000;
	};

	/**
	 *  Return the time in seconds.
	 *  @return  {Seconds} 
	 */
	Tone.Time.prototype.valueOf = function(){
		var val = this._expr();
		return val + (this._plusNow?this.now():0);
	};

	return Tone.Time;
});
define('Tone/type/Frequency',["Tone/core/Tone", "Tone/type/TimeBase"], function (Tone) {

	/**
	 *  @class Tone.Frequency is a primitive type for encoding Frequency values. 
	 *         Eventually all time values are evaluated to hertz
	 *         using the `eval` method. 
	 *  @constructor
	 *  @extends {Tone.TimeBase}
	 *  @param  {String|Number}  val    The time value.
	 *  @param  {String=}  units  The units of the value.
	 *  @example
	 * Tone.Frequency("C3") // 261
	 * Tone.Frequency(38, "midi") //
	 * Tone.Frequency("C3").transpose(4);
	 */
	Tone.Frequency = function(val, units){
		if (this instanceof Tone.Frequency){
			
			Tone.TimeBase.call(this, val, units);

		} else {
			return new Tone.Frequency(val, units);
		}
	};

	Tone.extend(Tone.Frequency, Tone.TimeBase);

	///////////////////////////////////////////////////////////////////////////
	//	AUGMENT BASE EXPRESSIONS
	///////////////////////////////////////////////////////////////////////////

	//clone the expressions so that 
	//we can add more without modifying the original
	Tone.Frequency.prototype._primaryExpressions = Object.create(Tone.TimeBase.prototype._primaryExpressions);

	/*
	 *  midi type primary expression
	 *  @type {Object}
	 *  @private
	 */
	Tone.Frequency.prototype._primaryExpressions.midi = {
		regexp : /^(\d+(?:\.\d+)?midi)/,
		method : function(value){
			return this.midiToFrequency(value);
		}	
	};

	/*
	 *  note type primary expression
	 *  @type {Object}
	 *  @private
	 */
	Tone.Frequency.prototype._primaryExpressions.note = {
		regexp : /^([a-g]{1}(?:b|#|x|bb)?)(-?[0-9]+)/i,
		method : function(pitch, octave){
			var index = noteToScaleIndex[pitch.toLowerCase()];
			var noteNumber = index + (parseInt(octave) + 1) * 12;
			return this.midiToFrequency(noteNumber);
		}	
	};

	/*
	 *  BeatsBarsSixteenths type primary expression
	 *  @type {Object}
	 *  @private
	 */
	Tone.Frequency.prototype._primaryExpressions.tr = {
			regexp : /^(\d+(?:\.\d+)?):(\d+(?:\.\d+)?):?(\d+(?:\.\d+)?)?/,
			method : function(m, q, s){
			var total = 1;
			if (m && m !== "0"){
				total *= this._beatsToUnits(this._timeSignature() * parseFloat(m));
			}
			if (q && q !== "0"){
				total *= this._beatsToUnits(parseFloat(q));
			}
			if (s && s !== "0"){
				total *= this._beatsToUnits(parseFloat(s) / 4);
			}
			return total;
		}
	};

	///////////////////////////////////////////////////////////////////////////
	//	EXPRESSIONS
	///////////////////////////////////////////////////////////////////////////

	/**
	 *  Transposes the frequency by the given number of semitones.
	 *  @param  {Interval}  interval
	 *  @return  {Tone.Frequency} this
	 *  @example
	 * Tone.Frequency("A4").transpose(3); //"C5"
	 */
	Tone.Frequency.prototype.transpose = function(interval){
		this._expr = function(expr, interval){
			var val = expr();
			return val * this.intervalToFrequencyRatio(interval);
		}.bind(this, this._expr, interval);
		return this;
	};

	/**
	 *  Takes an array of semitone intervals and returns
	 *  an array of frequencies transposed by those intervals.
	 *  @param  {Array}  intervals
	 *  @return  {Tone.Frequency} this
	 *  @example
	 * Tone.Frequency("A4").harmonize([0, 3, 7]); //["A4", "C5", "E5"]
	 */
	Tone.Frequency.prototype.harmonize = function(intervals){
		this._expr = function(expr, intervals){
			var val = expr();
			var ret = [];
			for (var i = 0; i < intervals.length; i++){
				ret[i] = val * this.intervalToFrequencyRatio(intervals[i]);
			}
			return ret;
		}.bind(this, this._expr, intervals);
		return this;
	};

	///////////////////////////////////////////////////////////////////////////
	//	UNIT CONVERSIONS
	///////////////////////////////////////////////////////////////////////////

	/**
	 *  Return the value of the frequency as a MIDI note
	 *  @return  {MIDI}
	 *  @example
	 * Tone.Frequency("C4").toMidi(); //60
	 */
	Tone.Frequency.prototype.toMidi = function(){
		return this.frequencyToMidi(this.valueOf());
	};

	/**
	 *  Return the value of the frequency in Scientific Pitch Notation
	 *  @return  {Note}
	 *  @example
	 * Tone.Frequency(69, "midi").toNote(); //"A4"
	 */
	Tone.Frequency.prototype.toNote = function(){
		var freq = this.valueOf();
		var log = Math.log(freq / Tone.Frequency.A4) / Math.LN2;
		var noteNumber = Math.round(12 * log) + 57;
		var octave = Math.floor(noteNumber/12);
		if(octave < 0){
			noteNumber += -12 * octave;
		}
		var noteName = scaleIndexToNote[noteNumber % 12];
		return noteName + octave.toString();
	};

	/**
	 *  Return the duration of one cycle in seconds.
	 *  @return  {Seconds}
	 */
	Tone.Frequency.prototype.toSeconds = function(){
		return 1 / this.valueOf();
	};

	/**
	 *  Return the value in Hertz
	 *  @return  {Frequency}
	 */
	Tone.Frequency.prototype.toFrequency = function(){
		return this.valueOf();
	};

	/**
	 *  Return the duration of one cycle in ticks
	 *  @return  {Ticks}
	 */
	Tone.Frequency.prototype.toTicks = function(){
		var quarterTime = this._beatsToUnits(1);
		var quarters = this.valueOf() / quarterTime;
		return Math.floor(quarters * Tone.Transport.PPQ);
	};

	///////////////////////////////////////////////////////////////////////////
	//	UNIT CONVERSIONS HELPERS
	///////////////////////////////////////////////////////////////////////////

	/**
	 *  Returns the value of a frequency in the current units
	 *  @param {Frequency} freq
	 *  @return  {Number}
	 *  @private
	 */
	Tone.Frequency.prototype._frequencyToUnits = function(freq){
		return freq;
	};

	/**
	 *  Returns the value of a tick in the current time units
	 *  @param {Ticks} ticks
	 *  @return  {Number}
	 *  @private
	 */
	Tone.Frequency.prototype._ticksToUnits = function(ticks){
		return 1 / ((ticks * 60) / (Tone.Transport.bpm.value * Tone.Transport.PPQ));
	};

	/**
	 *  Return the value of the beats in the current units
	 *  @param {Number} beats
	 *  @return  {Number}
	 *  @private
	 */
	Tone.Frequency.prototype._beatsToUnits = function(beats){
		return 1 / Tone.TimeBase.prototype._beatsToUnits.call(this, beats);
	};

	/**
	 *  Returns the value of a second in the current units
	 *  @param {Seconds} seconds
	 *  @return  {Number}
	 *  @private
	 */
	Tone.Frequency.prototype._secondsToUnits = function(seconds){
		return 1 / seconds;
	};

	/**
	 *  The default units if none are given.
	 *  @private
	 */
	Tone.Frequency.prototype._defaultUnits = "hz";

	///////////////////////////////////////////////////////////////////////////
	//	FREQUENCY CONVERSIONS
	///////////////////////////////////////////////////////////////////////////

	/**
	 *  Note to scale index
	 *  @type  {Object}
	 */
	var noteToScaleIndex = {
		"cbb" : -2, "cb" : -1, "c" : 0,  "c#" : 1,  "cx" : 2, 
		"dbb" : 0,  "db" : 1,  "d" : 2,  "d#" : 3,  "dx" : 4,
		"ebb" : 2,  "eb" : 3,  "e" : 4,  "e#" : 5,  "ex" : 6, 
		"fbb" : 3,  "fb" : 4,  "f" : 5,  "f#" : 6,  "fx" : 7,
		"gbb" : 5,  "gb" : 6,  "g" : 7,  "g#" : 8,  "gx" : 9,
		"abb" : 7,  "ab" : 8,  "a" : 9,  "a#" : 10, "ax" : 11,
		"bbb" : 9,  "bb" : 10, "b" : 11, "b#" : 12, "bx" : 13,
	};

	/**
	 *  scale index to note (sharps)
	 *  @type  {Array}
	 */
	var scaleIndexToNote = ["C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A", "A#", "B"];

	/**
	 *  The [concert pitch](https://en.wikipedia.org/wiki/Concert_pitch)
	 *  A4's values in Hertz. 
	 *  @type {Frequency}
	 *  @static
	 */
	Tone.Frequency.A4 = 440;

	/**
	 *  Convert a MIDI note to frequency value. 
	 *  @param  {MIDI} midi The midi number to convert.
	 *  @return {Frequency} the corresponding frequency value
	 *  @example
	 * tone.midiToFrequency(69); // returns 440
	 */
	Tone.Frequency.prototype.midiToFrequency = function(midi){
		return Tone.Frequency.A4 * Math.pow(2, (midi - 69) / 12);
	};

	/**
	 *  Convert a frequency value to a MIDI note.
	 *  @param {Frequency} frequency The value to frequency value to convert.
	 *  @returns  {MIDI}
	 *  @example
	 * tone.midiToFrequency(440); // returns 69
	 */
	Tone.Frequency.prototype.frequencyToMidi = function(frequency){
		return 69 + 12 * Math.log(frequency / Tone.Frequency.A4) / Math.LN2;
	};

	return Tone.Frequency;
});
define('Tone/type/TransportTime',["Tone/core/Tone", "Tone/type/Time"], function (Tone) {

	/**
	 *  @class Tone.TransportTime is a the time along the Transport's
	 *         timeline. It is similar to Tone.Time, but instead of evaluating
	 *         against the AudioContext's clock, it is evaluated against
	 *         the Transport's position. See [TransportTime wiki](https://github.com/Tonejs/Tone.js/wiki/TransportTime).
	 *  @constructor
	 *  @param  {Time}  val    The time value as a number or string
	 *  @param  {String=}  units  Unit values
	 *  @extends {Tone.Time}
	 */
	Tone.TransportTime = function(val, units){
		if (this instanceof Tone.TransportTime){
			
			Tone.Time.call(this, val, units);

		} else {
			return new Tone.TransportTime(val, units);
		}
	};

	Tone.extend(Tone.TransportTime, Tone.Time);

	//clone the expressions so that 
	//we can add more without modifying the original
	Tone.TransportTime.prototype._unaryExpressions = Object.create(Tone.Time.prototype._unaryExpressions);

	/**
	 *  Adds an additional unary expression
	 *  which quantizes values to the next subdivision
	 *  @type {Object}
	 *  @private
	 */
	Tone.TransportTime.prototype._unaryExpressions.quantize = {
		regexp : /^@/,
		method : function(rh){
			var subdivision = this._secondsToTicks(rh());
			var multiple = Math.ceil(Tone.Transport.ticks / subdivision);
			return this._ticksToUnits(multiple * subdivision);
		}
	};

	/**
	 *  Convert seconds into ticks
	 *  @param {Seconds} seconds
	 *  @return  {Ticks}
	 *  @private
	 */
	Tone.TransportTime.prototype._secondsToTicks = function(seconds){
		var quarterTime = this._beatsToUnits(1);
		var quarters = seconds / quarterTime;
		return Math.round(quarters * Tone.Transport.PPQ);
	};

	/**
	 *  Evaluate the time expression. Returns values in ticks
	 *  @return {Ticks}
	 */
	Tone.TransportTime.prototype.valueOf = function(){
		var val = this._secondsToTicks(this._expr());
		return val + (this._plusNow ? Tone.Transport.ticks : 0);
	};

	/**
	 *  Return the time in ticks.
	 *  @return  {Ticks}
	 */
	Tone.TransportTime.prototype.toTicks = function(){
		return this.valueOf();
	};

	/**
	 *  Return the time in seconds.
	 *  @return  {Seconds}
	 */
	Tone.TransportTime.prototype.toSeconds = function(){
		var val = this._expr();
		return val + (this._plusNow ? Tone.Transport.seconds : 0);
	};

	/**
	 *  Return the time as a frequency value
	 *  @return  {Frequency} 
	 */
	Tone.TransportTime.prototype.toFrequency = function(){
		return 1/this.toSeconds();
	};

	return Tone.TransportTime;
});
define('Tone/core/Emitter',["Tone/core/Tone"], function (Tone) {

	"use strict";

	/**
	 *  @class Tone.Emitter gives classes which extend it
	 *         the ability to listen for and emit events. 
	 *         Inspiration and reference from Jerome Etienne's [MicroEvent](https://github.com/jeromeetienne/microevent.js).
	 *         MIT (c) 2011 Jerome Etienne.
	 *         
	 *  @extends {Tone}
	 */
	Tone.Emitter = function(){
		/**
		 *  Contains all of the events.
		 *  @private
		 *  @type  {Object}
		 */
		this._events = {};
	};

	Tone.extend(Tone.Emitter);

	/**
	 *  Bind a callback to a specific event.
	 *  @param  {String}    event     The name of the event to listen for.
	 *  @param  {Function}  callback  The callback to invoke when the
	 *                                event is emitted
	 *  @return  {Tone.Emitter}    this
	 */
	Tone.Emitter.prototype.on = function(event, callback){
		//split the event
		var events = event.split(/\W+/);
		for (var i = 0; i < events.length; i++){
			var eventName = events[i];
			if (!this._events.hasOwnProperty(eventName)){
				this._events[eventName] = [];
			}
			this._events[eventName].push(callback);
		}
		return this;
	};

	/**
	 *  Remove the event listener.
	 *  @param  {String}    event     The event to stop listening to.
	 *  @param  {Function=}  callback  The callback which was bound to 
	 *                                the event with Tone.Emitter.on.
	 *                                If no callback is given, all callbacks
	 *                                events are removed.
	 *  @return  {Tone.Emitter}    this
	 */
	Tone.Emitter.prototype.off = function(event, callback){
		var events = event.split(/\W+/);
		for (var ev = 0; ev < events.length; ev++){
			event = events[ev];
			if (this._events.hasOwnProperty(event)){
				if (Tone.prototype.isUndef(callback)){
					this._events[event] = [];
				} else {
					var eventList = this._events[event];
					for (var i = 0; i < eventList.length; i++){
						if (eventList[i] === callback){
							eventList.splice(i, 1);
						}
					}
				}
			}
		}
		return this;
	};

	/**
	 *  Invoke all of the callbacks bound to the event
	 *  with any arguments passed in. 
	 *  @param  {String}  event  The name of the event.
	 *  @param {*...} args The arguments to pass to the functions listening.
	 *  @return  {Tone.Emitter}  this
	 */
	Tone.Emitter.prototype.emit = function(event){
		if (this._events){
			var args = Array.apply(null, arguments).slice(1);
			if (this._events.hasOwnProperty(event)){
				var eventList = this._events[event];
				for (var i = 0, len = eventList.length; i < len; i++){
					eventList[i].apply(this, args);
				}
			}
		}
		return this;
	};

	/**
	 *  Add Emitter functions (on/off/emit) to the object
	 *  @param  {Object|Function}  object  The object or class to extend.
	 */
	Tone.Emitter.mixin = function(object){
		var functions = ["on", "off", "emit"];
		object._events = {};
		for (var i = 0; i < functions.length; i++){
			var func = functions[i];
			var emitterFunc = Tone.Emitter.prototype[func];
			object[func] = emitterFunc;
		}
	};

	/**
	 *  Clean up
	 *  @return  {Tone.Emitter}  this
	 */
	Tone.Emitter.prototype.dispose = function(){
		Tone.prototype.dispose.call(this);
		this._events = null;
		return this;
	};

	return Tone.Emitter;
});
define('Tone/core/Context',["Tone/core/Tone", "Tone/core/Emitter"], function (Tone) {

	/**
	 *  shim
	 *  @private
	 */
	if (!window.hasOwnProperty("AudioContext") && window.hasOwnProperty("webkitAudioContext")){
		window.AudioContext = window.webkitAudioContext;
	}

	/**
	 *  @class Wrapper around the native AudioContext.
	 *  @extends {Tone.Emitter}
	 *  @param {AudioContext=} context optionally pass in a context
	 */
	Tone.Context = function(context){

		Tone.Emitter.call(this);

		if (!context){
			context = new window.AudioContext();
		}
		this._context = context;
		// extend all of the methods
		for (var prop in this._context){
			this._defineProperty(this._context, prop);
		}

		///////////////////////////////////////////////////////////////////////
		// WORKER
		///////////////////////////////////////////////////////////////////////

		/**
		 *  The default latency hint
		 *  @type  {String}
		 *  @private
		 */
		this._latencyHint = "interactive";

		/**
		 *  The amount of time events are scheduled
		 *  into the future
		 *  @type  {Number}
		 *  @private
		 */
		this._lookAhead = 0.1;

		/**
		 *  How often the update look runs
		 *  @type  {Number}
		 *  @private
		 */
		this._updateInterval = this._lookAhead/3;

		/**
		 *  A reference to the actual computed update interval
		 *  @type  {Number}
		 *  @private
		 */
		this._computedUpdateInterval = 0;

		/**
		 *  The web worker which is used to update Tone.Clock
		 *  @private
		 *  @type  {WebWorker}
		 */
		this._worker = this._createWorker();

		/**
		 *  An object containing all of the constants AudioBufferSourceNodes
		 *  @type  {Object}
		 *  @private
		 */
		this._constants = {};

	};

	Tone.extend(Tone.Context, Tone.Emitter);
	Tone.Emitter.mixin(Tone.Context);

	/**
	 *  Define a property on this Tone.Context. 
	 *  This is used to extend the native AudioContext
	 *  @param  {AudioContext}  context
	 *  @param  {String}  prop 
	 *  @private
	 */
	Tone.Context.prototype._defineProperty = function(context, prop){
		if (this.isUndef(this[prop])){
			Object.defineProperty(this, prop, {
				get : function(){
					if (typeof context[prop] === "function"){
						return context[prop].bind(context);
					} else {
						return context[prop];
					}
				},
				set : function(val){
					context[prop] = val;
				}
			});
		}
	};

	/**
	 *  The current audio context time
	 *  @return  {Number}
	 */
	Tone.Context.prototype.now = function(){
		return this._context.currentTime;
	};

	/**
	 *  Generate a web worker
	 *  @return  {WebWorker}
	 *  @private
	 */
	Tone.Context.prototype._createWorker = function(){
		
		//URL Shim
		window.URL = window.URL || window.webkitURL;

		var blob = new Blob([
			//the initial timeout time
			"var timeoutTime = "+(this._updateInterval * 1000).toFixed(1)+";" +
			//onmessage callback
			"self.onmessage = function(msg){" +
			"	timeoutTime = parseInt(msg.data);" + 
			"};" + 
			//the tick function which posts a message
			//and schedules a new tick
			"function tick(){" +
			"	setTimeout(tick, timeoutTime);" +
			"	self.postMessage('tick');" +
			"}" +
			//call tick initially
			"tick();"
		]);
		var blobUrl = URL.createObjectURL(blob);
		var worker = new Worker(blobUrl);

		worker.addEventListener("message", function(){
			// tick the clock
			this.emit("tick");
		}.bind(this));

		//lag compensation
		worker.addEventListener("message", function(){
			var now = this.now();
			if (this.isNumber(this._lastUpdate)){
				var diff = now - this._lastUpdate;
				this._computedUpdateInterval = Math.max(diff, this._computedUpdateInterval * 0.97);
			}
			this._lastUpdate = now;
		}.bind(this));

		return worker;
	};

	/**
	 *  Generate a looped buffer at some constant value.
	 *  @param  {Number}  val
	 *  @return  {BufferSourceNode}
	 */
	Tone.Context.prototype.getConstant = function(val){
		if (this._constants[val]){
			return this._constants[val];
		} else {
			var buffer = this._context.createBuffer(1, 128, this._context.sampleRate);
			var arr = buffer.getChannelData(0);
			for (var i = 0; i < arr.length; i++){
				arr[i] = val;
			}
			var constant = this._context.createBufferSource();
			constant.channelCount = 1;
			constant.channelCountMode = "explicit";
			constant.buffer = buffer;
			constant.loop = true;
			constant.start(0);
			this._constants[val] = constant;
			return constant;
		}
	};

	/**
	 *  This is the time that the clock is falling behind
	 *  the scheduled update interval. The Context automatically
	 *  adjusts for the lag and schedules further in advance.
	 *  @type {Number}
	 *  @memberOf Tone.Context
	 *  @name lag
	 *  @static
	 *  @readOnly
	 */
	Object.defineProperty(Tone.Context.prototype, "lag", {
		get : function(){
			var diff = this._computedUpdateInterval - this._updateInterval;
			diff = Math.max(diff, 0);
			return diff;
		}
	});

	/**
	 *  The amount of time in advance that events are scheduled.
	 *  The lookAhead will adjust slightly in response to the 
	 *  measured update time to try to avoid clicks.
	 *  @type {Number}
	 *  @memberOf Tone.Context
	 *  @name lookAhead
	 *  @static
	 */
	Object.defineProperty(Tone.Context.prototype, "lookAhead", {
		get : function(){
			return this._lookAhead;
		},
		set : function(lA){
			this._lookAhead = lA;
		}
	});

	/**
	 *  How often the Web Worker callback is invoked.
	 *  This number corresponds to how responsive the scheduling
	 *  can be. Context.updateInterval + Context.lookAhead gives you the
	 *  total latency between scheduling an event and hearing it.
	 *  @type {Number}
	 *  @memberOf Tone.Context
	 *  @name updateInterval
	 *  @static
	 */
	Object.defineProperty(Tone.Context.prototype, "updateInterval", {
		get : function(){
			return this._updateInterval;
		},
		set : function(interval){
			this._updateInterval = Math.max(interval, Tone.prototype.blockTime);
			this._worker.postMessage(Math.max(interval * 1000, 1));
		}
	});

	/**
	 *  The type of playback, which affects tradeoffs between audio 
	 *  output latency and responsiveness. 
	 *  
	 *  In addition to setting the value in seconds, the latencyHint also
	 *  accepts the strings "interactive" (prioritizes low latency), 
	 *  "playback" (prioritizes sustained playback), "balanced" (balances
	 *  latency and performance), and "fastest" (lowest latency, might glitch more often). 
	 *  @type {String|Seconds}
	 *  @memberOf Tone.Context#
	 *  @name latencyHint
	 *  @static
	 *  @example
	 * //set the lookAhead to 0.3 seconds
	 * Tone.context.latencyHint = 0.3;
	 */
	Object.defineProperty(Tone.Context.prototype, "latencyHint", {
		get : function(){
			return this._latencyHint;
		},
		set : function(hint){
			var lookAhead = hint;
			this._latencyHint = hint;
			if (this.isString(hint)){
				switch(hint){
					case "interactive" :
						lookAhead = 0.1;
						this._context.latencyHint = hint;
						break;
					case "playback" :
						lookAhead = 0.8;
						this._context.latencyHint = hint;
						break;
					case "balanced" :
						lookAhead = 0.25;
						this._context.latencyHint = hint;
						break;
					case "fastest" :
						lookAhead = 0.01;
						break;
				}
			}
			this.lookAhead = lookAhead;
			this.updateInterval = lookAhead/3;
		}
	});

	/**
	 *  Shim all connect/disconnect and some deprecated methods which are still in
	 *  some older implementations.
	 *  @private
	 */
	function shimConnect(){

		var nativeConnect = AudioNode.prototype.connect;
		var nativeDisconnect = AudioNode.prototype.disconnect;

		//replace the old connect method
		function toneConnect(B, outNum, inNum){
			if (B.input){
				if (Array.isArray(B.input)){
					if (Tone.prototype.isUndef(inNum)){
						inNum = 0;
					}
					this.connect(B.input[inNum]);
				} else {
					this.connect(B.input, outNum, inNum);
				}
			} else {
				try {
					if (B instanceof AudioNode){
						nativeConnect.call(this, B, outNum, inNum);
					} else {
						nativeConnect.call(this, B, outNum);
					}
				} catch (e) {
					throw new Error("error connecting to node: "+B+"\n"+e);
				}
			}
		}

		//replace the old disconnect method
		function toneDisconnect(B, outNum, inNum){
			if (B && B.input && Array.isArray(B.input)){
				if (Tone.prototype.isUndef(inNum)){
					inNum = 0;
				}
				this.disconnect(B.input[inNum], outNum, inNum);
			} else if (B && B.input){
				this.disconnect(B.input, outNum, inNum);
			} else {
				try {
					nativeDisconnect.apply(this, arguments);
				} catch (e) {
					throw new Error("error disconnecting node: "+B+"\n"+e);
				}
			}
		}

		if (AudioNode.prototype.connect !== toneConnect){
			AudioNode.prototype.connect = toneConnect;
			AudioNode.prototype.disconnect = toneDisconnect;
		}
	}

	// set the audio context initially
	if (Tone.supported){
		shimConnect();
		Tone.context = new Tone.Context();
	} else {
		console.warn("This browser does not support Tone.js");
	}

	return Tone.Context;
});
define('Tone/type/Type',["Tone/core/Tone", "Tone/type/Time", "Tone/type/Frequency", "Tone/type/TransportTime", "Tone/core/Context"],
function (Tone) {	

	///////////////////////////////////////////////////////////////////////////
	//	TYPES
	///////////////////////////////////////////////////////////////////////////

	/**
	 * Units which a value can take on.
	 * @enum {String}
	 */
	Tone.Type = {
		/** 
		 *  Default units
		 *  @typedef {Default}
		 */
		Default : "number",
		/**
		 *  Time can be described in a number of ways. Read more [Time](https://github.com/Tonejs/Tone.js/wiki/Time).
		 *
		 *  <ul>
		 *  <li>Numbers, which will be taken literally as the time (in seconds).</li>
		 *  <li>Notation, ("4n", "8t") describes time in BPM and time signature relative values.</li>
		 *  <li>TransportTime, ("4:3:2") will also provide tempo and time signature relative times 
		 *  in the form BARS:QUARTERS:SIXTEENTHS.</li>
		 *  <li>Frequency, ("8hz") is converted to the length of the cycle in seconds.</li>
		 *  <li>Now-Relative, ("+1") prefix any of the above with "+" and it will be interpreted as 
		 *  "the current time plus whatever expression follows".</li>
		 *  <li>Expressions, ("3:0 + 2 - (1m / 7)") any of the above can also be combined 
		 *  into a mathematical expression which will be evaluated to compute the desired time.</li>
		 *  <li>No Argument, for methods which accept time, no argument will be interpreted as 
		 *  "now" (i.e. the currentTime).</li>
		 *  </ul>
		 *  
		 *  @typedef {Time}
		 */
		Time : "time",
		/**
		 *  Frequency can be described similar to time, except ultimately the
		 *  values are converted to frequency instead of seconds. A number
		 *  is taken literally as the value in hertz. Additionally any of the 
		 *  Time encodings can be used. Note names in the form
		 *  of NOTE OCTAVE (i.e. C4) are also accepted and converted to their
		 *  frequency value. 
		 *  @typedef {Frequency}
		 */
		Frequency : "frequency",
		/**
		 *  TransportTime describes a position along the Transport's timeline. It is
		 *  similar to Time in that it uses all the same encodings, but TransportTime specifically
		 *  pertains to the Transport's timeline, which is startable, stoppable, loopable, and seekable. 
		 *  [Read more](https://github.com/Tonejs/Tone.js/wiki/TransportTime)
		 *  @typedef {TransportTime}
		 */
		TransportTime : "transportTime",
		/** 
		 *  Ticks are the basic subunit of the Transport. They are
		 *  the smallest unit of time that the Transport supports.
		 *  @typedef {Ticks}
		 */
		Ticks : "ticks",
		/** 
		 *  Normal values are within the range [0, 1].
		 *  @typedef {NormalRange}
		 */
		NormalRange : "normalRange",
		/** 
		 *  AudioRange values are between [-1, 1].
		 *  @typedef {AudioRange}
		 */
		AudioRange : "audioRange",
		/** 
		 *  Decibels are a logarithmic unit of measurement which is useful for volume
		 *  because of the logarithmic way that we perceive loudness. 0 decibels 
		 *  means no change in volume. -10db is approximately half as loud and 10db 
		 *  is twice is loud. 
		 *  @typedef {Decibels}
		 */
		Decibels : "db",
		/** 
		 *  Half-step note increments, i.e. 12 is an octave above the root. and 1 is a half-step up.
		 *  @typedef {Interval}
		 */
		Interval : "interval",
		/** 
		 *  Beats per minute. 
		 *  @typedef {BPM}
		 */
		BPM : "bpm",
		/** 
		 *  The value must be greater than or equal to 0.
		 *  @typedef {Positive}
		 */
		Positive : "positive",
		/** 
		 *  A cent is a hundredth of a semitone. 
		 *  @typedef {Cents}
		 */
		Cents : "cents",
		/** 
		 *  Angle between 0 and 360. 
		 *  @typedef {Degrees}
		 */
		Degrees : "degrees",
		/** 
		 *  A number representing a midi note.
		 *  @typedef {MIDI}
		 */
		MIDI : "midi",
		/** 
		 *  A colon-separated representation of time in the form of
		 *  Bars:Beats:Sixteenths. 
		 *  @typedef {BarsBeatsSixteenths}
		 */
		BarsBeatsSixteenths : "barsBeatsSixteenths",
		/** 
		 *  Sampling is the reduction of a continuous signal to a discrete signal.
		 *  Audio is typically sampled 44100 times per second. 
		 *  @typedef {Samples}
		 */
		Samples : "samples",
		/** 
		 *  Hertz are a frequency representation defined as one cycle per second.
		 *  @typedef {Hertz}
		 */
		Hertz : "hertz",
		/** 
		 *  A frequency represented by a letter name, 
		 *  accidental and octave. This system is known as
		 *  [Scientific Pitch Notation](https://en.wikipedia.org/wiki/Scientific_pitch_notation).
		 *  @typedef {Note}
		 */
		Note : "note",
		/** 
		 *  One millisecond is a thousandth of a second. 
		 *  @typedef {Milliseconds}
		 */
		Milliseconds : "milliseconds",
		/** 
		 *  Seconds are the time unit of the AudioContext. In the end, 
		 *  all values need to be evaluated to seconds. 
		 *  @typedef {Seconds}
		 */
		Seconds : "seconds",
		/** 
		 *  A string representing a duration relative to a measure. 
		 *  <ul>
		 *  	<li>"4n" = quarter note</li>
		 *   	<li>"2m" = two measures</li>
		 *    	<li>"8t" = eighth-note triplet</li>
		 *  </ul>
		 *  @typedef {Notation}
		 */
		Notation : "notation",
	};

	///////////////////////////////////////////////////////////////////////////
	// AUGMENT TONE's PROTOTYPE
	///////////////////////////////////////////////////////////////////////////

	/**
	 *  Convert Time into seconds.
	 *  
	 *  Unlike the method which it overrides, this takes into account 
	 *  transporttime and musical notation.
	 *
	 *  Time : 1.40
	 *  Notation: 4n|1m|2t
	 *  Now Relative: +3n
	 *  Math: 3n+16n or even complicated expressions ((3n*2)/6 + 1)
	 *
	 *  @param  {Time} time 
	 *  @return {Seconds} 
	 */
	Tone.prototype.toSeconds = function(time){
		if (this.isNumber(time)){
			return time;
		} else if (this.isUndef(time)){
			return this.now();			
		} else if (this.isString(time)){
			return (new Tone.Time(time)).toSeconds();
		} else if (time instanceof Tone.TimeBase){
			return time.toSeconds();
		}
	};

	/**
	 *  Convert a frequency representation into a number.
	 *  @param  {Frequency} freq 
	 *  @return {Hertz}      the frequency in hertz
	 */
	Tone.prototype.toFrequency = function(freq){
		if (this.isNumber(freq)){
			return freq;
		} else if (this.isString(freq) || this.isUndef(freq)){
			return (new Tone.Frequency(freq)).valueOf();
		} else if (freq instanceof Tone.TimeBase){
			return freq.toFrequency();
		}
	};

	/**
	 *  Convert a time representation into ticks.
	 *  @param  {Time} time
	 *  @return {Ticks}  the time in ticks
	 */
	Tone.prototype.toTicks = function(time){
		if (this.isNumber(time) || this.isString(time)){
			return (new Tone.TransportTime(time)).toTicks();
		} else if (this.isUndef(time)){
			return Tone.Transport.ticks;			
		} else if (time instanceof Tone.TimeBase){
			return time.toTicks();
		}
	};

	return Tone;
});
define('Tone/core/Param',["Tone/core/Tone", "Tone/type/Type"], function(Tone){

	"use strict";

	/**
	 *  @class Tone.Param wraps the native Web Audio's AudioParam to provide
	 *         additional unit conversion functionality. It also
	 *         serves as a base-class for classes which have a single,
	 *         automatable parameter. 
	 *  @extends {Tone}
	 *  @param  {AudioParam}  param  The parameter to wrap.
	 *  @param  {Tone.Type} units The units of the audio param.
	 *  @param  {Boolean} convert If the param should be converted.
	 */
	Tone.Param = function(){

		var options = this.optionsObject(arguments, ["param", "units", "convert"], Tone.Param.defaults);

		/**
		 *  The native parameter to control
		 *  @type  {AudioParam}
		 *  @private
		 */
		this._param = this.input = options.param;

		/**
		 *  The units of the parameter
		 *  @type {Tone.Type}
		 */
		this.units = options.units;

		/**
		 *  If the value should be converted or not
		 *  @type {Boolean}
		 */
		this.convert = options.convert;

		/**
		 *  True if the signal value is being overridden by 
		 *  a connected signal.
		 *  @readOnly
		 *  @type  {boolean}
		 *  @private
		 */
		this.overridden = false;

		/**
		 *  If there is an LFO, this is where it is held.
		 *  @type  {Tone.LFO}
		 *  @private
		 */
		this._lfo = null;

		if (this.isObject(options.lfo)){
			this.value = options.lfo;
		} else if (!this.isUndef(options.value)){
			this.value = options.value;
		}
	};

	Tone.extend(Tone.Param);
	
	/**
	 *  Defaults
	 *  @type  {Object}
	 *  @const
	 */
	Tone.Param.defaults = {
		"units" : Tone.Type.Default,
		"convert" : true,
		"param" : undefined
	};

	/**
	 * The current value of the parameter. 
	 * @memberOf Tone.Param#
	 * @type {Number}
	 * @name value
	 */
	Object.defineProperty(Tone.Param.prototype, "value", {
		get : function(){
			return this._toUnits(this._param.value);
		},
		set : function(value){
			if (this.isObject(value)){
				//throw an error if the LFO needs to be included
				if (this.isUndef(Tone.LFO)){
					throw new Error("Include 'Tone.LFO' to use an LFO as a Param value.");
				}
				//remove the old one
				if (this._lfo){
					this._lfo.dispose();
				}
				this._lfo = new Tone.LFO(value).start();
				this._lfo.connect(this.input);
			} else {
				var convertedVal = this._fromUnits(value);
				this._param.cancelScheduledValues(0);
				this._param.value = convertedVal;
			}
		}
	});

	/**
	 *  Convert the given value from the type specified by Tone.Param.units
	 *  into the destination value (such as Gain or Frequency).
	 *  @private
	 *  @param  {*} val the value to convert
	 *  @return {number}     the number which the value should be set to
	 */
	Tone.Param.prototype._fromUnits = function(val){
		if (this.convert || this.isUndef(this.convert)){
			switch(this.units){
				case Tone.Type.Time: 
					return this.toSeconds(val);
				case Tone.Type.Frequency: 
					return this.toFrequency(val);
				case Tone.Type.Decibels: 
					return this.dbToGain(val);
				case Tone.Type.NormalRange: 
					return Math.min(Math.max(val, 0), 1);
				case Tone.Type.AudioRange: 
					return Math.min(Math.max(val, -1), 1);
				case Tone.Type.Positive: 
					return Math.max(val, 0);
				default:
					return val;
			}
		} else {
			return val;
		}
	};

	/**
	 * Convert the parameters value into the units specified by Tone.Param.units.
	 * @private
	 * @param  {number} val the value to convert
	 * @return {number}
	 */
	Tone.Param.prototype._toUnits = function(val){
		if (this.convert || this.isUndef(this.convert)){
			switch(this.units){
				case Tone.Type.Decibels: 
					return this.gainToDb(val);
				default:
					return val;
			}
		} else {
			return val;
		}
	};

	/**
	 *  the minimum output value
	 *  @type {Number}
	 *  @private
	 */
	Tone.Param.prototype._minOutput = 0.00001;

	/**
	 *  Schedules a parameter value change at the given time.
	 *  @param {*}	value The value to set the signal.
	 *  @param {Time}  time The time when the change should occur.
	 *  @returns {Tone.Param} this
	 *  @example
	 * //set the frequency to "G4" in exactly 1 second from now. 
	 * freq.setValueAtTime("G4", "+1");
	 */
	Tone.Param.prototype.setValueAtTime = function(value, time){
		value = this._fromUnits(value);
		time = this.toSeconds(time);
		if (time <= this.now() + this.blockTime){
			this._param.value = value;
		} else {
			this._param.setValueAtTime(value, time);
		}
		return this;
	};

	/**
	 *  Creates a schedule point with the current value at the current time.
	 *  This is useful for creating an automation anchor point in order to 
	 *  schedule changes from the current value. 
	 *
	 *  @param {number=} now (Optionally) pass the now value in. 
	 *  @returns {Tone.Param} this
	 */
	Tone.Param.prototype.setRampPoint = function(now){
		now = this.defaultArg(now, this.now());
		var currentVal = this._param.value;
		// exponentialRampToValueAt cannot ever ramp from or to 0
		// More info: https://bugzilla.mozilla.org/show_bug.cgi?id=1125600#c2
		if (currentVal === 0){
			currentVal = this._minOutput;
		}
		this._param.setValueAtTime(currentVal, now);
		return this;
	};

	/**
	 *  Schedules a linear continuous change in parameter value from the 
	 *  previous scheduled parameter value to the given value.
	 *  
	 *  @param  {number} value   
	 *  @param  {Time} endTime 
	 *  @returns {Tone.Param} this
	 */
	Tone.Param.prototype.linearRampToValueAtTime = function(value, endTime){
		value = this._fromUnits(value);
		this._param.linearRampToValueAtTime(value, this.toSeconds(endTime));
		return this;
	};

	/**
	 *  Schedules an exponential continuous change in parameter value from 
	 *  the previous scheduled parameter value to the given value.
	 *  
	 *  @param  {number} value   
	 *  @param  {Time} endTime 
	 *  @returns {Tone.Param} this
	 */
	Tone.Param.prototype.exponentialRampToValueAtTime = function(value, endTime){
		value = this._fromUnits(value);
		value = Math.max(this._minOutput, value);
		this._param.exponentialRampToValueAtTime(value, this.toSeconds(endTime));
		return this;
	};

	/**
	 *  Schedules an exponential continuous change in parameter value from 
	 *  the current time and current value to the given value over the 
	 *  duration of the rampTime.
	 *  
	 *  @param  {number} value   The value to ramp to.
	 *  @param  {Time} rampTime the time that it takes the 
	 *                               value to ramp from it's current value
	 *  @param {Time}	[startTime=now] 	When the ramp should start. 
	 *  @returns {Tone.Param} this
	 *  @example
	 * //exponentially ramp to the value 2 over 4 seconds. 
	 * signal.exponentialRampToValue(2, 4);
	 */
	Tone.Param.prototype.exponentialRampToValue = function(value, rampTime, startTime){
		startTime = this.toSeconds(startTime);
		this.setRampPoint(startTime);
		this.exponentialRampToValueAtTime(value, startTime + this.toSeconds(rampTime));
		return this;
	};

	/**
	 *  Schedules an linear continuous change in parameter value from 
	 *  the current time and current value to the given value over the 
	 *  duration of the rampTime.
	 *  
	 *  @param  {number} value   The value to ramp to.
	 *  @param  {Time} rampTime the time that it takes the 
	 *                               value to ramp from it's current value
	 *  @param {Time}	[startTime=now] 	When the ramp should start. 
	 *  @returns {Tone.Param} this
	 *  @example
	 * //linearly ramp to the value 4 over 3 seconds. 
	 * signal.linearRampToValue(4, 3);
	 */
	Tone.Param.prototype.linearRampToValue = function(value, rampTime, startTime){
		startTime = this.toSeconds(startTime);
		this.setRampPoint(startTime);
		this.linearRampToValueAtTime(value, startTime + this.toSeconds(rampTime));
		return this;
	};

	/**
	 *  Start exponentially approaching the target value at the given time with
	 *  a rate having the given time constant.
	 *  @param {number} value        
	 *  @param {Time} startTime    
	 *  @param {number} timeConstant 
	 *  @returns {Tone.Param} this 
	 */
	Tone.Param.prototype.setTargetAtTime = function(value, startTime, timeConstant){
		value = this._fromUnits(value);
		// The value will never be able to approach without timeConstant > 0.
		// http://www.w3.org/TR/webaudio/#dfn-setTargetAtTime, where the equation
		// is described. 0 results in a division by 0.
		value = Math.max(this._minOutput, value);
		timeConstant = Math.max(this._minOutput, timeConstant);
		this._param.setTargetAtTime(value, this.toSeconds(startTime), timeConstant);
		return this;
	};

	/**
	 *  Sets an array of arbitrary parameter values starting at the given time
	 *  for the given duration.
	 *  	
	 *  @param {Array} values    
	 *  @param {Time} startTime 
	 *  @param {Time} duration  
	 *  @returns {Tone.Param} this
	 */
	Tone.Param.prototype.setValueCurveAtTime = function(values, startTime, duration){
		for (var i = 0; i < values.length; i++){
			values[i] = this._fromUnits(values[i]);
		}
		this._param.setValueCurveAtTime(values, this.toSeconds(startTime), this.toSeconds(duration));
		return this;
	};

	/**
	 *  Cancels all scheduled parameter changes with times greater than or 
	 *  equal to startTime.
	 *  
	 *  @param  {Time} startTime
	 *  @returns {Tone.Param} this
	 */
	Tone.Param.prototype.cancelScheduledValues = function(startTime){
		this._param.cancelScheduledValues(this.toSeconds(startTime));
		return this;
	};

	/**
	 *  Ramps to the given value over the duration of the rampTime. 
	 *  Automatically selects the best ramp type (exponential or linear)
	 *  depending on the `units` of the signal
	 *  
	 *  @param  {number} value   
	 *  @param  {Time} rampTime 	The time that it takes the 
	 *                              value to ramp from it's current value
	 *  @param {Time}	[startTime=now] 	When the ramp should start. 
	 *  @returns {Tone.Param} this
	 *  @example
	 * //ramp to the value either linearly or exponentially 
	 * //depending on the "units" value of the signal
	 * signal.rampTo(0, 10);
	 *  @example
	 * //schedule it to ramp starting at a specific time
	 * signal.rampTo(0, 10, 5)
	 */
	Tone.Param.prototype.rampTo = function(value, rampTime, startTime){
		rampTime = this.defaultArg(rampTime, 0);
		if (this.units === Tone.Type.Frequency || this.units === Tone.Type.BPM || this.units === Tone.Type.Decibels){
			this.exponentialRampToValue(value, rampTime, startTime);
		} else {
			this.linearRampToValue(value, rampTime, startTime);
		}
		return this;
	};

	/**
	 *  The LFO created by the signal instance. If none
	 *  was created, this is null.
	 *  @type {Tone.LFO}
	 *  @readOnly
	 *  @memberOf Tone.Param#
	 *  @name lfo
	 */
	Object.defineProperty(Tone.Param.prototype, "lfo", {
		get : function(){
			return this._lfo;
		}
	});

	/**
	 *  Clean up
	 *  @returns {Tone.Param} this
	 */
	Tone.Param.prototype.dispose = function(){
		Tone.prototype.dispose.call(this);
		this._param = null;
		if (this._lfo){
			this._lfo.dispose();
			this._lfo = null;
		}
		return this;
	};

	return Tone.Param;
});
define('Tone/core/Gain',["Tone/core/Tone", "Tone/core/Param", "Tone/type/Type"], function (Tone) {

	"use strict";

	/**
	 *  createGain shim
	 *  @private
	 */
	if (window.GainNode && !AudioContext.prototype.createGain){
		AudioContext.prototype.createGain = AudioContext.prototype.createGainNode;
	}

	/**
	 *  @class A thin wrapper around the Native Web Audio GainNode.
	 *         The GainNode is a basic building block of the Web Audio
	 *         API and is useful for routing audio and adjusting gains. 
	 *  @extends {Tone}
	 *  @param  {Number=}  gain  The initial gain of the GainNode
	 *  @param {Tone.Type=} units The units of the gain parameter. 
	 */
	Tone.Gain = function(){

		var options = this.optionsObject(arguments, ["gain", "units"], Tone.Gain.defaults);

		/**
		 *  The GainNode
		 *  @type  {GainNode}
		 *  @private
		 */
		this.input = this.output = this._gainNode = this.context.createGain();

		/**
		 *  The gain parameter of the gain node.
		 *  @type {Tone.Param}
		 *  @signal
		 */
		this.gain = new Tone.Param({
			"param" : this._gainNode.gain, 
			"units" : options.units,
			"value" : options.gain,
			"convert" : options.convert
		});
		this._readOnly("gain");
	};

	Tone.extend(Tone.Gain);

	/**
	 *  The defaults
	 *  @const
	 *  @type  {Object}
	 */
	Tone.Gain.defaults = {
		"gain" : 1,
		"convert" : true,
	};

	/**
	 *  Clean up.
	 *  @return  {Tone.Gain}  this
	 */
	Tone.Gain.prototype.dispose = function(){
		Tone.Param.prototype.dispose.call(this);
		this._gainNode.disconnect();
		this._gainNode = null;
		this._writable("gain");
		this.gain.dispose();
		this.gain = null;
	};

	//STATIC///////////////////////////////////////////////////////////////////

	/**
	 *  Create input and outputs for this object.
	 *  @param  {Number}  input   The number of inputs
	 *  @param  {Number=}  outputs  The number of outputs
	 *  @return  {Tone}  this
	 *  @internal
	 */
	Tone.prototype.createInsOuts = function(inputs, outputs){

		if (inputs === 1){
			this.input = new Tone.Gain();
		} else if (inputs > 1){
			this.input = new Array(inputs);
		}

		if (outputs === 1){
			this.output = new Tone.Gain();
		} else if (outputs > 1){
			this.output = new Array(inputs);
		}
	};

	///////////////////////////////////////////////////////////////////////////

	return Tone.Gain;
});
define('Tone/signal/Signal',["Tone/core/Tone", "Tone/signal/WaveShaper", "Tone/type/Type", "Tone/core/Param", "Tone/core/Gain"], function(Tone){

	"use strict";

	/**
	 *  @class  A signal is an audio-rate value. Tone.Signal is a core component of the library.
	 *          Unlike a number, Signals can be scheduled with sample-level accuracy. Tone.Signal
	 *          has all of the methods available to native Web Audio 
	 *          [AudioParam](http://webaudio.github.io/web-audio-api/#the-audioparam-interface)
	 *          as well as additional conveniences. Read more about working with signals 
	 *          [here](https://github.com/Tonejs/Tone.js/wiki/Signals).
	 *
	 *  @constructor
	 *  @extends {Tone.Param}
	 *  @param {Number|AudioParam} [value] Initial value of the signal. If an AudioParam
	 *                                     is passed in, that parameter will be wrapped
	 *                                     and controlled by the Signal. 
	 *  @param {string} [units=Number] unit The units the signal is in. 
	 *  @example
	 * var signal = new Tone.Signal(10);
	 */
	Tone.Signal = function(){

		var options = this.optionsObject(arguments, ["value", "units"], Tone.Signal.defaults);

		/**
		 * The node where the constant signal value is scaled.
		 * @type {GainNode}
		 * @private
		 */
		this.output = this._gain = this.context.createGain();

		options.param = this._gain.gain;
		Tone.Param.call(this, options);

		/**
		 * The node where the value is set.
		 * @type {Tone.Param}
		 * @private
		 */
		this.input = this._param = this._gain.gain;

		//connect the const output to the node output
		this.context.getConstant(1).chain(this._gain);
	};

	Tone.extend(Tone.Signal, Tone.Param);

	/**
	 *  The default values
	 *  @type  {Object}
	 *  @static
	 *  @const
	 */
	Tone.Signal.defaults = {
		"value" : 0,
		"units" : Tone.Type.Default,
		"convert" : true,
	};

	/**
	 *  When signals connect to other signals or AudioParams, 
	 *  they take over the output value of that signal or AudioParam. 
	 *  For all other nodes, the behavior is the same as a default <code>connect</code>. 
	 *
	 *  @override
	 *  @param {AudioParam|AudioNode|Tone.Signal|Tone} node 
	 *  @param {number} [outputNumber=0] The output number to connect from.
	 *  @param {number} [inputNumber=0] The input number to connect to.
	 *  @returns {Tone.SignalBase} this
	 *  @method
	 */
	Tone.Signal.prototype.connect = Tone.SignalBase.prototype.connect;

	/**
	 *  dispose and disconnect
	 *  @returns {Tone.Signal} this
	 */
	Tone.Signal.prototype.dispose = function(){
		Tone.Param.prototype.dispose.call(this);
		this._param = null;
		this._gain.disconnect();
		this._gain = null;
		return this;
	};

	return Tone.Signal;
});
define('Tone/signal/Add',["Tone/core/Tone", "Tone/signal/Signal", "Tone/core/Gain"], function(Tone){

	"use strict";

	/**
	 *  @class Add a signal and a number or two signals. When no value is
	 *         passed into the constructor, Tone.Add will sum <code>input[0]</code>
	 *         and <code>input[1]</code>. If a value is passed into the constructor, 
	 *         the it will be added to the input.
	 *  
	 *  @constructor
	 *  @extends {Tone.Signal}
	 *  @param {number=} value If no value is provided, Tone.Add will sum the first
	 *                         and second inputs. 
	 *  @example
	 * var signal = new Tone.Signal(2);
	 * var add = new Tone.Add(2);
	 * signal.connect(add);
	 * //the output of add equals 4
	 *  @example
	 * //if constructed with no arguments
	 * //it will add the first and second inputs
	 * var add = new Tone.Add();
	 * var sig0 = new Tone.Signal(3).connect(add, 0, 0);
	 * var sig1 = new Tone.Signal(4).connect(add, 0, 1);
	 * //the output of add equals 7. 
	 */
	Tone.Add = function(value){

		this.createInsOuts(2, 0);

		/**
		 *  the summing node
		 *  @type {GainNode}
		 *  @private
		 */
		this._sum = this.input[0] = this.input[1] = this.output = new Tone.Gain();

		/**
		 *  @private
		 *  @type {Tone.Signal}
		 */
		this._param = this.input[1] = new Tone.Signal(value);

		this._param.connect(this._sum);
	};

	Tone.extend(Tone.Add, Tone.Signal);
	
	/**
	 *  Clean up.
	 *  @returns {Tone.Add} this
	 */
	Tone.Add.prototype.dispose = function(){
		Tone.prototype.dispose.call(this);
		this._sum.dispose();
		this._sum = null;
		this._param.dispose();
		this._param = null;
		return this;
	}; 

	return Tone.Add;
});
define('Tone/signal/Multiply',["Tone/core/Tone", "Tone/signal/Signal", "Tone/core/Gain"], function(Tone){

	"use strict";

	/**
	 *  @class  Multiply two incoming signals. Or, if a number is given in the constructor, 
	 *          multiplies the incoming signal by that value. 
	 *
	 *  @constructor
	 *  @extends {Tone.Signal}
	 *  @param {number=} value Constant value to multiple. If no value is provided,
	 *                         it will return the product of the first and second inputs
	 *  @example
	 * var mult = new Tone.Multiply();
	 * var sigA = new Tone.Signal(3);
	 * var sigB = new Tone.Signal(4);
	 * sigA.connect(mult, 0, 0);
	 * sigB.connect(mult, 0, 1);
	 * //output of mult is 12.
	 *  @example
	 * var mult = new Tone.Multiply(10);
	 * var sig = new Tone.Signal(2).connect(mult);
	 * //the output of mult is 20. 
	 */
	Tone.Multiply = function(value){

		this.createInsOuts(2, 0);

		/**
		 *  the input node is the same as the output node
		 *  it is also the GainNode which handles the scaling of incoming signal
		 *  
		 *  @type {GainNode}
		 *  @private
		 */
		this._mult = this.input[0] = this.output = new Tone.Gain();

		/**
		 *  the scaling parameter
		 *  @type {AudioParam}
		 *  @private
		 */
		this._param = this.input[1] = this.output.gain;
		
		this._param.value = this.defaultArg(value, 0);
	};

	Tone.extend(Tone.Multiply, Tone.Signal);

	/**
	 *  clean up
	 *  @returns {Tone.Multiply} this
	 */
	Tone.Multiply.prototype.dispose = function(){
		Tone.prototype.dispose.call(this);
		this._mult.dispose();
		this._mult = null;
		this._param = null;
		return this;
	}; 

	return Tone.Multiply;
});

define('Tone/signal/Scale',["Tone/core/Tone", "Tone/signal/Add", "Tone/signal/Multiply", "Tone/signal/Signal"], function(Tone){

	"use strict";
	
	/**
	 *  @class  Performs a linear scaling on an input signal.
	 *          Scales a NormalRange input to between
	 *          outputMin and outputMax.
	 *
	 *  @constructor
	 *  @extends {Tone.SignalBase}
	 *  @param {number} [outputMin=0] The output value when the input is 0. 
	 *  @param {number} [outputMax=1]	The output value when the input is 1. 
	 *  @example
	 * var scale = new Tone.Scale(50, 100);
	 * var signal = new Tone.Signal(0.5).connect(scale);
	 * //the output of scale equals 75
	 */
	Tone.Scale = function(outputMin, outputMax){

		/** 
		 *  @private
		 *  @type {number}
		 */
		this._outputMin = this.defaultArg(outputMin, 0);

		/** 
		 *  @private
		 *  @type {number}
		 */
		this._outputMax = this.defaultArg(outputMax, 1);


		/** 
		 *  @private
		 *  @type {Tone.Multiply}
		 *  @private
		 */
		this._scale = this.input = new Tone.Multiply(1);
		
		/** 
		 *  @private
		 *  @type {Tone.Add}
		 *  @private
		 */
		this._add = this.output = new Tone.Add(0);

		this._scale.connect(this._add);
		this._setRange();
	};

	Tone.extend(Tone.Scale, Tone.SignalBase);

	/**
	 * The minimum output value. This number is output when 
	 * the value input value is 0. 
	 * @memberOf Tone.Scale#
	 * @type {number}
	 * @name min
	 */
	Object.defineProperty(Tone.Scale.prototype, "min", {
		get : function(){
			return this._outputMin;
		},
		set : function(min){
			this._outputMin = min;
			this._setRange();
		}
	});

	/**
	 * The maximum output value. This number is output when 
	 * the value input value is 1. 
	 * @memberOf Tone.Scale#
	 * @type {number}
	 * @name max
	 */
	Object.defineProperty(Tone.Scale.prototype, "max", {
		get : function(){
			return this._outputMax;
		},
		set : function(max){
			this._outputMax = max;
			this._setRange();
		}
	});

	/**
	 *  set the values
	 *  @private
	 */
	Tone.Scale.prototype._setRange = function() {
		this._add.value = this._outputMin;
		this._scale.value = this._outputMax - this._outputMin;
	};

	/**
	 *  Clean up.
	 *  @returns {Tone.Scale} this
	 */
	Tone.Scale.prototype.dispose = function(){
		Tone.prototype.dispose.call(this);
		this._add.dispose();
		this._add = null;
		this._scale.dispose();
		this._scale = null;
		return this;
	}; 

	return Tone.Scale;
});

var signal;
'use strict';
signal = function () {
    var Signal = Tone_signal_Signal;
    var Add = Tone_signal_Add;
    var Mult = Tone_signal_Multiply;
    var Scale = Tone_signal_Scale;
    var Tone = Tone_core_Tone;
    var p5sound = master;
    Tone.setContext(p5sound.audiocontext);
    p5.Signal = function (value) {
        var s = new Signal(value);
        return s;
    };
    Signal.prototype.fade = Signal.prototype.linearRampToValueAtTime;
    Mult.prototype.fade = Signal.prototype.fade;
    Add.prototype.fade = Signal.prototype.fade;
    Scale.prototype.fade = Signal.prototype.fade;
    Signal.prototype.setInput = function (_input) {
        _input.connect(this);
    };
    Mult.prototype.setInput = Signal.prototype.setInput;
    Add.prototype.setInput = Signal.prototype.setInput;
    Scale.prototype.setInput = Signal.prototype.setInput;
    Signal.prototype.add = function (num) {
        var add = new Add(num);
        this.connect(add);
        return add;
    };
    Mult.prototype.add = Signal.prototype.add;
    Add.prototype.add = Signal.prototype.add;
    Scale.prototype.add = Signal.prototype.add;
    Signal.prototype.mult = function (num) {
        var mult = new Mult(num);
        this.connect(mult);
        return mult;
    };
    Mult.prototype.mult = Signal.prototype.mult;
    Add.prototype.mult = Signal.prototype.mult;
    Scale.prototype.mult = Signal.prototype.mult;
    Signal.prototype.scale = function (inMin, inMax, outMin, outMax) {
        var mapOutMin, mapOutMax;
        if (arguments.length === 4) {
            mapOutMin = p5.prototype.map(outMin, inMin, inMax, 0, 1) - 0.5;
            mapOutMax = p5.prototype.map(outMax, inMin, inMax, 0, 1) - 0.5;
        } else {
            mapOutMin = arguments[0];
            mapOutMax = arguments[1];
        }
        var scale = new Scale(mapOutMin, mapOutMax);
        this.connect(scale);
        return scale;
    };
    Mult.prototype.scale = Signal.prototype.scale;
    Add.prototype.scale = Signal.prototype.scale;
    Scale.prototype.scale = Signal.prototype.scale;
}(Tone_signal_Signal, Tone_signal_Add, Tone_signal_Multiply, Tone_signal_Scale, Tone_core_Tone, master);
var oscillator;
'use strict';
oscillator = function () {
    var p5sound = master;
    var Add = Tone_signal_Add;
    var Mult = Tone_signal_Multiply;
    var Scale = Tone_signal_Scale;
    p5.Oscillator = function (freq, type) {
        if (typeof freq === 'string') {
            var f = type;
            type = freq;
            freq = f;
        }
        if (typeof type === 'number') {
            var f = type;
            type = freq;
            freq = f;
        }
        this.started = false;
        this.phaseAmount = undefined;
        this.oscillator = p5sound.audiocontext.createOscillator();
        this.f = freq || 440;
        this.oscillator.type = type || 'sine';
        this.oscillator.frequency.setValueAtTime(this.f, p5sound.audiocontext.currentTime);
        this.output = p5sound.audiocontext.createGain();
        this._freqMods = [];
        this.output.gain.value = 0.5;
        this.output.gain.setValueAtTime(0.5, p5sound.audiocontext.currentTime);
        this.oscillator.connect(this.output);
        this.panPosition = 0;
        this.connection = p5sound.input;
        this.panner = new p5.Panner(this.output, this.connection, 1);
        this.mathOps = [this.output];
        p5sound.soundArray.push(this);
    };
    p5.Oscillator.prototype.start = function (time, f) {
        if (this.started) {
            var now = p5sound.audiocontext.currentTime;
            this.stop(now);
        }
        if (!this.started) {
            var freq = f || this.f;
            var type = this.oscillator.type;
            if (this.oscillator) {
                this.oscillator.disconnect();
                delete this.oscillator;
            }
            this.oscillator = p5sound.audiocontext.createOscillator();
            this.oscillator.frequency.value = Math.abs(freq);
            this.oscillator.type = type;
            this.oscillator.connect(this.output);
            time = time || 0;
            this.oscillator.start(time + p5sound.audiocontext.currentTime);
            this.freqNode = this.oscillator.frequency;
            for (var i in this._freqMods) {
                if (typeof this._freqMods[i].connect !== 'undefined') {
                    this._freqMods[i].connect(this.oscillator.frequency);
                }
            }
            this.started = true;
        }
    };
    p5.Oscillator.prototype.stop = function (time) {
        if (this.started) {
            var t = time || 0;
            var now = p5sound.audiocontext.currentTime;
            this.oscillator.stop(t + now);
            this.started = false;
        }
    };
    p5.Oscillator.prototype.amp = function (vol, rampTime, tFromNow) {
        var self = this;
        if (typeof vol === 'number') {
            var rampTime = rampTime || 0;
            var tFromNow = tFromNow || 0;
            var now = p5sound.audiocontext.currentTime;
            this.output.gain.linearRampToValueAtTime(vol, now + tFromNow + rampTime);
        } else if (vol) {
            vol.connect(self.output.gain);
        } else {
            return this.output.gain;
        }
    };
    p5.Oscillator.prototype.fade = p5.Oscillator.prototype.amp;
    p5.Oscillator.prototype.getAmp = function () {
        return this.output.gain.value;
    };
    p5.Oscillator.prototype.freq = function (val, rampTime, tFromNow) {
        if (typeof val === 'number' && !isNaN(val)) {
            this.f = val;
            var now = p5sound.audiocontext.currentTime;
            var rampTime = rampTime || 0;
            var tFromNow = tFromNow || 0;
            var t = now + tFromNow + rampTime;
            if (rampTime === 0) {
                this.oscillator.frequency.setValueAtTime(val, tFromNow + now);
            } else {
                if (val > 0) {
                    this.oscillator.frequency.exponentialRampToValueAtTime(val, tFromNow + rampTime + now);
                } else {
                    this.oscillator.frequency.linearRampToValueAtTime(val, tFromNow + rampTime + now);
                }
            }
            if (this.phaseAmount) {
                this.phase(this.phaseAmount);
            }
        } else if (val) {
            if (val.output) {
                val = val.output;
            }
            val.connect(this.oscillator.frequency);
            this._freqMods.push(val);
        } else {
            return this.oscillator.frequency;
        }
    };
    p5.Oscillator.prototype.getFreq = function () {
        return this.oscillator.frequency.value;
    };
    p5.Oscillator.prototype.setType = function (type) {
        this.oscillator.type = type;
    };
    p5.Oscillator.prototype.getType = function () {
        return this.oscillator.type;
    };
    p5.Oscillator.prototype.connect = function (unit) {
        if (!unit) {
            this.panner.connect(p5sound.input);
        } else if (unit.hasOwnProperty('input')) {
            this.panner.connect(unit.input);
            this.connection = unit.input;
        } else {
            this.panner.connect(unit);
            this.connection = unit;
        }
    };
    p5.Oscillator.prototype.disconnect = function () {
        if (this.output) {
            this.output.disconnect();
        }
        if (this.panner) {
            this.panner.disconnect();
            if (this.output) {
                this.output.connect(this.panner);
            }
        }
        this.oscMods = [];
    };
    p5.Oscillator.prototype.pan = function (pval, tFromNow) {
        this.panPosition = pval;
        this.panner.pan(pval, tFromNow);
    };
    p5.Oscillator.prototype.getPan = function () {
        return this.panPosition;
    };
    p5.Oscillator.prototype.dispose = function () {
        var index = p5sound.soundArray.indexOf(this);
        p5sound.soundArray.splice(index, 1);
        if (this.oscillator) {
            var now = p5sound.audiocontext.currentTime;
            this.stop(now);
            this.disconnect();
            this.panner = null;
            this.oscillator = null;
        }
        if (this.osc2) {
            this.osc2.dispose();
        }
    };
    p5.Oscillator.prototype.phase = function (p) {
        var delayAmt = p5.prototype.map(p, 0, 1, 0, 1 / this.f);
        var now = p5sound.audiocontext.currentTime;
        this.phaseAmount = p;
        if (!this.dNode) {
            this.dNode = p5sound.audiocontext.createDelay();
            this.oscillator.disconnect();
            this.oscillator.connect(this.dNode);
            this.dNode.connect(this.output);
        }
        this.dNode.delayTime.setValueAtTime(delayAmt, now);
    };
    var sigChain = function (o, mathObj, thisChain, nextChain, type) {
        var chainSource = o.oscillator;
        for (var i in o.mathOps) {
            if (o.mathOps[i] instanceof type) {
                chainSource.disconnect();
                o.mathOps[i].dispose();
                thisChain = i;
                if (thisChain < o.mathOps.length - 2) {
                    nextChain = o.mathOps[i + 1];
                }
            }
        }
        if (thisChain === o.mathOps.length - 1) {
            o.mathOps.push(nextChain);
        }
        if (i > 0) {
            chainSource = o.mathOps[i - 1];
        }
        chainSource.disconnect();
        chainSource.connect(mathObj);
        mathObj.connect(nextChain);
        o.mathOps[thisChain] = mathObj;
        return o;
    };
    p5.Oscillator.prototype.add = function (num) {
        var add = new Add(num);
        var thisChain = this.mathOps.length - 1;
        var nextChain = this.output;
        return sigChain(this, add, thisChain, nextChain, Add);
    };
    p5.Oscillator.prototype.mult = function (num) {
        var mult = new Mult(num);
        var thisChain = this.mathOps.length - 1;
        var nextChain = this.output;
        return sigChain(this, mult, thisChain, nextChain, Mult);
    };
    p5.Oscillator.prototype.scale = function (inMin, inMax, outMin, outMax) {
        var mapOutMin, mapOutMax;
        if (arguments.length === 4) {
            mapOutMin = p5.prototype.map(outMin, inMin, inMax, 0, 1) - 0.5;
            mapOutMax = p5.prototype.map(outMax, inMin, inMax, 0, 1) - 0.5;
        } else {
            mapOutMin = arguments[0];
            mapOutMax = arguments[1];
        }
        var scale = new Scale(mapOutMin, mapOutMax);
        var thisChain = this.mathOps.length - 1;
        var nextChain = this.output;
        return sigChain(this, scale, thisChain, nextChain, Scale);
    };
    p5.SinOsc = function (freq) {
        p5.Oscillator.call(this, freq, 'sine');
    };
    p5.SinOsc.prototype = Object.create(p5.Oscillator.prototype);
    p5.TriOsc = function (freq) {
        p5.Oscillator.call(this, freq, 'triangle');
    };
    p5.TriOsc.prototype = Object.create(p5.Oscillator.prototype);
    p5.SawOsc = function (freq) {
        p5.Oscillator.call(this, freq, 'sawtooth');
    };
    p5.SawOsc.prototype = Object.create(p5.Oscillator.prototype);
    p5.SqrOsc = function (freq) {
        p5.Oscillator.call(this, freq, 'square');
    };
    p5.SqrOsc.prototype = Object.create(p5.Oscillator.prototype);
}(master, Tone_signal_Add, Tone_signal_Multiply, Tone_signal_Scale);
define('Tone/core/Timeline',["Tone/core/Tone", "Tone/type/Type"], function (Tone) {

	"use strict";

	/**
	 *  @class A Timeline class for scheduling and maintaining state
	 *         along a timeline. All events must have a "time" property. 
	 *         Internally, events are stored in time order for fast 
	 *         retrieval.
	 *  @extends {Tone}
	 *  @param {Positive} [memory=Infinity] The number of previous events that are retained.
	 */
	Tone.Timeline = function(){

		var options = this.optionsObject(arguments, ["memory"], Tone.Timeline.defaults);

		/**
		 *  The array of scheduled timeline events
		 *  @type  {Array}
		 *  @private
		 */
		this._timeline = [];

		/**
		 *  An array of items to remove from the list. 
		 *  @type {Array}
		 *  @private
		 */
		this._toRemove = [];

		/**
		 *  Flag if the tieline is mid iteration
		 *  @private
		 *  @type {Boolean}
		 */
		this._iterating = false;

		/**
		 *  The memory of the timeline, i.e.
		 *  how many events in the past it will retain
		 *  @type {Positive}
		 */
		this.memory = options.memory;
	};

	Tone.extend(Tone.Timeline);

	/**
	 *  the default parameters
	 *  @static
	 *  @const
	 */
	Tone.Timeline.defaults = {
		"memory" : Infinity
	};

	/**
	 *  The number of items in the timeline.
	 *  @type {Number}
	 *  @memberOf Tone.Timeline#
	 *  @name length
	 *  @readOnly
	 */
	Object.defineProperty(Tone.Timeline.prototype, "length", {
		get : function(){
			return this._timeline.length;
		}
	});

	/**
	 *  Insert an event object onto the timeline. Events must have a "time" attribute.
	 *  @param  {Object}  event  The event object to insert into the 
	 *                           timeline. 
	 *  @returns {Tone.Timeline} this
	 */
	Tone.Timeline.prototype.add = function(event){
		//the event needs to have a time attribute
		if (this.isUndef(event.time)){
			throw new Error("Tone.Timeline: events must have a time attribute");
		}
		if (this._timeline.length){
			var index = this._search(event.time);
			this._timeline.splice(index + 1, 0, event);
		} else {
			this._timeline.push(event);			
		}
		//if the length is more than the memory, remove the previous ones
		if (this.length > this.memory){
			var diff = this.length - this.memory;
			this._timeline.splice(0, diff);
		}
		return this;
	};

	/**
	 *  Remove an event from the timeline.
	 *  @param  {Object}  event  The event object to remove from the list.
	 *  @returns {Tone.Timeline} this
	 */
	Tone.Timeline.prototype.remove = function(event){
		if (this._iterating){
			this._toRemove.push(event);
		} else {
			var index = this._timeline.indexOf(event);
			if (index !== -1){
				this._timeline.splice(index, 1);
			}
		}
		return this;
	};

	/**
	 *  Get the nearest event whose time is less than or equal to the given time.
	 *  @param  {Number}  time  The time to query.
	 *  @returns {Object} The event object set after that time.
	 */
	Tone.Timeline.prototype.get = function(time){
		var index = this._search(time);
		if (index !== -1){
			return this._timeline[index];
		} else {
			return null;
		}
	};

	/**
	 *  Return the first event in the timeline without removing it
	 *  @returns {Object} The first event object
	 */
	Tone.Timeline.prototype.peek = function(){
		return this._timeline[0];
	};

	/**
	 *  Return the first event in the timeline and remove it
	 *  @returns {Object} The first event object
	 */
	Tone.Timeline.prototype.shift = function(){
		return this._timeline.shift();
	};

	/**
	 *  Get the event which is scheduled after the given time.
	 *  @param  {Number}  time  The time to query.
	 *  @returns {Object} The event object after the given time
	 */
	Tone.Timeline.prototype.getAfter = function(time){
		var index = this._search(time);
		if (index + 1 < this._timeline.length){
			return this._timeline[index + 1];
		} else {
			return null;
		}
	};

	/**
	 *  Get the event before the event at the given time.
	 *  @param  {Number}  time  The time to query.
	 *  @returns {Object} The event object before the given time
	 */
	Tone.Timeline.prototype.getBefore = function(time){
		var len = this._timeline.length;
		//if it's after the last item, return the last item
		if (len > 0 && this._timeline[len - 1].time < time){
			return this._timeline[len - 1];
		}
		var index = this._search(time);
		if (index - 1 >= 0){
			return this._timeline[index - 1];
		} else {
			return null;
		}
	};

	/**
	 *  Cancel events after the given time
	 *  @param  {Number}  time  The time to query.
	 *  @returns {Tone.Timeline} this
	 */
	Tone.Timeline.prototype.cancel = function(after){
		if (this._timeline.length > 1){
			var index = this._search(after);
			if (index >= 0){
				if (this._timeline[index].time === after){
					//get the first item with that time
					for (var i = index; i >= 0; i--){
						if (this._timeline[i].time === after){
							index = i;
						} else {
							break;
						}
					}
					this._timeline = this._timeline.slice(0, index);
				} else {
					this._timeline = this._timeline.slice(0, index + 1);
				}
			} else {
				this._timeline = [];
			}
		} else if (this._timeline.length === 1){
			//the first item's time
			if (this._timeline[0].time >= after){
				this._timeline = [];
			}
		}
		return this;
	};

	/**
	 *  Cancel events before or equal to the given time.
	 *  @param  {Number}  time  The time to cancel before.
	 *  @returns {Tone.Timeline} this
	 */
	Tone.Timeline.prototype.cancelBefore = function(time){
		if (this._timeline.length){
			var index = this._search(time);
			if (index >= 0){
				this._timeline = this._timeline.slice(index + 1);
			}
		}
		return this;
	};

	/**
	 *  Does a binary serach on the timeline array and returns the 
	 *  nearest event index whose time is after or equal to the given time.
	 *  If a time is searched before the first index in the timeline, -1 is returned.
	 *  If the time is after the end, the index of the last item is returned.
	 *  @param  {Number}  time  
	 *  @return  {Number} the index in the timeline array 
	 *  @private
	 */
	Tone.Timeline.prototype._search = function(time){
		var beginning = 0;
		var len = this._timeline.length;
		var end = len;
		if (len > 0 && this._timeline[len - 1].time <= time){
			return len - 1;
		}
		while (beginning < end){
			// calculate the midpoint for roughly equal partition
			var midPoint = Math.floor(beginning + (end - beginning) / 2);
			var event = this._timeline[midPoint];
			var nextEvent = this._timeline[midPoint + 1];
			if (event.time === time){
				//choose the last one that has the same time
				for (var i = midPoint; i < this._timeline.length; i++){
					var testEvent = this._timeline[i];
					if (testEvent.time === time){
						midPoint = i;
					}
				}
				return midPoint;
			} else if (event.time < time && nextEvent.time > time){
				return midPoint;
			} else if (event.time > time){
				//search lower
				end = midPoint;
			} else if (event.time < time){
				//search upper
				beginning = midPoint + 1;
			} 
		}
		return -1;
	};

	/**
	 *  Internal iterator. Applies extra safety checks for 
	 *  removing items from the array. 
	 *  @param  {Function}  callback 
	 *  @param  {Number=}    lowerBound     
	 *  @param  {Number=}    upperBound    
	 *  @private
	 */
	Tone.Timeline.prototype._iterate = function(callback, lowerBound, upperBound){
		this._iterating = true;
		lowerBound = this.defaultArg(lowerBound, 0);
		upperBound = this.defaultArg(upperBound, this._timeline.length - 1);
		for (var i = lowerBound; i <= upperBound; i++){
			callback(this._timeline[i]);
		}
		this._iterating = false;
		if (this._toRemove.length > 0){
			for (var j = 0; j < this._toRemove.length; j++){
				var index = this._timeline.indexOf(this._toRemove[j]);
				if (index !== -1){
					this._timeline.splice(index, 1);
				}
			}
			this._toRemove = [];
		}
	};

	/**
	 *  Iterate over everything in the array
	 *  @param  {Function}  callback The callback to invoke with every item
	 *  @returns {Tone.Timeline} this
	 */
	Tone.Timeline.prototype.forEach = function(callback){
		this._iterate(callback);
		return this;
	};

	/**
	 *  Iterate over everything in the array at or before the given time.
	 *  @param  {Number}  time The time to check if items are before
	 *  @param  {Function}  callback The callback to invoke with every item
	 *  @returns {Tone.Timeline} this
	 */
	Tone.Timeline.prototype.forEachBefore = function(time, callback){
		//iterate over the items in reverse so that removing an item doesn't break things
		var upperBound = this._search(time);
		if (upperBound !== -1){
			this._iterate(callback, 0, upperBound);
		}
		return this;
	};

	/**
	 *  Iterate over everything in the array after the given time.
	 *  @param  {Number}  time The time to check if items are before
	 *  @param  {Function}  callback The callback to invoke with every item
	 *  @returns {Tone.Timeline} this
	 */
	Tone.Timeline.prototype.forEachAfter = function(time, callback){
		//iterate over the items in reverse so that removing an item doesn't break things
		var lowerBound = this._search(time);
		this._iterate(callback, lowerBound + 1);
		return this;
	};

	/**
	 *  Iterate over everything in the array at or after the given time. Similar to 
	 *  forEachAfter, but includes the item(s) at the given time.
	 *  @param  {Number}  time The time to check if items are before
	 *  @param  {Function}  callback The callback to invoke with every item
	 *  @returns {Tone.Timeline} this
	 */
	Tone.Timeline.prototype.forEachFrom = function(time, callback){
		//iterate over the items in reverse so that removing an item doesn't break things
		var lowerBound = this._search(time);
		//work backwards until the event time is less than time
		while (lowerBound >= 0 && this._timeline[lowerBound].time >= time){
			lowerBound--;
		}
		this._iterate(callback, lowerBound + 1);
		return this;
	};

	/**
	 *  Iterate over everything in the array at the given time
	 *  @param  {Number}  time The time to check if items are before
	 *  @param  {Function}  callback The callback to invoke with every item
	 *  @returns {Tone.Timeline} this
	 */
	Tone.Timeline.prototype.forEachAtTime = function(time, callback){
		//iterate over the items in reverse so that removing an item doesn't break things
		var upperBound = this._search(time);
		if (upperBound !== -1){
			this._iterate(function(event){
				if (event.time === time){
					callback(event);
				} 
			}, 0, upperBound);
		}
		return this;
	};

	/**
	 *  Clean up.
	 *  @return  {Tone.Timeline}  this
	 */
	Tone.Timeline.prototype.dispose = function(){
		Tone.prototype.dispose.call(this);
		this._timeline = null;
		this._toRemove = null;
	};

	return Tone.Timeline;
});
define('Tone/signal/TimelineSignal',["Tone/core/Tone", "Tone/signal/Signal", "Tone/core/Timeline"], function (Tone) {

	"use strict";

	/**
	 *  @class A signal which adds the method getValueAtTime. 
	 *         Code and inspiration from https://github.com/jsantell/web-audio-automation-timeline
	 *  @extends {Tone.Param}
	 *  @param {Number=} value The initial value of the signal
	 *  @param {String=} units The conversion units of the signal.
	 */
	Tone.TimelineSignal = function(){

		var options = this.optionsObject(arguments, ["value", "units"], Tone.Signal.defaults);
		
		/**
		 *  The scheduled events
		 *  @type {Tone.Timeline}
		 *  @private
		 */
		this._events = new Tone.Timeline(10);

		//constructors
		Tone.Signal.apply(this, options);
		options.param = this._param;
		Tone.Param.call(this, options);

		/**
		 *  The initial scheduled value
		 *  @type {Number}
		 *  @private
		 */
		this._initial = this._fromUnits(this._param.value);
	};

	Tone.extend(Tone.TimelineSignal, Tone.Param);

	/**
	 *  The event types of a schedulable signal.
	 *  @enum {String}
	 *  @private
	 */
	Tone.TimelineSignal.Type = {
		Linear : "linear",
		Exponential : "exponential",
		Target : "target",
		Curve : "curve",
		Set : "set"
	};

	/**
	 * The current value of the signal. 
	 * @memberOf Tone.TimelineSignal#
	 * @type {Number}
	 * @name value
	 */
	Object.defineProperty(Tone.TimelineSignal.prototype, "value", {
		get : function(){
			var now = this.now();
			var val = this.getValueAtTime(now);
			return this._toUnits(val);
		},
		set : function(value){
			var convertedVal = this._fromUnits(value);
			this._initial = convertedVal;
			this.cancelScheduledValues();
			this._param.value = convertedVal;
		}
	});

	///////////////////////////////////////////////////////////////////////////
	//	SCHEDULING
	///////////////////////////////////////////////////////////////////////////

	/**
	 *  Schedules a parameter value change at the given time.
	 *  @param {*}	value The value to set the signal.
	 *  @param {Time}  time The time when the change should occur.
	 *  @returns {Tone.TimelineSignal} this
	 *  @example
	 * //set the frequency to "G4" in exactly 1 second from now. 
	 * freq.setValueAtTime("G4", "+1");
	 */
	Tone.TimelineSignal.prototype.setValueAtTime = function (value, startTime) {
		value = this._fromUnits(value);
		startTime = this.toSeconds(startTime);
		this._events.add({
			"type" : Tone.TimelineSignal.Type.Set,
			"value" : value,
			"time" : startTime
		});
		//invoke the original event
		this._param.setValueAtTime(value, startTime);
		return this;
	};

	/**
	 *  Schedules a linear continuous change in parameter value from the 
	 *  previous scheduled parameter value to the given value.
	 *  
	 *  @param  {number} value   
	 *  @param  {Time} endTime 
	 *  @returns {Tone.TimelineSignal} this
	 */
	Tone.TimelineSignal.prototype.linearRampToValueAtTime = function (value, endTime) {
		value = this._fromUnits(value);
		endTime = this.toSeconds(endTime);
		this._events.add({
			"type" : Tone.TimelineSignal.Type.Linear,
			"value" : value,
			"time" : endTime
		});
		this._param.linearRampToValueAtTime(value, endTime);
		return this;
	};

	/**
	 *  Schedules an exponential continuous change in parameter value from 
	 *  the previous scheduled parameter value to the given value.
	 *  
	 *  @param  {number} value   
	 *  @param  {Time} endTime 
	 *  @returns {Tone.TimelineSignal} this
	 */
	Tone.TimelineSignal.prototype.exponentialRampToValueAtTime = function (value, endTime) {
		//get the previous event and make sure it's not starting from 0
		endTime = this.toSeconds(endTime);
		var beforeEvent = this._searchBefore(endTime);
		if (beforeEvent && beforeEvent.value === 0){
			//reschedule that event
			this.setValueAtTime(this._minOutput, beforeEvent.time);
		}
		value = this._fromUnits(value);
		var setValue = Math.max(value, this._minOutput);
		this._events.add({
			"type" : Tone.TimelineSignal.Type.Exponential,
			"value" : setValue,
			"time" : endTime
		});
		//if the ramped to value is 0, make it go to the min output, and then set to 0.
		if (value < this._minOutput){
			this._param.exponentialRampToValueAtTime(this._minOutput, endTime - this.sampleTime);
			this.setValueAtTime(0, endTime);
		} else {
			this._param.exponentialRampToValueAtTime(value, endTime);
		}
		return this;
	};

	/**
	 *  Start exponentially approaching the target value at the given time with
	 *  a rate having the given time constant.
	 *  @param {number} value        
	 *  @param {Time} startTime    
	 *  @param {number} timeConstant 
	 *  @returns {Tone.TimelineSignal} this 
	 */
	Tone.TimelineSignal.prototype.setTargetAtTime = function (value, startTime, timeConstant) {
		value = this._fromUnits(value);
		value = Math.max(this._minOutput, value);
		timeConstant = Math.max(this._minOutput, timeConstant);
		startTime = this.toSeconds(startTime);
		this._events.add({
			"type" : Tone.TimelineSignal.Type.Target,
			"value" : value,
			"time" : startTime,
			"constant" : timeConstant
		});
		this._param.setTargetAtTime(value, startTime, timeConstant);
		return this;
	};

	/**
	 *  Set an array of arbitrary values starting at the given time for the given duration.
	 *  @param {Float32Array} values        
	 *  @param {Time} startTime    
	 *  @param {Time} duration
	 *  @param {NormalRange} [scaling=1] If the values in the curve should be scaled by some value
	 *  @returns {Tone.TimelineSignal} this 
	 */
	Tone.TimelineSignal.prototype.setValueCurveAtTime = function (values, startTime, duration, scaling) {
		scaling = this.defaultArg(scaling, 1);
		//copy the array
		var floats = new Array(values.length);
		for (var i = 0; i < floats.length; i++){
			floats[i] = this._fromUnits(values[i]) * scaling;
		}
		startTime = this.toSeconds(startTime);
		duration = this.toSeconds(duration);
		this._events.add({
			"type" : Tone.TimelineSignal.Type.Curve,
			"value" : floats,
			"time" : startTime,
			"duration" : duration
		});
		//set the first value
		this._param.setValueAtTime(floats[0], startTime);
		//schedule a lienar ramp for each of the segments
		for (var j = 1; j < floats.length; j++){
			var segmentTime = startTime + (j / (floats.length - 1) * duration);
			this._param.linearRampToValueAtTime(floats[j], segmentTime);
		}
		return this;
	};

	/**
	 *  Cancels all scheduled parameter changes with times greater than or 
	 *  equal to startTime.
	 *  
	 *  @param  {Time} startTime
	 *  @returns {Tone.TimelineSignal} this
	 */
	Tone.TimelineSignal.prototype.cancelScheduledValues = function (after) {
		after = this.toSeconds(after);
		this._events.cancel(after);
		this._param.cancelScheduledValues(after);
		return this;
	};

	/**
	 *  Sets the computed value at the given time. This provides
	 *  a point from which a linear or exponential curve
	 *  can be scheduled after. Will cancel events after 
	 *  the given time and shorten the currently scheduled
	 *  linear or exponential ramp so that it ends at `time` .
	 *  This is to avoid discontinuities and clicks in envelopes. 
	 *  @param {Time} time When to set the ramp point
	 *  @returns {Tone.TimelineSignal} this
	 */
	Tone.TimelineSignal.prototype.setRampPoint = function (time) {
		time = this.toSeconds(time);
		//get the value at the given time
		var val = this._toUnits(this.getValueAtTime(time));
		//if there is an event at the given time
		//and that even is not a "set"
		var before = this._searchBefore(time);
		if (before && before.time === time){
			//remove everything after
			this.cancelScheduledValues(time + this.sampleTime);
		} else if (before && 
				   before.type === Tone.TimelineSignal.Type.Curve &&
				   before.time + before.duration > time){
			//if the curve is still playing
			//cancel the curve
			this.cancelScheduledValues(time);
			this.linearRampToValueAtTime(val, time);
		} else {
			//reschedule the next event to end at the given time
			var after = this._searchAfter(time);
			if (after){
				//cancel the next event(s)
				this.cancelScheduledValues(time);
				if (after.type === Tone.TimelineSignal.Type.Linear){
					this.linearRampToValueAtTime(val, time);
				} else if (after.type === Tone.TimelineSignal.Type.Exponential){
					this.exponentialRampToValueAtTime(val, time);
				}
			}
			this.setValueAtTime(val, time);
		}
		return this;
	};

	/**
	 *  Do a linear ramp to the given value between the start and finish times.
	 *  @param {Number} value The value to ramp to.
	 *  @param {Time} start The beginning anchor point to do the linear ramp
	 *  @param {Time} finish The ending anchor point by which the value of
	 *                       the signal will equal the given value.
	 *  @returns {Tone.TimelineSignal} this
	 */
	Tone.TimelineSignal.prototype.linearRampToValueBetween = function (value, start, finish) {
		this.setRampPoint(start);
		this.linearRampToValueAtTime(value, finish);
		return this;
	};

	/**
	 *  Do a exponential ramp to the given value between the start and finish times.
	 *  @param {Number} value The value to ramp to.
	 *  @param {Time} start The beginning anchor point to do the exponential ramp
	 *  @param {Time} finish The ending anchor point by which the value of
	 *                       the signal will equal the given value.
	 *  @returns {Tone.TimelineSignal} this
	 */
	Tone.TimelineSignal.prototype.exponentialRampToValueBetween = function (value, start, finish) {
		this.setRampPoint(start);
		this.exponentialRampToValueAtTime(value, finish);
		return this;
	};

	///////////////////////////////////////////////////////////////////////////
	//	GETTING SCHEDULED VALUES
	///////////////////////////////////////////////////////////////////////////

	/**
	 *  Returns the value before or equal to the given time
	 *  @param  {Number}  time  The time to query
	 *  @return  {Object}  The event at or before the given time.
	 *  @private
	 */
	Tone.TimelineSignal.prototype._searchBefore = function(time){
		return this._events.get(time);
	};

	/**
	 *  The event after the given time
	 *  @param  {Number}  time  The time to query.
	 *  @return  {Object}  The next event after the given time
	 *  @private
	 */
	Tone.TimelineSignal.prototype._searchAfter = function(time){
		return this._events.getAfter(time);
	};

	/**
	 *  Get the scheduled value at the given time. This will
	 *  return the unconverted (raw) value.
	 *  @param  {Number}  time  The time in seconds.
	 *  @return  {Number}  The scheduled value at the given time.
	 */
	Tone.TimelineSignal.prototype.getValueAtTime = function(time){
		time = this.toSeconds(time);
		var after = this._searchAfter(time);
		var before = this._searchBefore(time);
		var value = this._initial;
		//if it was set by
		if (before === null){
			value = this._initial;
		} else if (before.type === Tone.TimelineSignal.Type.Target){
			var previous = this._events.getBefore(before.time);
			var previouVal;
			if (previous === null){
				previouVal = this._initial;
			} else {
				previouVal = previous.value;
			}
			value = this._exponentialApproach(before.time, previouVal, before.value, before.constant, time);
		} else if (before.type === Tone.TimelineSignal.Type.Curve){
			value = this._curveInterpolate(before.time, before.value, before.duration, time);
		} else if (after === null){
			value = before.value;
		} else if (after.type === Tone.TimelineSignal.Type.Linear){
			value = this._linearInterpolate(before.time, before.value, after.time, after.value, time);
		} else if (after.type === Tone.TimelineSignal.Type.Exponential){
			value = this._exponentialInterpolate(before.time, before.value, after.time, after.value, time);
		} else {
			value = before.value;
		}
		return value;
	};

	/**
	 *  When signals connect to other signals or AudioParams, 
	 *  they take over the output value of that signal or AudioParam. 
	 *  For all other nodes, the behavior is the same as a default <code>connect</code>. 
	 *
	 *  @override
	 *  @param {AudioParam|AudioNode|Tone.Signal|Tone} node 
	 *  @param {number} [outputNumber=0] The output number to connect from.
	 *  @param {number} [inputNumber=0] The input number to connect to.
	 *  @returns {Tone.TimelineSignal} this
	 *  @method
	 */
	Tone.TimelineSignal.prototype.connect = Tone.SignalBase.prototype.connect;


	///////////////////////////////////////////////////////////////////////////
	//	AUTOMATION CURVE CALCULATIONS
	//	MIT License, copyright (c) 2014 Jordan Santell
	///////////////////////////////////////////////////////////////////////////

	/**
	 *  Calculates the the value along the curve produced by setTargetAtTime
	 *  @private
	 */
	Tone.TimelineSignal.prototype._exponentialApproach = function (t0, v0, v1, timeConstant, t) {
		return v1 + (v0 - v1) * Math.exp(-(t - t0) / timeConstant);
	};

	/**
	 *  Calculates the the value along the curve produced by linearRampToValueAtTime
	 *  @private
	 */
	Tone.TimelineSignal.prototype._linearInterpolate = function (t0, v0, t1, v1, t) {
		return v0 + (v1 - v0) * ((t - t0) / (t1 - t0));
	};

	/**
	 *  Calculates the the value along the curve produced by exponentialRampToValueAtTime
	 *  @private
	 */
	Tone.TimelineSignal.prototype._exponentialInterpolate = function (t0, v0, t1, v1, t) {
		v0 = Math.max(this._minOutput, v0);
		return v0 * Math.pow(v1 / v0, (t - t0) / (t1 - t0));
	};

	/**
	 *  Calculates the the value along the curve produced by setValueCurveAtTime
	 *  @private
	 */
	Tone.TimelineSignal.prototype._curveInterpolate = function (start, curve, duration, time) {
		var len = curve.length;
		// If time is after duration, return the last curve value
		if (time >= start + duration) {
			return curve[len - 1];
		} else if (time <= start){
			return curve[0];
		} else {
			var progress = (time - start) / duration;
			var lowerIndex = Math.floor((len - 1) * progress);
			var upperIndex = Math.ceil((len - 1) * progress);
			var lowerVal = curve[lowerIndex];
			var upperVal = curve[upperIndex];
			if (upperIndex === lowerIndex){
				return lowerVal;
			} else {
				return this._linearInterpolate(lowerIndex, lowerVal, upperIndex, upperVal, progress * (len - 1));
			}
		}
	};

	/**
	 *  Clean up.
	 *  @return {Tone.TimelineSignal} this
	 */
	Tone.TimelineSignal.prototype.dispose = function(){
		Tone.Signal.prototype.dispose.call(this);
		Tone.Param.prototype.dispose.call(this);
		this._events.dispose();
		this._events = null;
	};

	return Tone.TimelineSignal;
});
var envelope;
'use strict';
envelope = function () {
    var p5sound = master;
    var Add = Tone_signal_Add;
    var Mult = Tone_signal_Multiply;
    var Scale = Tone_signal_Scale;
    var TimelineSignal = Tone_signal_TimelineSignal;
    var Tone = Tone_core_Tone;
    Tone.setContext(p5sound.audiocontext);
    p5.Envelope = function (t1, l1, t2, l2, t3, l3) {
        this.aTime = t1 || 0.1;
        this.aLevel = l1 || 1;
        this.dTime = t2 || 0.5;
        this.dLevel = l2 || 0;
        this.rTime = t3 || 0;
        this.rLevel = l3 || 0;
        this._rampHighPercentage = 0.98;
        this._rampLowPercentage = 0.02;
        this.output = p5sound.audiocontext.createGain();
        this.control = new TimelineSignal();
        this._init();
        this.control.connect(this.output);
        this.connection = null;
        this.mathOps = [this.control];
        this.isExponential = false;
        this.sourceToClear = null;
        this.wasTriggered = false;
        p5sound.soundArray.push(this);
    };
    p5.Envelope.prototype._init = function () {
        var now = p5sound.audiocontext.currentTime;
        var t = now;
        this.control.setTargetAtTime(0.00001, t, 0.001);
        this._setRampAD(this.aTime, this.dTime);
    };
    p5.Envelope.prototype.set = function (t1, l1, t2, l2, t3, l3) {
        this.aTime = t1;
        this.aLevel = l1;
        this.dTime = t2 || 0;
        this.dLevel = l2 || 0;
        this.rTime = t3 || 0;
        this.rLevel = l3 || 0;
        this._setRampAD(t1, t2);
    };
    p5.Envelope.prototype.setADSR = function (aTime, dTime, sPercent, rTime) {
        this.aTime = aTime;
        this.dTime = dTime || 0;
        this.sPercent = sPercent || 0;
        this.dLevel = typeof sPercent !== 'undefined' ? sPercent * (this.aLevel - this.rLevel) + this.rLevel : 0;
        this.rTime = rTime || 0;
        this._setRampAD(aTime, dTime);
    };
    p5.Envelope.prototype.setRange = function (aLevel, rLevel) {
        this.aLevel = aLevel || 1;
        this.rLevel = rLevel || 0;
    };
    p5.Envelope.prototype._setRampAD = function (t1, t2) {
        this._rampAttackTime = this.checkExpInput(t1);
        this._rampDecayTime = this.checkExpInput(t2);
        var TCDenominator = 1;
        TCDenominator = Math.log(1 / this.checkExpInput(1 - this._rampHighPercentage));
        this._rampAttackTC = t1 / this.checkExpInput(TCDenominator);
        TCDenominator = Math.log(1 / this._rampLowPercentage);
        this._rampDecayTC = t2 / this.checkExpInput(TCDenominator);
    };
    p5.Envelope.prototype.setRampPercentages = function (p1, p2) {
        this._rampHighPercentage = this.checkExpInput(p1);
        this._rampLowPercentage = this.checkExpInput(p2);
        var TCDenominator = 1;
        TCDenominator = Math.log(1 / this.checkExpInput(1 - this._rampHighPercentage));
        this._rampAttackTC = this._rampAttackTime / this.checkExpInput(TCDenominator);
        TCDenominator = Math.log(1 / this._rampLowPercentage);
        this._rampDecayTC = this._rampDecayTime / this.checkExpInput(TCDenominator);
    };
    p5.Envelope.prototype.setInput = function () {
        for (var i = 0; i < arguments.length; i++) {
            this.connect(arguments[i]);
        }
    };
    p5.Envelope.prototype.setExp = function (isExp) {
        this.isExponential = isExp;
    };
    p5.Envelope.prototype.checkExpInput = function (value) {
        if (value <= 0) {
            value = 1e-8;
        }
        return value;
    };
    p5.Envelope.prototype.play = function (unit, secondsFromNow, susTime) {
        var tFromNow = secondsFromNow || 0;
        var susTime = susTime || 0;
        if (unit) {
            if (this.connection !== unit) {
                this.connect(unit);
            }
        }
        this.triggerAttack(unit, tFromNow);
        this.triggerRelease(unit, tFromNow + this.aTime + this.dTime + susTime);
    };
    p5.Envelope.prototype.triggerAttack = function (unit, secondsFromNow) {
        var now = p5sound.audiocontext.currentTime;
        var tFromNow = secondsFromNow || 0;
        var t = now + tFromNow;
        this.lastAttack = t;
        this.wasTriggered = true;
        if (unit) {
            if (this.connection !== unit) {
                this.connect(unit);
            }
        }
        var valToSet = this.control.getValueAtTime(t);
        if (this.isExponential === true) {
            this.control.exponentialRampToValueAtTime(this.checkExpInput(valToSet), t);
        } else {
            this.control.linearRampToValueAtTime(valToSet, t);
        }
        t += this.aTime;
        if (this.isExponential === true) {
            this.control.exponentialRampToValueAtTime(this.checkExpInput(this.aLevel), t);
            valToSet = this.checkExpInput(this.control.getValueAtTime(t));
            this.control.cancelScheduledValues(t);
            this.control.exponentialRampToValueAtTime(valToSet, t);
        } else {
            this.control.linearRampToValueAtTime(this.aLevel, t);
            valToSet = this.control.getValueAtTime(t);
            this.control.cancelScheduledValues(t);
            this.control.linearRampToValueAtTime(valToSet, t);
        }
        t += this.dTime;
        if (this.isExponential === true) {
            this.control.exponentialRampToValueAtTime(this.checkExpInput(this.dLevel), t);
            valToSet = this.checkExpInput(this.control.getValueAtTime(t));
            this.control.cancelScheduledValues(t);
            this.control.exponentialRampToValueAtTime(valToSet, t);
        } else {
            this.control.linearRampToValueAtTime(this.dLevel, t);
            valToSet = this.control.getValueAtTime(t);
            this.control.cancelScheduledValues(t);
            this.control.linearRampToValueAtTime(valToSet, t);
        }
    };
    p5.Envelope.prototype.triggerRelease = function (unit, secondsFromNow) {
        if (!this.wasTriggered) {
            return;
        }
        var now = p5sound.audiocontext.currentTime;
        var tFromNow = secondsFromNow || 0;
        var t = now + tFromNow;
        if (unit) {
            if (this.connection !== unit) {
                this.connect(unit);
            }
        }
        var valToSet = this.control.getValueAtTime(t);
        if (this.isExponential === true) {
            this.control.exponentialRampToValueAtTime(this.checkExpInput(valToSet), t);
        } else {
            this.control.linearRampToValueAtTime(valToSet, t);
        }
        t += this.rTime;
        if (this.isExponential === true) {
            this.control.exponentialRampToValueAtTime(this.checkExpInput(this.rLevel), t);
            valToSet = this.checkExpInput(this.control.getValueAtTime(t));
            this.control.cancelScheduledValues(t);
            this.control.exponentialRampToValueAtTime(valToSet, t);
        } else {
            this.control.linearRampToValueAtTime(this.rLevel, t);
            valToSet = this.control.getValueAtTime(t);
            this.control.cancelScheduledValues(t);
            this.control.linearRampToValueAtTime(valToSet, t);
        }
        this.wasTriggered = false;
    };
    p5.Envelope.prototype.ramp = function (unit, secondsFromNow, v1, v2) {
        var now = p5sound.audiocontext.currentTime;
        var tFromNow = secondsFromNow || 0;
        var t = now + tFromNow;
        var destination1 = this.checkExpInput(v1);
        var destination2 = typeof v2 !== 'undefined' ? this.checkExpInput(v2) : undefined;
        if (unit) {
            if (this.connection !== unit) {
                this.connect(unit);
            }
        }
        var currentVal = this.checkExpInput(this.control.getValueAtTime(t));
        if (destination1 > currentVal) {
            this.control.setTargetAtTime(destination1, t, this._rampAttackTC);
            t += this._rampAttackTime;
        } else if (destination1 < currentVal) {
            this.control.setTargetAtTime(destination1, t, this._rampDecayTC);
            t += this._rampDecayTime;
        }
        if (destination2 === undefined)
            return;
        if (destination2 > destination1) {
            this.control.setTargetAtTime(destination2, t, this._rampAttackTC);
        } else if (destination2 < destination1) {
            this.control.setTargetAtTime(destination2, t, this._rampDecayTC);
        }
    };
    p5.Envelope.prototype.connect = function (unit) {
        this.connection = unit;
        if (unit instanceof p5.Oscillator || unit instanceof p5.SoundFile || unit instanceof p5.AudioIn || unit instanceof p5.Reverb || unit instanceof p5.Noise || unit instanceof p5.Filter || unit instanceof p5.Delay) {
            unit = unit.output.gain;
        }
        if (unit instanceof AudioParam) {
            unit.setValueAtTime(0, p5sound.audiocontext.currentTime);
        }
        if (unit instanceof p5.Signal) {
            unit.setValue(0);
        }
        this.output.connect(unit);
    };
    p5.Envelope.prototype.disconnect = function () {
        if (this.output) {
            this.output.disconnect();
        }
    };
    p5.Envelope.prototype.add = function (num) {
        var add = new Add(num);
        var thisChain = this.mathOps.length;
        var nextChain = this.output;
        return p5.prototype._mathChain(this, add, thisChain, nextChain, Add);
    };
    p5.Envelope.prototype.mult = function (num) {
        var mult = new Mult(num);
        var thisChain = this.mathOps.length;
        var nextChain = this.output;
        return p5.prototype._mathChain(this, mult, thisChain, nextChain, Mult);
    };
    p5.Envelope.prototype.scale = function (inMin, inMax, outMin, outMax) {
        var scale = new Scale(inMin, inMax, outMin, outMax);
        var thisChain = this.mathOps.length;
        var nextChain = this.output;
        return p5.prototype._mathChain(this, scale, thisChain, nextChain, Scale);
    };
    p5.Envelope.prototype.dispose = function () {
        var index = p5sound.soundArray.indexOf(this);
        p5sound.soundArray.splice(index, 1);
        this.disconnect();
        if (this.control) {
            this.control.dispose();
            this.control = null;
        }
        for (var i = 1; i < this.mathOps.length; i++) {
            this.mathOps[i].dispose();
        }
    };
    p5.Env = function (t1, l1, t2, l2, t3, l3) {
        console.warn('WARNING: p5.Env is now deprecated and may be removed in future versions. ' + 'Please use the new p5.Envelope instead.');
        p5.Envelope.call(this, t1, l1, t2, l2, t3, l3);
    };
    p5.Env.prototype = Object.create(p5.Envelope.prototype);
}(master, Tone_signal_Add, Tone_signal_Multiply, Tone_signal_Scale, Tone_signal_TimelineSignal, Tone_core_Tone);
var pulse;
'use strict';
pulse = function () {
    var p5sound = master;
    p5.Pulse = function (freq, w) {
        p5.Oscillator.call(this, freq, 'sawtooth');
        this.w = w || 0;
        this.osc2 = new p5.SawOsc(freq);
        this.dNode = p5sound.audiocontext.createDelay();
        this.dcOffset = createDCOffset();
        this.dcGain = p5sound.audiocontext.createGain();
        this.dcOffset.connect(this.dcGain);
        this.dcGain.connect(this.output);
        this.f = freq || 440;
        var mW = this.w / this.oscillator.frequency.value;
        this.dNode.delayTime.value = mW;
        this.dcGain.gain.value = 1.7 * (0.5 - this.w);
        this.osc2.disconnect();
        this.osc2.panner.disconnect();
        this.osc2.amp(-1);
        this.osc2.output.connect(this.dNode);
        this.dNode.connect(this.output);
        this.output.gain.value = 1;
        this.output.connect(this.panner);
    };
    p5.Pulse.prototype = Object.create(p5.Oscillator.prototype);
    p5.Pulse.prototype.width = function (w) {
        if (typeof w === 'number') {
            if (w <= 1 && w >= 0) {
                this.w = w;
                var mW = this.w / this.oscillator.frequency.value;
                this.dNode.delayTime.value = mW;
            }
            this.dcGain.gain.value = 1.7 * (0.5 - this.w);
        } else {
            w.connect(this.dNode.delayTime);
            var sig = new p5.SignalAdd(-0.5);
            sig.setInput(w);
            sig = sig.mult(-1);
            sig = sig.mult(1.7);
            sig.connect(this.dcGain.gain);
        }
    };
    p5.Pulse.prototype.start = function (f, time) {
        var now = p5sound.audiocontext.currentTime;
        var t = time || 0;
        if (!this.started) {
            var freq = f || this.f;
            var type = this.oscillator.type;
            this.oscillator = p5sound.audiocontext.createOscillator();
            this.oscillator.frequency.setValueAtTime(freq, now);
            this.oscillator.type = type;
            this.oscillator.connect(this.output);
            this.oscillator.start(t + now);
            this.osc2.oscillator = p5sound.audiocontext.createOscillator();
            this.osc2.oscillator.frequency.setValueAtTime(freq, t + now);
            this.osc2.oscillator.type = type;
            this.osc2.oscillator.connect(this.osc2.output);
            this.osc2.start(t + now);
            this.freqNode = [
                this.oscillator.frequency,
                this.osc2.oscillator.frequency
            ];
            this.dcOffset = createDCOffset();
            this.dcOffset.connect(this.dcGain);
            this.dcOffset.start(t + now);
            if (this.mods !== undefined && this.mods.frequency !== undefined) {
                this.mods.frequency.connect(this.freqNode[0]);
                this.mods.frequency.connect(this.freqNode[1]);
            }
            this.started = true;
            this.osc2.started = true;
        }
    };
    p5.Pulse.prototype.stop = function (time) {
        if (this.started) {
            var t = time || 0;
            var now = p5sound.audiocontext.currentTime;
            this.oscillator.stop(t + now);
            if (this.osc2.oscillator) {
                this.osc2.oscillator.stop(t + now);
            }
            this.dcOffset.stop(t + now);
            this.started = false;
            this.osc2.started = false;
        }
    };
    p5.Pulse.prototype.freq = function (val, rampTime, tFromNow) {
        if (typeof val === 'number') {
            this.f = val;
            var now = p5sound.audiocontext.currentTime;
            var rampTime = rampTime || 0;
            var tFromNow = tFromNow || 0;
            var currentFreq = this.oscillator.frequency.value;
            this.oscillator.frequency.cancelScheduledValues(now);
            this.oscillator.frequency.setValueAtTime(currentFreq, now + tFromNow);
            this.oscillator.frequency.exponentialRampToValueAtTime(val, tFromNow + rampTime + now);
            this.osc2.oscillator.frequency.cancelScheduledValues(now);
            this.osc2.oscillator.frequency.setValueAtTime(currentFreq, now + tFromNow);
            this.osc2.oscillator.frequency.exponentialRampToValueAtTime(val, tFromNow + rampTime + now);
            if (this.freqMod) {
                this.freqMod.output.disconnect();
                this.freqMod = null;
            }
        } else if (val.output) {
            val.output.disconnect();
            val.output.connect(this.oscillator.frequency);
            val.output.connect(this.osc2.oscillator.frequency);
            this.freqMod = val;
        }
    };
    function createDCOffset() {
        var ac = p5sound.audiocontext;
        var buffer = ac.createBuffer(1, 2048, ac.sampleRate);
        var data = buffer.getChannelData(0);
        for (var i = 0; i < 2048; i++)
            data[i] = 1;
        var bufferSource = ac.createBufferSource();
        bufferSource.buffer = buffer;
        bufferSource.loop = true;
        return bufferSource;
    }
}(master, oscillator);
var noise;
'use strict';
noise = function () {
    var p5sound = master;
    p5.Noise = function (type) {
        var assignType;
        p5.Oscillator.call(this);
        delete this.f;
        delete this.freq;
        delete this.oscillator;
        if (type === 'brown') {
            assignType = _brownNoise;
        } else if (type === 'pink') {
            assignType = _pinkNoise;
        } else {
            assignType = _whiteNoise;
        }
        this.buffer = assignType;
    };
    p5.Noise.prototype = Object.create(p5.Oscillator.prototype);
    var _whiteNoise = function () {
        var bufferSize = 2 * p5sound.audiocontext.sampleRate;
        var whiteBuffer = p5sound.audiocontext.createBuffer(1, bufferSize, p5sound.audiocontext.sampleRate);
        var noiseData = whiteBuffer.getChannelData(0);
        for (var i = 0; i < bufferSize; i++) {
            noiseData[i] = Math.random() * 2 - 1;
        }
        whiteBuffer.type = 'white';
        return whiteBuffer;
    }();
    var _pinkNoise = function () {
        var bufferSize = 2 * p5sound.audiocontext.sampleRate;
        var pinkBuffer = p5sound.audiocontext.createBuffer(1, bufferSize, p5sound.audiocontext.sampleRate);
        var noiseData = pinkBuffer.getChannelData(0);
        var b0, b1, b2, b3, b4, b5, b6;
        b0 = b1 = b2 = b3 = b4 = b5 = b6 = 0;
        for (var i = 0; i < bufferSize; i++) {
            var white = Math.random() * 2 - 1;
            b0 = 0.99886 * b0 + white * 0.0555179;
            b1 = 0.99332 * b1 + white * 0.0750759;
            b2 = 0.969 * b2 + white * 0.153852;
            b3 = 0.8665 * b3 + white * 0.3104856;
            b4 = 0.55 * b4 + white * 0.5329522;
            b5 = -0.7616 * b5 - white * 0.016898;
            noiseData[i] = b0 + b1 + b2 + b3 + b4 + b5 + b6 + white * 0.5362;
            noiseData[i] *= 0.11;
            b6 = white * 0.115926;
        }
        pinkBuffer.type = 'pink';
        return pinkBuffer;
    }();
    var _brownNoise = function () {
        var bufferSize = 2 * p5sound.audiocontext.sampleRate;
        var brownBuffer = p5sound.audiocontext.createBuffer(1, bufferSize, p5sound.audiocontext.sampleRate);
        var noiseData = brownBuffer.getChannelData(0);
        var lastOut = 0;
        for (var i = 0; i < bufferSize; i++) {
            var white = Math.random() * 2 - 1;
            noiseData[i] = (lastOut + 0.02 * white) / 1.02;
            lastOut = noiseData[i];
            noiseData[i] *= 3.5;
        }
        brownBuffer.type = 'brown';
        return brownBuffer;
    }();
    p5.Noise.prototype.setType = function (type) {
        switch (type) {
        case 'white':
            this.buffer = _whiteNoise;
            break;
        case 'pink':
            this.buffer = _pinkNoise;
            break;
        case 'brown':
            this.buffer = _brownNoise;
            break;
        default:
            this.buffer = _whiteNoise;
        }
        if (this.started) {
            var now = p5sound.audiocontext.currentTime;
            this.stop(now);
            this.start(now + 0.01);
        }
    };
    p5.Noise.prototype.getType = function () {
        return this.buffer.type;
    };
    p5.Noise.prototype.start = function () {
        if (this.started) {
            this.stop();
        }
        this.noise = p5sound.audiocontext.createBufferSource();
        this.noise.buffer = this.buffer;
        this.noise.loop = true;
        this.noise.connect(this.output);
        var now = p5sound.audiocontext.currentTime;
        this.noise.start(now);
        this.started = true;
    };
    p5.Noise.prototype.stop = function () {
        var now = p5sound.audiocontext.currentTime;
        if (this.noise) {
            this.noise.stop(now);
            this.started = false;
        }
    };
    p5.Noise.prototype.dispose = function () {
        var now = p5sound.audiocontext.currentTime;
        var index = p5sound.soundArray.indexOf(this);
        p5sound.soundArray.splice(index, 1);
        if (this.noise) {
            this.noise.disconnect();
            this.stop(now);
        }
        if (this.output) {
            this.output.disconnect();
        }
        if (this.panner) {
            this.panner.disconnect();
        }
        this.output = null;
        this.panner = null;
        this.buffer = null;
        this.noise = null;
    };
}(master);
var audioin;
'use strict';
audioin = function () {
    var p5sound = master;
    p5sound.inputSources = [];
    p5.AudioIn = function (errorCallback) {
        this.input = p5sound.audiocontext.createGain();
        this.output = p5sound.audiocontext.createGain();
        this.stream = null;
        this.mediaStream = null;
        this.currentSource = null;
        this.enabled = false;
        this.amplitude = new p5.Amplitude();
        this.output.connect(this.amplitude.input);
        if (!window.MediaStreamTrack || !window.navigator.mediaDevices || !window.navigator.mediaDevices.getUserMedia) {
            errorCallback ? errorCallback() : window.alert('This browser does not support MediaStreamTrack and mediaDevices');
        }
        p5sound.soundArray.push(this);
    };
    p5.AudioIn.prototype.start = function (successCallback, errorCallback) {
        var self = this;
        if (this.stream) {
            this.stop();
        }
        var audioSource = p5sound.inputSources[self.currentSource];
        var constraints = {
            audio: {
                sampleRate: p5sound.audiocontext.sampleRate,
                echoCancellation: false
            }
        };
        if (p5sound.inputSources[this.currentSource]) {
            constraints.audio.deviceId = audioSource.deviceId;
        }
        window.navigator.mediaDevices.getUserMedia(constraints).then(function (stream) {
            self.stream = stream;
            self.enabled = true;
            self.mediaStream = p5sound.audiocontext.createMediaStreamSource(stream);
            self.mediaStream.connect(self.output);
            self.amplitude.setInput(self.output);
            if (successCallback)
                successCallback();
        }).catch(function (err) {
            if (errorCallback)
                errorCallback(err);
            else
                console.error(err);
        });
    };
    p5.AudioIn.prototype.stop = function () {
        if (this.stream) {
            this.stream.getTracks().forEach(function (track) {
                track.stop();
            });
            this.mediaStream.disconnect();
            delete this.mediaStream;
            delete this.stream;
        }
    };
    p5.AudioIn.prototype.connect = function (unit) {
        if (unit) {
            if (unit.hasOwnProperty('input')) {
                this.output.connect(unit.input);
            } else if (unit.hasOwnProperty('analyser')) {
                this.output.connect(unit.analyser);
            } else {
                this.output.connect(unit);
            }
        } else {
            this.output.connect(p5sound.input);
        }
    };
    p5.AudioIn.prototype.disconnect = function () {
        if (this.output) {
            this.output.disconnect();
            this.output.connect(this.amplitude.input);
        }
    };
    p5.AudioIn.prototype.getLevel = function (smoothing) {
        if (smoothing) {
            this.amplitude.smoothing = smoothing;
        }
        return this.amplitude.getLevel();
    };
    p5.AudioIn.prototype.amp = function (vol, t) {
        if (t) {
            var rampTime = t || 0;
            var currentVol = this.output.gain.value;
            this.output.gain.cancelScheduledValues(p5sound.audiocontext.currentTime);
            this.output.gain.setValueAtTime(currentVol, p5sound.audiocontext.currentTime);
            this.output.gain.linearRampToValueAtTime(vol, rampTime + p5sound.audiocontext.currentTime);
        } else {
            this.output.gain.cancelScheduledValues(p5sound.audiocontext.currentTime);
            this.output.gain.setValueAtTime(vol, p5sound.audiocontext.currentTime);
        }
    };
    p5.AudioIn.prototype.getSources = function (onSuccess, onError) {
        return new Promise(function (resolve, reject) {
            window.navigator.mediaDevices.enumerateDevices().then(function (devices) {
                p5sound.inputSources = devices.filter(function (device) {
                    return device.kind === 'audioinput';
                });
                resolve(p5sound.inputSources);
                if (onSuccess) {
                    onSuccess(p5sound.inputSources);
                }
            }).catch(function (error) {
                reject(error);
                if (onError) {
                    onError(error);
                } else {
                    console.error('This browser does not support MediaStreamTrack.getSources()');
                }
            });
        });
    };
    p5.AudioIn.prototype.setSource = function (num) {
        if (p5sound.inputSources.length > 0 && num < p5sound.inputSources.length) {
            this.currentSource = num;
            console.log('set source to ', p5sound.inputSources[this.currentSource]);
        } else {
            console.log('unable to set input source');
        }
        if (this.stream && this.stream.active) {
            this.start();
        }
    };
    p5.AudioIn.prototype.dispose = function () {
        var index = p5sound.soundArray.indexOf(this);
        p5sound.soundArray.splice(index, 1);
        this.stop();
        if (this.output) {
            this.output.disconnect();
        }
        if (this.amplitude) {
            this.amplitude.disconnect();
        }
        delete this.amplitude;
        delete this.output;
    };
}(master);
define('Tone/signal/Negate',["Tone/core/Tone", "Tone/signal/Multiply", "Tone/signal/Signal"], function(Tone){

	"use strict";

	/**
	 *  @class Negate the incoming signal. i.e. an input signal of 10 will output -10
	 *
	 *  @constructor
	 *  @extends {Tone.SignalBase}
	 *  @example
	 * var neg = new Tone.Negate();
	 * var sig = new Tone.Signal(-2).connect(neg);
	 * //output of neg is positive 2. 
	 */
	Tone.Negate = function(){
		/**
		 *  negation is done by multiplying by -1
		 *  @type {Tone.Multiply}
		 *  @private
		 */
		this._multiply = this.input = this.output = new Tone.Multiply(-1);
	};

	Tone.extend(Tone.Negate, Tone.SignalBase);

	/**
	 *  clean up
	 *  @returns {Tone.Negate} this
	 */
	Tone.Negate.prototype.dispose = function(){
		Tone.prototype.dispose.call(this);
		this._multiply.dispose();
		this._multiply = null;
		return this;
	}; 

	return Tone.Negate;
});
define('Tone/signal/Subtract',["Tone/core/Tone", "Tone/signal/Add", "Tone/signal/Negate", "Tone/signal/Signal", "Tone/core/Gain"], function(Tone){

	"use strict";

	/**
	 *  @class Subtract the signal connected to <code>input[1]</code> from the signal connected 
	 *         to <code>input[0]</code>. If an argument is provided in the constructor, the 
	 *         signals <code>.value</code> will be subtracted from the incoming signal.
	 *
	 *  @extends {Tone.Signal}
	 *  @constructor
	 *  @param {number=} value The value to subtract from the incoming signal. If the value
	 *                         is omitted, it will subtract the second signal from the first.
	 *  @example
	 * var sub = new Tone.Subtract(1);
	 * var sig = new Tone.Signal(4).connect(sub);
	 * //the output of sub is 3. 
	 *  @example
	 * var sub = new Tone.Subtract();
	 * var sigA = new Tone.Signal(10);
	 * var sigB = new Tone.Signal(2.5);
	 * sigA.connect(sub, 0, 0);
	 * sigB.connect(sub, 0, 1);
	 * //output of sub is 7.5
	 */
	Tone.Subtract = function(value){

		this.createInsOuts(2, 0);

		/**
		 *  the summing node
		 *  @type {GainNode}
		 *  @private
		 */
		this._sum = this.input[0] = this.output = new Tone.Gain();

		/**
		 *  negate the input of the second input before connecting it
		 *  to the summing node.
		 *  @type {Tone.Negate}
		 *  @private
		 */
		this._neg = new Tone.Negate();

		/**
		 *  the node where the value is set
		 *  @private
		 *  @type {Tone.Signal}
		 */
		this._param = this.input[1] = new Tone.Signal(value);

		this._param.chain(this._neg, this._sum);
	};

	Tone.extend(Tone.Subtract, Tone.Signal);

	/**
	 *  Clean up.
	 *  @returns {Tone.SignalBase} this
	 */
	Tone.Subtract.prototype.dispose = function(){
		Tone.prototype.dispose.call(this);
		this._neg.dispose();
		this._neg = null;
		this._sum.disconnect();
		this._sum = null;
		this._param.dispose();
		this._param = null;
		return this;
	};

	return Tone.Subtract;
});
define('Tone/signal/GreaterThanZero',["Tone/core/Tone", "Tone/signal/Signal", "Tone/signal/Multiply", "Tone/signal/WaveShaper"], 
function(Tone){

	"use strict";

	/**
	 *  @class  GreaterThanZero outputs 1 when the input is strictly greater than zero
	 *  
	 *  @constructor
	 *  @extends {Tone.SignalBase}
	 *  @example
	 * var gt0 = new Tone.GreaterThanZero();
	 * var sig = new Tone.Signal(0.01).connect(gt0);
	 * //the output of gt0 is 1. 
	 * sig.value = 0;
	 * //the output of gt0 is 0. 
	 */
	Tone.GreaterThanZero = function(){
		
		/**
		 *  @type {Tone.WaveShaper}
		 *  @private
		 */
		this._thresh = this.output = new Tone.WaveShaper(function(val){
			if (val <= 0){
				return 0;
			} else {
				return 1;
			}
		}, 127);

		/**
		 *  scale the first thresholded signal by a large value.
		 *  this will help with values which are very close to 0
		 *  @type {Tone.Multiply}
		 *  @private
		 */
		this._scale = this.input = new Tone.Multiply(10000);

		//connections
		this._scale.connect(this._thresh);
	};

	Tone.extend(Tone.GreaterThanZero, Tone.SignalBase);

	/**
	 *  dispose method
	 *  @returns {Tone.GreaterThanZero} this
	 */
	Tone.GreaterThanZero.prototype.dispose = function(){
		Tone.prototype.dispose.call(this);
		this._scale.dispose();
		this._scale = null;
		this._thresh.dispose();
		this._thresh = null;
		return this;
	};

	return Tone.GreaterThanZero;
});
define('Tone/signal/GreaterThan',["Tone/core/Tone", "Tone/signal/GreaterThanZero", "Tone/signal/Subtract", "Tone/signal/Signal"], 
	function(Tone){

	"use strict";

	/**
	 *  @class  Output 1 if the signal is greater than the value, otherwise outputs 0.
	 *          can compare two signals or a signal and a number. 
	 *  
	 *  @constructor
	 *  @extends {Tone.Signal}
	 *  @param {number} [value=0] the value to compare to the incoming signal
	 *  @example
	 * var gt = new Tone.GreaterThan(2);
	 * var sig = new Tone.Signal(4).connect(gt);
	 * //output of gt is equal 1. 
	 */
	Tone.GreaterThan = function(value){

		this.createInsOuts(2, 0);
		
		/**
		 *  subtract the amount from the incoming signal
		 *  @type {Tone.Subtract}
		 *  @private
		 */
		this._param = this.input[0] = new Tone.Subtract(value);
		this.input[1] = this._param.input[1];

		/**
		 *  compare that amount to zero
		 *  @type {Tone.GreaterThanZero}
		 *  @private
		 */
		this._gtz = this.output = new Tone.GreaterThanZero();

		//connect
		this._param.connect(this._gtz);
	};

	Tone.extend(Tone.GreaterThan, Tone.Signal);

	/**
	 *  dispose method
	 *  @returns {Tone.GreaterThan} this
	 */
	Tone.GreaterThan.prototype.dispose = function(){
		Tone.prototype.dispose.call(this);
		this._param.dispose();
		this._param = null;
		this._gtz.dispose();
		this._gtz = null;
		return this;
	};

	return Tone.GreaterThan;
});
define('Tone/signal/Abs',["Tone/core/Tone", "Tone/signal/WaveShaper", "Tone/signal/SignalBase"], 
function(Tone){

	"use strict";

	/**
	 *  @class Return the absolute value of an incoming signal. 
	 *  
	 *  @constructor
	 *  @extends {Tone.SignalBase}
	 *  @example
	 * var signal = new Tone.Signal(-1);
	 * var abs = new Tone.Abs();
	 * signal.connect(abs);
	 * //the output of abs is 1. 
	 */
	Tone.Abs = function(){
		/**
		 *  @type {Tone.LessThan}
		 *  @private
		 */
		this._abs = this.input = this.output = new Tone.WaveShaper(function(val){
			if (val === 0){
				return 0;
			} else {
				return Math.abs(val);
			}
		}, 127);
	};

	Tone.extend(Tone.Abs, Tone.SignalBase);

	/**
	 *  dispose method
	 *  @returns {Tone.Abs} this
	 */
	Tone.Abs.prototype.dispose = function(){
		Tone.prototype.dispose.call(this);
		this._abs.dispose();
		this._abs = null;
		return this;
	}; 

	return Tone.Abs;
});
define('Tone/signal/Modulo',["Tone/core/Tone", "Tone/signal/WaveShaper", "Tone/signal/Multiply", "Tone/signal/Subtract"], 
function(Tone){

	"use strict";

	/**
	 *  @class Signal-rate modulo operator. Only works in AudioRange [-1, 1] and for modulus
	 *         values in the NormalRange. 
	 *
	 *  @constructor
	 *  @extends {Tone.SignalBase}
	 *  @param {NormalRange} modulus The modulus to apply.
	 *  @example
	 * var mod = new Tone.Modulo(0.2)
	 * var sig = new Tone.Signal(0.5).connect(mod);
	 * //mod outputs 0.1
	 */
	Tone.Modulo = function(modulus){

		this.createInsOuts(1, 0);

		/**
		 *  A waveshaper gets the integer multiple of 
		 *  the input signal and the modulus.
		 *  @private
		 *  @type {Tone.WaveShaper}
		 */
		this._shaper = new Tone.WaveShaper(Math.pow(2, 16));

		/**
		 *  the integer multiple is multiplied by the modulus
		 *  @type  {Tone.Multiply}
		 *  @private
		 */
		this._multiply = new Tone.Multiply();

		/**
		 *  and subtracted from the input signal
		 *  @type  {Tone.Subtract}
		 *  @private
		 */
		this._subtract = this.output = new Tone.Subtract();

		/**
		 *  the modulus signal
		 *  @type  {Tone.Signal}
		 *  @private
		 */
		this._modSignal = new Tone.Signal(modulus);

		//connections
		this.input.fan(this._shaper, this._subtract);
		this._modSignal.connect(this._multiply, 0, 0);
		this._shaper.connect(this._multiply, 0, 1);
		this._multiply.connect(this._subtract, 0, 1);
		this._setWaveShaper(modulus);
	};

	Tone.extend(Tone.Modulo, Tone.SignalBase);

	/**
	 *  @param  {number}  mod  the modulus to apply
	 *  @private
	 */
	Tone.Modulo.prototype._setWaveShaper = function(mod){
		this._shaper.setMap(function(val){
			var multiple = Math.floor((val + 0.0001) / mod);
			return multiple;
		});
	};

	/**
	 * The modulus value.
	 * @memberOf Tone.Modulo#
	 * @type {NormalRange}
	 * @name value
	 */
	Object.defineProperty(Tone.Modulo.prototype, "value", {
		get : function(){
			return this._modSignal.value;
		},
		set : function(mod){
			this._modSignal.value = mod;
			this._setWaveShaper(mod);
		}
	});

	/**
	 * clean up
	 *  @returns {Tone.Modulo} this
	 */
	Tone.Modulo.prototype.dispose = function(){
		Tone.prototype.dispose.call(this);
		this._shaper.dispose();
		this._shaper = null;
		this._multiply.dispose();
		this._multiply = null;
		this._subtract.dispose();
		this._subtract = null;
		this._modSignal.dispose();
		this._modSignal = null;
		return this;
	};

	return Tone.Modulo;
});
define('Tone/signal/Pow',["Tone/core/Tone", "Tone/signal/WaveShaper"], function(Tone){

	"use strict";

	/**
	 *  @class Pow applies an exponent to the incoming signal. The incoming signal
	 *         must be AudioRange.
	 *
	 *  @extends {Tone.SignalBase}
	 *  @constructor
	 *  @param {Positive} exp The exponent to apply to the incoming signal, must be at least 2. 
	 *  @example
	 * var pow = new Tone.Pow(2);
	 * var sig = new Tone.Signal(0.5).connect(pow);
	 * //output of pow is 0.25. 
	 */
	Tone.Pow = function(exp){

		/**
		 * the exponent
		 * @private
		 * @type {number}
		 */
		this._exp = this.defaultArg(exp, 1);

		/**
		 *  @type {WaveShaperNode}
		 *  @private
		 */
		this._expScaler = this.input = this.output = new Tone.WaveShaper(this._expFunc(this._exp), 8192);
	};

	Tone.extend(Tone.Pow, Tone.SignalBase);

	/**
	 * The value of the exponent.
	 * @memberOf Tone.Pow#
	 * @type {number}
	 * @name value
	 */
	Object.defineProperty(Tone.Pow.prototype, "value", {
		get : function(){
			return this._exp;
		},
		set : function(exp){
			this._exp = exp;
			this._expScaler.setMap(this._expFunc(this._exp));
		}
	});


	/**
	 *  the function which maps the waveshaper
	 *  @param   {number} exp
	 *  @return {function}
	 *  @private
	 */
	Tone.Pow.prototype._expFunc = function(exp){
		return function(val){
			return Math.pow(Math.abs(val), exp);
		};
	};

	/**
	 *  Clean up.
	 *  @returns {Tone.Pow} this
	 */
	Tone.Pow.prototype.dispose = function(){
		Tone.prototype.dispose.call(this);
		this._expScaler.dispose();
		this._expScaler = null;
		return this;
	};

	return Tone.Pow;
});
define('Tone/signal/AudioToGain',["Tone/core/Tone", "Tone/signal/WaveShaper", "Tone/signal/Signal"], function(Tone){

	"use strict";

	/**
	 *  @class AudioToGain converts an input in AudioRange [-1,1] to NormalRange [0,1]. 
	 *         See Tone.GainToAudio.
	 *
	 *  @extends {Tone.SignalBase}
	 *  @constructor
	 *  @example
	 *  var a2g = new Tone.AudioToGain();
	 */
	Tone.AudioToGain = function(){

		/**
		 *  @type {WaveShaperNode}
		 *  @private
		 */
		this._norm = this.input = this.output = new Tone.WaveShaper(function(x){
			return (x + 1) / 2;
		});
	};

	Tone.extend(Tone.AudioToGain, Tone.SignalBase);

	/**
	 *  clean up
	 *  @returns {Tone.AudioToGain} this
	 */
	Tone.AudioToGain.prototype.dispose = function(){
		Tone.prototype.dispose.call(this);
		this._norm.dispose();
		this._norm = null;
		return this;
	};

	return Tone.AudioToGain;
});
define('Tone/signal/Expr',["Tone/core/Tone", "Tone/signal/Add", "Tone/signal/Subtract", "Tone/signal/Multiply", 
	"Tone/signal/GreaterThan", "Tone/signal/GreaterThanZero", "Tone/signal/Abs", "Tone/signal/Negate", 
	"Tone/signal/Modulo", "Tone/signal/Pow", "Tone/signal/AudioToGain"], 
	function(Tone){

	"use strict";

	/**
	 *  @class Evaluate an expression at audio rate. <br><br>
	 *         Parsing code modified from https://code.google.com/p/tapdigit/
	 *         Copyright 2011 2012 Ariya Hidayat, New BSD License
	 *
	 *  @extends {Tone.SignalBase}
	 *  @constructor
	 *  @param {string} expr the expression to generate
	 *  @example
	 * //adds the signals from input[0] and input[1].
	 * var expr = new Tone.Expr("$0 + $1");
	 */
	Tone.Expr = function(){

		var expr = this._replacements(Array.prototype.slice.call(arguments));
		var inputCount = this._parseInputs(expr);

		/**
		 *  hold onto all of the nodes for disposal
		 *  @type {Array}
		 *  @private
		 */
		this._nodes = [];

		/**
		 *  The inputs. The length is determined by the expression. 
		 *  @type {Array}
		 */
		this.input = new Array(inputCount);

		//create a gain for each input
		for (var i = 0; i < inputCount; i++){
			this.input[i] = this.context.createGain();
		}

		//parse the syntax tree
		var tree = this._parseTree(expr);
		//evaluate the results
		var result;
		try {
			result = this._eval(tree);
		} catch (e){
			this._disposeNodes();
			throw new Error("Tone.Expr: Could evaluate expression: "+expr);
		}

		/**
		 *  The output node is the result of the expression
		 *  @type {Tone}
		 */
		this.output = result;
	};

	Tone.extend(Tone.Expr, Tone.SignalBase);

	//some helpers to cut down the amount of code
	function applyBinary(Constructor, args, self){
		var op = new Constructor();
		self._eval(args[0]).connect(op, 0, 0);
		self._eval(args[1]).connect(op, 0, 1);
		return op;
	}
	function applyUnary(Constructor, args, self){
		var op = new Constructor();
		self._eval(args[0]).connect(op, 0, 0);
		return op;
	}
	function getNumber(arg){
		return arg ? parseFloat(arg) : undefined;
	}
	function literalNumber(arg){
		return arg && arg.args ? parseFloat(arg.args) : undefined;
	}

	/*
	 *  the Expressions that Tone.Expr can parse.
	 *
	 *  each expression belongs to a group and contains a regexp 
	 *  for selecting the operator as well as that operators method
	 *  
	 *  @type {Object}
	 *  @private
	 */
	Tone.Expr._Expressions = {
		//values
		"value" : {
			"signal" : {
				regexp : /^\d+\.\d+|^\d+/,
				method : function(arg){
					var sig = new Tone.Signal(getNumber(arg));
					return sig;
				}
			},
			"input" : {
				regexp : /^\$\d/,
				method : function(arg, self){
					return self.input[getNumber(arg.substr(1))];
				}
			}
		},
		//syntactic glue
		"glue" : {
			"(" : {
				regexp : /^\(/,
			},
			")" : {
				regexp : /^\)/,
			},
			"," : {
				regexp : /^,/,
			}
		},
		//functions
		"func" : {
			"abs" :  {
				regexp : /^abs/,
				method : applyUnary.bind(this, Tone.Abs)
			},
			"mod" : {
				regexp : /^mod/,
				method : function(args, self){
					var modulus = literalNumber(args[1]);
					var op = new Tone.Modulo(modulus);
					self._eval(args[0]).connect(op);
					return op;
				}
			},
			"pow" : {
				regexp : /^pow/,
				method : function(args, self){
					var exp = literalNumber(args[1]);
					var op = new Tone.Pow(exp);
					self._eval(args[0]).connect(op);
					return op;
				}
			},
			"a2g" : {
				regexp : /^a2g/,
				method : function(args, self){
					var op = new Tone.AudioToGain();
					self._eval(args[0]).connect(op);
					return op;
				}
			},
		},
		//binary expressions
		"binary" : {
			"+" : {
				regexp : /^\+/,
				precedence : 1,
				method : applyBinary.bind(this, Tone.Add)
			},
			"-" : {
				regexp : /^\-/,
				precedence : 1,
				method : function(args, self){
					//both unary and binary op
					if (args.length === 1){
						return applyUnary(Tone.Negate, args, self);
					} else {
						return applyBinary(Tone.Subtract, args, self);
					}
				}
			},
			"*" : {
				regexp : /^\*/,
				precedence : 0,
				method : applyBinary.bind(this, Tone.Multiply)
			}
		},
		//unary expressions
		"unary" : {
			"-" : {
				regexp : /^\-/,
				method : applyUnary.bind(this, Tone.Negate)
			},
			"!" : {
				regexp : /^\!/,
				method : applyUnary.bind(this, Tone.NOT)
			},
		},
	};
		
	/**
	 *  @param   {string} expr the expression string
	 *  @return  {number}      the input count
	 *  @private
	 */
	Tone.Expr.prototype._parseInputs = function(expr){
		var inputArray = expr.match(/\$\d/g);
		var inputMax = 0;
		if (inputArray !== null){
			for (var i = 0; i < inputArray.length; i++){
				var inputNum = parseInt(inputArray[i].substr(1)) + 1;
				inputMax = Math.max(inputMax, inputNum);
			}
		}
		return inputMax;
	};

	/**
	 *  @param   {Array} args 	an array of arguments
	 *  @return  {string} the results of the replacements being replaced
	 *  @private
	 */
	Tone.Expr.prototype._replacements = function(args){
		var expr = args.shift();
		for (var i = 0; i < args.length; i++){
			expr = expr.replace(/\%/i, args[i]);
		}
		return expr;
	};

	/**
	 *  tokenize the expression based on the Expressions object
	 *  @param   {string} expr 
	 *  @return  {Object}      returns two methods on the tokenized list, next and peek
	 *  @private
	 */
	Tone.Expr.prototype._tokenize = function(expr){
		var position = -1;
		var tokens = [];

		while(expr.length > 0){
			expr = expr.trim();
			var token =  getNextToken(expr);
			tokens.push(token);
			expr = expr.substr(token.value.length);
		}

		function getNextToken(expr){
			for (var type in Tone.Expr._Expressions){
				var group = Tone.Expr._Expressions[type];
				for (var opName in group){
					var op = group[opName];
					var reg = op.regexp;
					var match = expr.match(reg);
					if (match !== null){
						return {
							type : type,
							value : match[0],
							method : op.method
						};
					}
				}
			}
			throw new SyntaxError("Tone.Expr: Unexpected token "+expr);
		}

		return {
			next : function(){
				return tokens[++position];
			},
			peek : function(){
				return tokens[position + 1];
			}
		};
	};

	/**
	 *  recursively parse the string expression into a syntax tree
	 *  
	 *  @param   {string} expr 
	 *  @return  {Object}
	 *  @private
	 */
	Tone.Expr.prototype._parseTree = function(expr){
		var lexer = this._tokenize(expr);
		var isUndef = this.isUndef.bind(this);

		function matchSyntax(token, syn) {
			return !isUndef(token) && 
				token.type === "glue" &&
				token.value === syn;
		}

		function matchGroup(token, groupName, prec) {
			var ret = false;
			var group = Tone.Expr._Expressions[groupName];
			if (!isUndef(token)){
				for (var opName in group){
					var op = group[opName];
					if (op.regexp.test(token.value)){
						if (!isUndef(prec)){
							if(op.precedence === prec){	
								return true;
							}
						} else {
							return true;
						}
					}
				}
			}
			return ret;
		}

		function parseExpression(precedence) {
			if (isUndef(precedence)){
				precedence = 5;
			}
			var expr;
			if (precedence < 0){
				expr = parseUnary();
			} else {
				expr = parseExpression(precedence-1);
			}
			var token = lexer.peek();
			while (matchGroup(token, "binary", precedence)) {
				token = lexer.next();
				expr = {
					operator: token.value,
					method : token.method,
					args : [
						expr,
						parseExpression(precedence-1)
					]
				};
				token = lexer.peek();
			}
			return expr;
		}

		function parseUnary() {
			var token, expr;
			token = lexer.peek();
			if (matchGroup(token, "unary")) {
				token = lexer.next();
				expr = parseUnary();
				return {
					operator: token.value,
					method : token.method,
					args : [expr]
				};
			}
			return parsePrimary();
		}

		function parsePrimary() {
			var token, expr;
			token = lexer.peek();
			if (isUndef(token)) {
				throw new SyntaxError("Tone.Expr: Unexpected termination of expression");
			}
			if (token.type === "func") {
				token = lexer.next();
				return parseFunctionCall(token);
			}
			if (token.type === "value") {
				token = lexer.next();
				return {
					method : token.method,
					args : token.value
				};
			}
			if (matchSyntax(token, "(")) {
				lexer.next();
				expr = parseExpression();
				token = lexer.next();
				if (!matchSyntax(token, ")")) {
					throw new SyntaxError("Expected )");
				}
				return expr;
			}
			throw new SyntaxError("Tone.Expr: Parse error, cannot process token " + token.value);
		}

		function parseFunctionCall(func) {
			var token, args = [];
			token = lexer.next();
			if (!matchSyntax(token, "(")) {
				throw new SyntaxError("Tone.Expr: Expected ( in a function call \"" + func.value + "\"");
			}
			token = lexer.peek();
			if (!matchSyntax(token, ")")) {
				args = parseArgumentList();
			}
			token = lexer.next();
			if (!matchSyntax(token, ")")) {
				throw new SyntaxError("Tone.Expr: Expected ) in a function call \"" + func.value + "\"");
			}
			return {
				method : func.method,
				args : args,
				name : name
			};
		}

		function parseArgumentList() {
			var token, expr, args = [];
			while (true) {
				expr = parseExpression();
				if (isUndef(expr)) {
					// TODO maybe throw exception?
					break;
				}
				args.push(expr);
				token = lexer.peek();
				if (!matchSyntax(token, ",")) {
					break;
				}
				lexer.next();
			}
			return args;
		}

		return parseExpression();
	};

	/**
	 *  recursively evaluate the expression tree
	 *  @param   {Object} tree 
	 *  @return  {AudioNode}      the resulting audio node from the expression
	 *  @private
	 */
	Tone.Expr.prototype._eval = function(tree){
		if (!this.isUndef(tree)){
			var node = tree.method(tree.args, this);
			this._nodes.push(node);
			return node;
		} 
	};

	/**
	 *  dispose all the nodes
	 *  @private
	 */
	Tone.Expr.prototype._disposeNodes = function(){
		for (var i = 0; i < this._nodes.length; i++){
			var node = this._nodes[i];
			if (this.isFunction(node.dispose)) {
				node.dispose();
			} else if (this.isFunction(node.disconnect)) {
				node.disconnect();
			}
			node = null;
			this._nodes[i] = null;
		}
		this._nodes = null;
	};

	/**
	 *  clean up
	 */
	Tone.Expr.prototype.dispose = function(){
		Tone.prototype.dispose.call(this);
		this._disposeNodes();
	};

	return Tone.Expr;
});
define('Tone/signal/EqualPowerGain',["Tone/core/Tone", "Tone/signal/WaveShaper"], function(Tone){

	"use strict";

	/**
	 *  @class Convert an incoming signal between 0, 1 to an equal power gain scale.
	 *
	 *  @extends {Tone.SignalBase}
	 *  @constructor
	 *  @example
	 * var eqPowGain = new Tone.EqualPowerGain();
	 */
	Tone.EqualPowerGain = function(){

		/**
		 *  @type {Tone.WaveShaper}
		 *  @private
		 */
		this._eqPower = this.input = this.output = new Tone.WaveShaper(function(val){
			if (Math.abs(val) < 0.001){
				//should output 0 when input is 0
				return 0;
			} else {
				return this.equalPowerScale(val);
			}
		}.bind(this), 4096);
	};

	Tone.extend(Tone.EqualPowerGain, Tone.SignalBase);

	/**
	 *  clean up
	 *  @returns {Tone.EqualPowerGain} this
	 */
	Tone.EqualPowerGain.prototype.dispose = function(){
		Tone.prototype.dispose.call(this);
		this._eqPower.dispose();
		this._eqPower = null;
		return this;
	};

	return Tone.EqualPowerGain;
});
define('Tone/component/CrossFade',["Tone/core/Tone", "Tone/signal/Signal", "Tone/signal/Expr", 
	"Tone/signal/EqualPowerGain", "Tone/core/Gain"], function(Tone){

	"use strict";

	/**
	 * @class  Tone.Crossfade provides equal power fading between two inputs. 
	 *         More on crossfading technique [here](https://en.wikipedia.org/wiki/Fade_(audio_engineering)#Crossfading).
	 *
	 * @constructor
	 * @extends {Tone}
	 * @param {NormalRange} [initialFade=0.5]
	 * @example
	 * var crossFade = new Tone.CrossFade(0.5);
	 * //connect effect A to crossfade from
	 * //effect output 0 to crossfade input 0
	 * effectA.connect(crossFade, 0, 0);
	 * //connect effect B to crossfade from
	 * //effect output 0 to crossfade input 1
	 * effectB.connect(crossFade, 0, 1);
	 * crossFade.fade.value = 0;
	 * // ^ only effectA is output
	 * crossFade.fade.value = 1;
	 * // ^ only effectB is output
	 * crossFade.fade.value = 0.5;
	 * // ^ the two signals are mixed equally. 
	 */		
	Tone.CrossFade = function(initialFade){

		this.createInsOuts(2, 1);

		/**
		 *  Alias for <code>input[0]</code>. 
		 *  @type {Tone.Gain}
		 */
		this.a = this.input[0] = new Tone.Gain();

		/**
		 *  Alias for <code>input[1]</code>. 
		 *  @type {Tone.Gain}
		 */
		this.b = this.input[1] = new Tone.Gain();

		/**
		 * 	The mix between the two inputs. A fade value of 0
		 * 	will output 100% <code>input[0]</code> and 
		 * 	a value of 1 will output 100% <code>input[1]</code>. 
		 *  @type {NormalRange}
		 *  @signal
		 */
		this.fade = new Tone.Signal(this.defaultArg(initialFade, 0.5), Tone.Type.NormalRange);

		/**
		 *  equal power gain cross fade
		 *  @private
		 *  @type {Tone.EqualPowerGain}
		 */
		this._equalPowerA = new Tone.EqualPowerGain();

		/**
		 *  equal power gain cross fade
		 *  @private
		 *  @type {Tone.EqualPowerGain}
		 */
		this._equalPowerB = new Tone.EqualPowerGain();
		
		/**
		 *  invert the incoming signal
		 *  @private
		 *  @type {Tone}
		 */
		this._invert = new Tone.Expr("1 - $0");

		//connections
		this.a.connect(this.output);
		this.b.connect(this.output);
		this.fade.chain(this._equalPowerB, this.b.gain);
		this.fade.chain(this._invert, this._equalPowerA, this.a.gain);
		this._readOnly("fade");
	};

	Tone.extend(Tone.CrossFade);

	/**
	 *  clean up
	 *  @returns {Tone.CrossFade} this
	 */
	Tone.CrossFade.prototype.dispose = function(){
		Tone.prototype.dispose.call(this);
		this._writable("fade");
		this._equalPowerA.dispose();
		this._equalPowerA = null;
		this._equalPowerB.dispose();
		this._equalPowerB = null;
		this.fade.dispose();
		this.fade = null;
		this._invert.dispose();
		this._invert = null;
		this.a.dispose();
		this.a = null;
		this.b.dispose();
		this.b = null;
		return this;
	};

	return Tone.CrossFade;
});

var effect;
'use strict';
effect = function () {
    var p5sound = master;
    var CrossFade = Tone_component_CrossFade;
    p5.Effect = function () {
        this.ac = p5sound.audiocontext;
        this.input = this.ac.createGain();
        this.output = this.ac.createGain();
        this._drywet = new CrossFade(1);
        this.wet = this.ac.createGain();
        this.input.connect(this._drywet.a);
        this.wet.connect(this._drywet.b);
        this._drywet.connect(this.output);
        this.connect();
        p5sound.soundArray.push(this);
    };
    p5.Effect.prototype.amp = function (vol, rampTime, tFromNow) {
        var rampTime = rampTime || 0;
        var tFromNow = tFromNow || 0;
        var now = p5sound.audiocontext.currentTime;
        var currentVol = this.output.gain.value;
        this.output.gain.cancelScheduledValues(now);
        this.output.gain.linearRampToValueAtTime(currentVol, now + tFromNow + 0.001);
        this.output.gain.linearRampToValueAtTime(vol, now + tFromNow + rampTime + 0.001);
    };
    p5.Effect.prototype.chain = function () {
        if (arguments.length > 0) {
            this.connect(arguments[0]);
            for (var i = 1; i < arguments.length; i += 1) {
                arguments[i - 1].connect(arguments[i]);
            }
        }
        return this;
    };
    p5.Effect.prototype.drywet = function (fade) {
        if (typeof fade !== 'undefined') {
            this._drywet.fade.value = fade;
        }
        return this._drywet.fade.value;
    };
    p5.Effect.prototype.connect = function (unit) {
        var u = unit || p5.soundOut.input;
        this.output.connect(u.input ? u.input : u);
    };
    p5.Effect.prototype.disconnect = function () {
        if (this.output) {
            this.output.disconnect();
        }
    };
    p5.Effect.prototype.dispose = function () {
        var index = p5sound.soundArray.indexOf(this);
        p5sound.soundArray.splice(index, 1);
        if (this.input) {
            this.input.disconnect();
            delete this.input;
        }
        if (this.output) {
            this.output.disconnect();
            delete this.output;
        }
        if (this._drywet) {
            this._drywet.disconnect();
            delete this._drywet;
        }
        if (this.wet) {
            this.wet.disconnect();
            delete this.wet;
        }
        this.ac = undefined;
    };
    return p5.Effect;
}(master, Tone_component_CrossFade);
var filter;
'use strict';
filter = function () {
    var p5sound = master;
    var Effect = effect;
    p5.Filter = function (type) {
        Effect.call(this);
        this.biquad = this.ac.createBiquadFilter();
        this.input.connect(this.biquad);
        this.biquad.connect(this.wet);
        if (type) {
            this.setType(type);
        }
        this._on = true;
        this._untoggledType = this.biquad.type;
    };
    p5.Filter.prototype = Object.create(Effect.prototype);
    p5.Filter.prototype.process = function (src, freq, res, time) {
        src.connect(this.input);
        this.set(freq, res, time);
    };
    p5.Filter.prototype.set = function (freq, res, time) {
        if (freq) {
            this.freq(freq, time);
        }
        if (res) {
            this.res(res, time);
        }
    };
    p5.Filter.prototype.freq = function (freq, time) {
        var t = time || 0;
        if (freq <= 0) {
            freq = 1;
        }
        if (typeof freq === 'number') {
            this.biquad.frequency.value = freq;
            this.biquad.frequency.cancelScheduledValues(this.ac.currentTime + 0.01 + t);
            this.biquad.frequency.exponentialRampToValueAtTime(freq, this.ac.currentTime + 0.02 + t);
        } else if (freq) {
            freq.connect(this.biquad.frequency);
        }
        return this.biquad.frequency.value;
    };
    p5.Filter.prototype.res = function (res, time) {
        var t = time || 0;
        if (typeof res === 'number') {
            this.biquad.Q.value = res;
            this.biquad.Q.cancelScheduledValues(this.ac.currentTime + 0.01 + t);
            this.biquad.Q.linearRampToValueAtTime(res, this.ac.currentTime + 0.02 + t);
        } else if (res) {
            res.connect(this.biquad.Q);
        }
        return this.biquad.Q.value;
    };
    p5.Filter.prototype.gain = function (gain, time) {
        var t = time || 0;
        if (typeof gain === 'number') {
            this.biquad.gain.value = gain;
            this.biquad.gain.cancelScheduledValues(this.ac.currentTime + 0.01 + t);
            this.biquad.gain.linearRampToValueAtTime(gain, this.ac.currentTime + 0.02 + t);
        } else if (gain) {
            gain.connect(this.biquad.gain);
        }
        return this.biquad.gain.value;
    };
    p5.Filter.prototype.toggle = function () {
        this._on = !this._on;
        if (this._on === true) {
            this.biquad.type = this._untoggledType;
        } else if (this._on === false) {
            this.biquad.type = 'allpass';
        }
        return this._on;
    };
    p5.Filter.prototype.setType = function (t) {
        this.biquad.type = t;
        this._untoggledType = this.biquad.type;
    };
    p5.Filter.prototype.dispose = function () {
        Effect.prototype.dispose.apply(this);
        if (this.biquad) {
            this.biquad.disconnect();
            delete this.biquad;
        }
    };
    p5.LowPass = function () {
        p5.Filter.call(this, 'lowpass');
    };
    p5.LowPass.prototype = Object.create(p5.Filter.prototype);
    p5.HighPass = function () {
        p5.Filter.call(this, 'highpass');
    };
    p5.HighPass.prototype = Object.create(p5.Filter.prototype);
    p5.BandPass = function () {
        p5.Filter.call(this, 'bandpass');
    };
    p5.BandPass.prototype = Object.create(p5.Filter.prototype);
    return p5.Filter;
}(master, effect);
var src_eqFilter;
'use strict';
src_eqFilter = function () {
    var Filter = filter;
    var p5sound = master;
    var EQFilter = function (freq, res) {
        Filter.call(this, 'peaking');
        this.disconnect();
        this.set(freq, res);
        this.biquad.gain.value = 0;
        delete this.input;
        delete this.output;
        delete this._drywet;
        delete this.wet;
    };
    EQFilter.prototype = Object.create(Filter.prototype);
    EQFilter.prototype.amp = function () {
        console.warn('`amp()` is not available for p5.EQ bands. Use `.gain()`');
    };
    EQFilter.prototype.drywet = function () {
        console.warn('`drywet()` is not available for p5.EQ bands.');
    };
    EQFilter.prototype.connect = function (unit) {
        var u = unit || p5.soundOut.input;
        if (this.biquad) {
            this.biquad.connect(u.input ? u.input : u);
        } else {
            this.output.connect(u.input ? u.input : u);
        }
    };
    EQFilter.prototype.disconnect = function () {
        if (this.biquad) {
            this.biquad.disconnect();
        }
    };
    EQFilter.prototype.dispose = function () {
        var index = p5sound.soundArray.indexOf(this);
        p5sound.soundArray.splice(index, 1);
        this.disconnect();
        delete this.biquad;
    };
    return EQFilter;
}(filter, master);
var eq;
'use strict';
eq = function () {
    var Effect = effect;
    var EQFilter = src_eqFilter;
    p5.EQ = function (_eqsize) {
        Effect.call(this);
        _eqsize = _eqsize === 3 || _eqsize === 8 ? _eqsize : 3;
        var factor;
        _eqsize === 3 ? factor = Math.pow(2, 3) : factor = 2;
        this.bands = [];
        var freq, res;
        for (var i = 0; i < _eqsize; i++) {
            if (i === _eqsize - 1) {
                freq = 21000;
                res = 0.01;
            } else if (i === 0) {
                freq = 100;
                res = 0.1;
            } else if (i === 1) {
                freq = _eqsize === 3 ? 360 * factor : 360;
                res = 1;
            } else {
                freq = this.bands[i - 1].freq() * factor;
                res = 1;
            }
            this.bands[i] = this._newBand(freq, res);
            if (i > 0) {
                this.bands[i - 1].connect(this.bands[i].biquad);
            } else {
                this.input.connect(this.bands[i].biquad);
            }
        }
        this.bands[_eqsize - 1].connect(this.output);
    };
    p5.EQ.prototype = Object.create(Effect.prototype);
    p5.EQ.prototype.process = function (src) {
        src.connect(this.input);
    };
    p5.EQ.prototype.set = function () {
        if (arguments.length === this.bands.length * 2) {
            for (var i = 0; i < arguments.length; i += 2) {
                this.bands[i / 2].freq(arguments[i]);
                this.bands[i / 2].gain(arguments[i + 1]);
            }
        } else {
            console.error('Argument mismatch. .set() should be called with ' + this.bands.length * 2 + ' arguments. (one frequency and gain value pair for each band of the eq)');
        }
    };
    p5.EQ.prototype._newBand = function (freq, res) {
        return new EQFilter(freq, res);
    };
    p5.EQ.prototype.dispose = function () {
        Effect.prototype.dispose.apply(this);
        if (this.bands) {
            while (this.bands.length > 0) {
                delete this.bands.pop().dispose();
            }
            delete this.bands;
        }
    };
    return p5.EQ;
}(effect, src_eqFilter);
var panner3d;
'use strict';
panner3d = function () {
    var p5sound = master;
    var Effect = effect;
    p5.Panner3D = function () {
        Effect.call(this);
        this.panner = this.ac.createPanner();
        this.panner.panningModel = 'HRTF';
        this.panner.distanceModel = 'linear';
        this.panner.connect(this.output);
        this.input.connect(this.panner);
    };
    p5.Panner3D.prototype = Object.create(Effect.prototype);
    p5.Panner3D.prototype.process = function (src) {
        src.connect(this.input);
    };
    p5.Panner3D.prototype.set = function (xVal, yVal, zVal, time) {
        this.positionX(xVal, time);
        this.positionY(yVal, time);
        this.positionZ(zVal, time);
        return [
            this.panner.positionX.value,
            this.panner.positionY.value,
            this.panner.positionZ.value
        ];
    };
    p5.Panner3D.prototype.positionX = function (xVal, time) {
        var t = time || 0;
        if (typeof xVal === 'number') {
            this.panner.positionX.value = xVal;
            this.panner.positionX.cancelScheduledValues(this.ac.currentTime + 0.01 + t);
            this.panner.positionX.linearRampToValueAtTime(xVal, this.ac.currentTime + 0.02 + t);
        } else if (xVal) {
            xVal.connect(this.panner.positionX);
        }
        return this.panner.positionX.value;
    };
    p5.Panner3D.prototype.positionY = function (yVal, time) {
        var t = time || 0;
        if (typeof yVal === 'number') {
            this.panner.positionY.value = yVal;
            this.panner.positionY.cancelScheduledValues(this.ac.currentTime + 0.01 + t);
            this.panner.positionY.linearRampToValueAtTime(yVal, this.ac.currentTime + 0.02 + t);
        } else if (yVal) {
            yVal.connect(this.panner.positionY);
        }
        return this.panner.positionY.value;
    };
    p5.Panner3D.prototype.positionZ = function (zVal, time) {
        var t = time || 0;
        if (typeof zVal === 'number') {
            this.panner.positionZ.value = zVal;
            this.panner.positionZ.cancelScheduledValues(this.ac.currentTime + 0.01 + t);
            this.panner.positionZ.linearRampToValueAtTime(zVal, this.ac.currentTime + 0.02 + t);
        } else if (zVal) {
            zVal.connect(this.panner.positionZ);
        }
        return this.panner.positionZ.value;
    };
    p5.Panner3D.prototype.orient = function (xVal, yVal, zVal, time) {
        this.orientX(xVal, time);
        this.orientY(yVal, time);
        this.orientZ(zVal, time);
        return [
            this.panner.orientationX.value,
            this.panner.orientationY.value,
            this.panner.orientationZ.value
        ];
    };
    p5.Panner3D.prototype.orientX = function (xVal, time) {
        var t = time || 0;
        if (typeof xVal === 'number') {
            this.panner.orientationX.value = xVal;
            this.panner.orientationX.cancelScheduledValues(this.ac.currentTime + 0.01 + t);
            this.panner.orientationX.linearRampToValueAtTime(xVal, this.ac.currentTime + 0.02 + t);
        } else if (xVal) {
            xVal.connect(this.panner.orientationX);
        }
        return this.panner.orientationX.value;
    };
    p5.Panner3D.prototype.orientY = function (yVal, time) {
        var t = time || 0;
        if (typeof yVal === 'number') {
            this.panner.orientationY.value = yVal;
            this.panner.orientationY.cancelScheduledValues(this.ac.currentTime + 0.01 + t);
            this.panner.orientationY.linearRampToValueAtTime(yVal, this.ac.currentTime + 0.02 + t);
        } else if (yVal) {
            yVal.connect(this.panner.orientationY);
        }
        return this.panner.orientationY.value;
    };
    p5.Panner3D.prototype.orientZ = function (zVal, time) {
        var t = time || 0;
        if (typeof zVal === 'number') {
            this.panner.orientationZ.value = zVal;
            this.panner.orientationZ.cancelScheduledValues(this.ac.currentTime + 0.01 + t);
            this.panner.orientationZ.linearRampToValueAtTime(zVal, this.ac.currentTime + 0.02 + t);
        } else if (zVal) {
            zVal.connect(this.panner.orientationZ);
        }
        return this.panner.orientationZ.value;
    };
    p5.Panner3D.prototype.setFalloff = function (maxDistance, rolloffFactor) {
        this.maxDist(maxDistance);
        this.rolloff(rolloffFactor);
    };
    p5.Panner3D.prototype.maxDist = function (maxDistance) {
        if (typeof maxDistance === 'number') {
            this.panner.maxDistance = maxDistance;
        }
        return this.panner.maxDistance;
    };
    p5.Panner3D.prototype.rolloff = function (rolloffFactor) {
        if (typeof rolloffFactor === 'number') {
            this.panner.rolloffFactor = rolloffFactor;
        }
        return this.panner.rolloffFactor;
    };
    p5.Panner3D.dispose = function () {
        Effect.prototype.dispose.apply(this);
        if (this.panner) {
            this.panner.disconnect();
            delete this.panner;
        }
    };
    return p5.Panner3D;
}(master, effect);
var listener3d;
'use strict';
listener3d = function () {
    var p5sound = master;
    var Effect = effect;
    p5.Listener3D = function (type) {
        this.ac = p5sound.audiocontext;
        this.listener = this.ac.listener;
    };
    p5.Listener3D.prototype.process = function (src) {
        src.connect(this.input);
    };
    p5.Listener3D.prototype.position = function (xVal, yVal, zVal, time) {
        this.positionX(xVal, time);
        this.positionY(yVal, time);
        this.positionZ(zVal, time);
        return [
            this.listener.positionX.value,
            this.listener.positionY.value,
            this.listener.positionZ.value
        ];
    };
    p5.Listener3D.prototype.positionX = function (xVal, time) {
        var t = time || 0;
        if (typeof xVal === 'number') {
            this.listener.positionX.value = xVal;
            this.listener.positionX.cancelScheduledValues(this.ac.currentTime + 0.01 + t);
            this.listener.positionX.linearRampToValueAtTime(xVal, this.ac.currentTime + 0.02 + t);
        } else if (xVal) {
            xVal.connect(this.listener.positionX);
        }
        return this.listener.positionX.value;
    };
    p5.Listener3D.prototype.positionY = function (yVal, time) {
        var t = time || 0;
        if (typeof yVal === 'number') {
            this.listener.positionY.value = yVal;
            this.listener.positionY.cancelScheduledValues(this.ac.currentTime + 0.01 + t);
            this.listener.positionY.linearRampToValueAtTime(yVal, this.ac.currentTime + 0.02 + t);
        } else if (yVal) {
            yVal.connect(this.listener.positionY);
        }
        return this.listener.positionY.value;
    };
    p5.Listener3D.prototype.positionZ = function (zVal, time) {
        var t = time || 0;
        if (typeof zVal === 'number') {
            this.listener.positionZ.value = zVal;
            this.listener.positionZ.cancelScheduledValues(this.ac.currentTime + 0.01 + t);
            this.listener.positionZ.linearRampToValueAtTime(zVal, this.ac.currentTime + 0.02 + t);
        } else if (zVal) {
            zVal.connect(this.listener.positionZ);
        }
        return this.listener.positionZ.value;
    };
    p5.Listener3D.prototype.orient = function (xValF, yValF, zValF, xValU, yValU, zValU, time) {
        if (arguments.length === 3 || arguments.length === 4) {
            time = arguments[3];
            this.orientForward(xValF, yValF, zValF, time);
        } else if (arguments.length === 6 || arguments === 7) {
            this.orientForward(xValF, yValF, zValF);
            this.orientUp(xValU, yValU, zValU, time);
        }
        return [
            this.listener.forwardX.value,
            this.listener.forwardY.value,
            this.listener.forwardZ.value,
            this.listener.upX.value,
            this.listener.upY.value,
            this.listener.upZ.value
        ];
    };
    p5.Listener3D.prototype.orientForward = function (xValF, yValF, zValF, time) {
        this.forwardX(xValF, time);
        this.forwardY(yValF, time);
        this.forwardZ(zValF, time);
        return [
            this.listener.forwardX,
            this.listener.forwardY,
            this.listener.forwardZ
        ];
    };
    p5.Listener3D.prototype.orientUp = function (xValU, yValU, zValU, time) {
        this.upX(xValU, time);
        this.upY(yValU, time);
        this.upZ(zValU, time);
        return [
            this.listener.upX,
            this.listener.upY,
            this.listener.upZ
        ];
    };
    p5.Listener3D.prototype.forwardX = function (xVal, time) {
        var t = time || 0;
        if (typeof xVal === 'number') {
            this.listener.forwardX.value = xVal;
            this.listener.forwardX.cancelScheduledValues(this.ac.currentTime + 0.01 + t);
            this.listener.forwardX.linearRampToValueAtTime(xVal, this.ac.currentTime + 0.02 + t);
        } else if (xVal) {
            xVal.connect(this.listener.forwardX);
        }
        return this.listener.forwardX.value;
    };
    p5.Listener3D.prototype.forwardY = function (yVal, time) {
        var t = time || 0;
        if (typeof yVal === 'number') {
            this.listener.forwardY.value = yVal;
            this.listener.forwardY.cancelScheduledValues(this.ac.currentTime + 0.01 + t);
            this.listener.forwardY.linearRampToValueAtTime(yVal, this.ac.currentTime + 0.02 + t);
        } else if (yVal) {
            yVal.connect(this.listener.forwardY);
        }
        return this.listener.forwardY.value;
    };
    p5.Listener3D.prototype.forwardZ = function (zVal, time) {
        var t = time || 0;
        if (typeof zVal === 'number') {
            this.listener.forwardZ.value = zVal;
            this.listener.forwardZ.cancelScheduledValues(this.ac.currentTime + 0.01 + t);
            this.listener.forwardZ.linearRampToValueAtTime(zVal, this.ac.currentTime + 0.02 + t);
        } else if (zVal) {
            zVal.connect(this.listener.forwardZ);
        }
        return this.listener.forwardZ.value;
    };
    p5.Listener3D.prototype.upX = function (xVal, time) {
        var t = time || 0;
        if (typeof xVal === 'number') {
            this.listener.upX.value = xVal;
            this.listener.upX.cancelScheduledValues(this.ac.currentTime + 0.01 + t);
            this.listener.upX.linearRampToValueAtTime(xVal, this.ac.currentTime + 0.02 + t);
        } else if (xVal) {
            xVal.connect(this.listener.upX);
        }
        return this.listener.upX.value;
    };
    p5.Listener3D.prototype.upY = function (yVal, time) {
        var t = time || 0;
        if (typeof yVal === 'number') {
            this.listener.upY.value = yVal;
            this.listener.upY.cancelScheduledValues(this.ac.currentTime + 0.01 + t);
            this.listener.upY.linearRampToValueAtTime(yVal, this.ac.currentTime + 0.02 + t);
        } else if (yVal) {
            yVal.connect(this.listener.upY);
        }
        return this.listener.upY.value;
    };
    p5.Listener3D.prototype.upZ = function (zVal, time) {
        var t = time || 0;
        if (typeof zVal === 'number') {
            this.listener.upZ.value = zVal;
            this.listener.upZ.cancelScheduledValues(this.ac.currentTime + 0.01 + t);
            this.listener.upZ.linearRampToValueAtTime(zVal, this.ac.currentTime + 0.02 + t);
        } else if (zVal) {
            zVal.connect(this.listener.upZ);
        }
        return this.listener.upZ.value;
    };
    return p5.Listener3D;
}(master, effect);
var delay;
'use strict';
delay = function () {
    var Filter = filter;
    var Effect = effect;
    p5.Delay = function () {
        Effect.call(this);
        this._split = this.ac.createChannelSplitter(2);
        this._merge = this.ac.createChannelMerger(2);
        this._leftGain = this.ac.createGain();
        this._rightGain = this.ac.createGain();
        this.leftDelay = this.ac.createDelay();
        this.rightDelay = this.ac.createDelay();
        this._leftFilter = new Filter();
        this._rightFilter = new Filter();
        this._leftFilter.disconnect();
        this._rightFilter.disconnect();
        this._leftFilter.biquad.frequency.setValueAtTime(1200, this.ac.currentTime);
        this._rightFilter.biquad.frequency.setValueAtTime(1200, this.ac.currentTime);
        this._leftFilter.biquad.Q.setValueAtTime(0.3, this.ac.currentTime);
        this._rightFilter.biquad.Q.setValueAtTime(0.3, this.ac.currentTime);
        this.input.connect(this._split);
        this.leftDelay.connect(this._leftGain);
        this.rightDelay.connect(this._rightGain);
        this._leftGain.connect(this._leftFilter.input);
        this._rightGain.connect(this._rightFilter.input);
        this._merge.connect(this.wet);
        this._leftFilter.biquad.gain.setValueAtTime(1, this.ac.currentTime);
        this._rightFilter.biquad.gain.setValueAtTime(1, this.ac.currentTime);
        this.setType(0);
        this._maxDelay = this.leftDelay.delayTime.maxValue;
        this.feedback(0.5);
    };
    p5.Delay.prototype = Object.create(Effect.prototype);
    p5.Delay.prototype.process = function (src, _delayTime, _feedback, _filter) {
        var feedback = _feedback || 0;
        var delayTime = _delayTime || 0;
        if (feedback >= 1) {
            throw new Error('Feedback value will force a positive feedback loop.');
        }
        if (delayTime >= this._maxDelay) {
            throw new Error('Delay Time exceeds maximum delay time of ' + this._maxDelay + ' second.');
        }
        src.connect(this.input);
        this.leftDelay.delayTime.setValueAtTime(delayTime, this.ac.currentTime);
        this.rightDelay.delayTime.setValueAtTime(delayTime, this.ac.currentTime);
        this._leftGain.gain.value = feedback;
        this._rightGain.gain.value = feedback;
        if (_filter) {
            this._leftFilter.freq(_filter);
            this._rightFilter.freq(_filter);
        }
    };
    p5.Delay.prototype.delayTime = function (t) {
        if (typeof t !== 'number') {
            t.connect(this.leftDelay.delayTime);
            t.connect(this.rightDelay.delayTime);
        } else {
            this.leftDelay.delayTime.cancelScheduledValues(this.ac.currentTime);
            this.rightDelay.delayTime.cancelScheduledValues(this.ac.currentTime);
            this.leftDelay.delayTime.linearRampToValueAtTime(t, this.ac.currentTime);
            this.rightDelay.delayTime.linearRampToValueAtTime(t, this.ac.currentTime);
        }
    };
    p5.Delay.prototype.feedback = function (f) {
        if (f && typeof f !== 'number') {
            f.connect(this._leftGain.gain);
            f.connect(this._rightGain.gain);
        } else if (f >= 1) {
            throw new Error('Feedback value will force a positive feedback loop.');
        } else if (typeof f === 'number') {
            this._leftGain.gain.value = f;
            this._rightGain.gain.value = f;
        }
        return this._leftGain.gain.value;
    };
    p5.Delay.prototype.filter = function (freq, q) {
        this._leftFilter.set(freq, q);
        this._rightFilter.set(freq, q);
    };
    p5.Delay.prototype.setType = function (t) {
        if (t === 1) {
            t = 'pingPong';
        }
        this._split.disconnect();
        this._leftFilter.disconnect();
        this._rightFilter.disconnect();
        this._split.connect(this.leftDelay, 0);
        this._split.connect(this.rightDelay, 1);
        switch (t) {
        case 'pingPong':
            this._rightFilter.setType(this._leftFilter.biquad.type);
            this._leftFilter.output.connect(this._merge, 0, 0);
            this._rightFilter.output.connect(this._merge, 0, 1);
            this._leftFilter.output.connect(this.rightDelay);
            this._rightFilter.output.connect(this.leftDelay);
            break;
        default:
            this._leftFilter.output.connect(this._merge, 0, 0);
            this._rightFilter.output.connect(this._merge, 0, 1);
            this._leftFilter.output.connect(this.leftDelay);
            this._rightFilter.output.connect(this.rightDelay);
        }
    };
    p5.Delay.prototype.dispose = function () {
        Effect.prototype.dispose.apply(this);
        this._split.disconnect();
        this._leftFilter.dispose();
        this._rightFilter.dispose();
        this._merge.disconnect();
        this._leftGain.disconnect();
        this._rightGain.disconnect();
        this.leftDelay.disconnect();
        this.rightDelay.disconnect();
        this._split = undefined;
        this._leftFilter = undefined;
        this._rightFilter = undefined;
        this._merge = undefined;
        this._leftGain = undefined;
        this._rightGain = undefined;
        this.leftDelay = undefined;
        this.rightDelay = undefined;
    };
}(filter, effect);
var reverb;
'use strict';
reverb = function () {
    var CustomError = errorHandler;
    var Effect = effect;
    p5.Reverb = function () {
        Effect.call(this);
        this._initConvolverNode();
        this.input.gain.value = 0.5;
        this._seconds = 3;
        this._decay = 2;
        this._reverse = false;
        this._buildImpulse();
    };
    p5.Reverb.prototype = Object.create(Effect.prototype);
    p5.Reverb.prototype._initConvolverNode = function () {
        this.convolverNode = this.ac.createConvolver();
        this.input.connect(this.convolverNode);
        this.convolverNode.connect(this.wet);
    };
    p5.Reverb.prototype._teardownConvolverNode = function () {
        if (this.convolverNode) {
            this.convolverNode.disconnect();
            delete this.convolverNode;
        }
    };
    p5.Reverb.prototype._setBuffer = function (audioBuffer) {
        this._teardownConvolverNode();
        this._initConvolverNode();
        this.convolverNode.buffer = audioBuffer;
    };
    p5.Reverb.prototype.process = function (src, seconds, decayRate, reverse) {
        src.connect(this.input);
        var rebuild = false;
        if (seconds) {
            this._seconds = seconds;
            rebuild = true;
        }
        if (decayRate) {
            this._decay = decayRate;
        }
        if (reverse) {
            this._reverse = reverse;
        }
        if (rebuild) {
            this._buildImpulse();
        }
    };
    p5.Reverb.prototype.set = function (seconds, decayRate, reverse) {
        var rebuild = false;
        if (seconds) {
            this._seconds = seconds;
            rebuild = true;
        }
        if (decayRate) {
            this._decay = decayRate;
        }
        if (reverse) {
            this._reverse = reverse;
        }
        if (rebuild) {
            this._buildImpulse();
        }
    };
    p5.Reverb.prototype._buildImpulse = function () {
        var rate = this.ac.sampleRate;
        var length = rate * this._seconds;
        var decay = this._decay;
        var impulse = this.ac.createBuffer(2, length, rate);
        var impulseL = impulse.getChannelData(0);
        var impulseR = impulse.getChannelData(1);
        var n, i;
        for (i = 0; i < length; i++) {
            n = this._reverse ? length - i : i;
            impulseL[i] = (Math.random() * 2 - 1) * Math.pow(1 - n / length, decay);
            impulseR[i] = (Math.random() * 2 - 1) * Math.pow(1 - n / length, decay);
        }
        this._setBuffer(impulse);
    };
    p5.Reverb.prototype.dispose = function () {
        Effect.prototype.dispose.apply(this);
        this._teardownConvolverNode();
    };
    p5.Convolver = function (path, callback, errorCallback) {
        p5.Reverb.call(this);
        this._initConvolverNode();
        this.input.gain.value = 0.5;
        if (path) {
            this.impulses = [];
            this._loadBuffer(path, callback, errorCallback);
        } else {
            this._seconds = 3;
            this._decay = 2;
            this._reverse = false;
            this._buildImpulse();
        }
    };
    p5.Convolver.prototype = Object.create(p5.Reverb.prototype);
    p5.prototype.registerPreloadMethod('createConvolver', p5.prototype);
    p5.prototype.createConvolver = function (path, callback, errorCallback) {
        if (window.location.origin.indexOf('file://') > -1 && window.cordova === 'undefined') {
            alert('This sketch may require a server to load external files. Please see http://bit.ly/1qcInwS');
        }
        var self = this;
        var cReverb = new p5.Convolver(path, function (buffer) {
            if (typeof callback === 'function') {
                callback(buffer);
            }
            if (typeof self._decrementPreload === 'function') {
                self._decrementPreload();
            }
        }, errorCallback);
        cReverb.impulses = [];
        return cReverb;
    };
    p5.Convolver.prototype._loadBuffer = function (path, callback, errorCallback) {
        var path = p5.prototype._checkFileFormats(path);
        var self = this;
        var errorTrace = new Error().stack;
        var ac = p5.prototype.getAudioContext();
        var request = new XMLHttpRequest();
        request.open('GET', path, true);
        request.responseType = 'arraybuffer';
        request.onload = function () {
            if (request.status === 200) {
                ac.decodeAudioData(request.response, function (buff) {
                    var buffer = {};
                    var chunks = path.split('/');
                    buffer.name = chunks[chunks.length - 1];
                    buffer.audioBuffer = buff;
                    self.impulses.push(buffer);
                    self._setBuffer(buffer.audioBuffer);
                    if (callback) {
                        callback(buffer);
                    }
                }, function () {
                    var err = new CustomError('decodeAudioData', errorTrace, self.url);
                    var msg = 'AudioContext error at decodeAudioData for ' + self.url;
                    if (errorCallback) {
                        err.msg = msg;
                        errorCallback(err);
                    } else {
                        console.error(msg + '\n The error stack trace includes: \n' + err.stack);
                    }
                });
            } else {
                var err = new CustomError('loadConvolver', errorTrace, self.url);
                var msg = 'Unable to load ' + self.url + '. The request status was: ' + request.status + ' (' + request.statusText + ')';
                if (errorCallback) {
                    err.message = msg;
                    errorCallback(err);
                } else {
                    console.error(msg + '\n The error stack trace includes: \n' + err.stack);
                }
            }
        };
        request.onerror = function () {
            var err = new CustomError('loadConvolver', errorTrace, self.url);
            var msg = 'There was no response from the server at ' + self.url + '. Check the url and internet connectivity.';
            if (errorCallback) {
                err.message = msg;
                errorCallback(err);
            } else {
                console.error(msg + '\n The error stack trace includes: \n' + err.stack);
            }
        };
        request.send();
    };
    p5.Convolver.prototype.set = null;
    p5.Convolver.prototype.process = function (src) {
        src.connect(this.input);
    };
    p5.Convolver.prototype.impulses = [];
    p5.Convolver.prototype.addImpulse = function (path, callback, errorCallback) {
        if (window.location.origin.indexOf('file://') > -1 && window.cordova === 'undefined') {
            alert('This sketch may require a server to load external files. Please see http://bit.ly/1qcInwS');
        }
        this._loadBuffer(path, callback, errorCallback);
    };
    p5.Convolver.prototype.resetImpulse = function (path, callback, errorCallback) {
        if (window.location.origin.indexOf('file://') > -1 && window.cordova === 'undefined') {
            alert('This sketch may require a server to load external files. Please see http://bit.ly/1qcInwS');
        }
        this.impulses = [];
        this._loadBuffer(path, callback, errorCallback);
    };
    p5.Convolver.prototype.toggleImpulse = function (id) {
        if (typeof id === 'number' && id < this.impulses.length) {
            this._setBuffer(this.impulses[id].audioBuffer);
        }
        if (typeof id === 'string') {
            for (var i = 0; i < this.impulses.length; i++) {
                if (this.impulses[i].name === id) {
                    this._setBuffer(this.impulses[i].audioBuffer);
                    break;
                }
            }
        }
    };
    p5.Convolver.prototype.dispose = function () {
        p5.Reverb.prototype.dispose.apply(this);
        for (var i in this.impulses) {
            if (this.impulses[i]) {
                this.impulses[i] = null;
            }
        }
    };
}(errorHandler, effect);
define('Tone/core/TimelineState',["Tone/core/Tone", "Tone/core/Timeline", "Tone/type/Type"], function (Tone) {

	"use strict";

	/**
	 *  @class  A Timeline State. Provides the methods: <code>setStateAtTime("state", time)</code>
	 *          and <code>getValueAtTime(time)</code>.
	 *
	 *  @extends {Tone.Timeline}
	 *  @param {String} initial The initial state of the TimelineState. 
	 *                          Defaults to <code>undefined</code>
	 */
	Tone.TimelineState = function(initial){

		Tone.Timeline.call(this);

		/**
		 *  The initial state
		 *  @private
		 *  @type {String}
		 */
		this._initial = initial;
	};

	Tone.extend(Tone.TimelineState, Tone.Timeline);

	/**
	 *  Returns the scheduled state scheduled before or at
	 *  the given time.
	 *  @param  {Number}  time  The time to query.
	 *  @return  {String}  The name of the state input in setStateAtTime.
	 */
	Tone.TimelineState.prototype.getValueAtTime = function(time){
		var event = this.get(time);
		if (event !== null){
			return event.state;
		} else {
			return this._initial;
		}
	};

	/**
	 *  Returns the scheduled state scheduled before or at
	 *  the given time.
	 *  @param  {String}  state The name of the state to set.
	 *  @param  {Number}  time  The time to query.
	 */
	Tone.TimelineState.prototype.setStateAtTime = function(state, time){
		this.add({
			"state" : state,
			"time" : time
		});
	};

	return Tone.TimelineState;
});
define('Tone/core/Clock',["Tone/core/Tone", "Tone/signal/TimelineSignal", "Tone/core/TimelineState", 
	"Tone/core/Emitter", "Tone/core/Context"], function (Tone) {

	"use strict";

	/**
	 *  @class  A sample accurate clock which provides a callback at the given rate. 
	 *          While the callback is not sample-accurate (it is still susceptible to
	 *          loose JS timing), the time passed in as the argument to the callback
	 *          is precise. For most applications, it is better to use Tone.Transport
	 *          instead of the Clock by itself since you can synchronize multiple callbacks.
	 *
	 * 	@constructor
	 *  @extends {Tone.Emitter}
	 * 	@param {function} callback The callback to be invoked with the time of the audio event
	 * 	@param {Frequency} frequency The rate of the callback
	 * 	@example
	 * //the callback will be invoked approximately once a second
	 * //and will print the time exactly once a second apart.
	 * var clock = new Tone.Clock(function(time){
	 * 	
	 * }, 1);
	 */
	Tone.Clock = function(){

		Tone.Emitter.call(this);

		var options = this.optionsObject(arguments, ["callback", "frequency"], Tone.Clock.defaults);

		/**
		 *  The callback function to invoke at the scheduled tick.
		 *  @type  {Function}
		 */
		this.callback = options.callback;

		/**
		 *  The next time the callback is scheduled.
		 *  @type {Number}
		 *  @private
		 */
		this._nextTick = 0;

		/**
		 *  The last state of the clock.
		 *  @type  {State}
		 *  @private
		 */
		this._lastState = Tone.State.Stopped;

		/**
		 *  The rate the callback function should be invoked. 
		 *  @type  {BPM}
		 *  @signal
		 */
		this.frequency = new Tone.TimelineSignal(options.frequency, Tone.Type.Frequency);
		this._readOnly("frequency");

		/**
		 *  The number of times the callback was invoked. Starts counting at 0
		 *  and increments after the callback was invoked. 
		 *  @type {Ticks}
		 *  @readOnly
		 */
		this.ticks = 0;

		/**
		 *  The state timeline
		 *  @type {Tone.TimelineState}
		 *  @private
		 */
		this._state = new Tone.TimelineState(Tone.State.Stopped);

		/**
		 *  The loop function bound to its context. 
		 *  This is necessary to remove the event in the end.
		 *  @type {Function}
		 *  @private
		 */
		this._boundLoop = this._loop.bind(this);

		//bind a callback to the worker thread
    	this.context.on("tick", this._boundLoop);
	};

	Tone.extend(Tone.Clock, Tone.Emitter);

	/**
	 *  The defaults
	 *  @const
	 *  @type  {Object}
	 */
	Tone.Clock.defaults = {
		"callback" : Tone.noOp,
		"frequency" : 1,
		"lookAhead" : "auto",
	};

	/**
	 *  Returns the playback state of the source, either "started", "stopped" or "paused".
	 *  @type {Tone.State}
	 *  @readOnly
	 *  @memberOf Tone.Clock#
	 *  @name state
	 */
	Object.defineProperty(Tone.Clock.prototype, "state", {
		get : function(){
			return this._state.getValueAtTime(this.now());
		}
	});

	/**
	 *  Start the clock at the given time. Optionally pass in an offset
	 *  of where to start the tick counter from.
	 *  @param  {Time}  time    The time the clock should start
	 *  @param  {Ticks=}  offset  Where the tick counter starts counting from.
	 *  @return  {Tone.Clock}  this
	 */
	Tone.Clock.prototype.start = function(time, offset){
		time = this.toSeconds(time);
		if (this._state.getValueAtTime(time) !== Tone.State.Started){
			this._state.add({
				"state" : Tone.State.Started, 
				"time" : time,
				"offset" : offset
			});
		}
		return this;	
	};

	/**
	 *  Stop the clock. Stopping the clock resets the tick counter to 0.
	 *  @param {Time} [time=now] The time when the clock should stop.
	 *  @returns {Tone.Clock} this
	 *  @example
	 * clock.stop();
	 */
	Tone.Clock.prototype.stop = function(time){
		time = this.toSeconds(time);
		this._state.cancel(time);
		this._state.setStateAtTime(Tone.State.Stopped, time);
		return this;	
	};


	/**
	 *  Pause the clock. Pausing does not reset the tick counter.
	 *  @param {Time} [time=now] The time when the clock should stop.
	 *  @returns {Tone.Clock} this
	 */
	Tone.Clock.prototype.pause = function(time){
		time = this.toSeconds(time);
		if (this._state.getValueAtTime(time) === Tone.State.Started){
			this._state.setStateAtTime(Tone.State.Paused, time);
		}
		return this;	
	};

	/**
	 *  The scheduling loop.
	 *  @param  {Number}  time  The current page time starting from 0
	 *                          when the page was loaded.
	 *  @private
	 */
	Tone.Clock.prototype._loop = function(){
		//get the frequency value to compute the value of the next loop
		var now = this.now();
		//if it's started
		var lookAhead = this.context.lookAhead;
		var updateInterval = this.context.updateInterval;
		var lagCompensation = this.context.lag * 2;
		var loopInterval = now + lookAhead + updateInterval + lagCompensation;
		while (loopInterval > this._nextTick && this._state){
			var currentState = this._state.getValueAtTime(this._nextTick);
			if (currentState !== this._lastState){
				this._lastState = currentState;
				var event = this._state.get(this._nextTick);
				// emit an event
				if (currentState === Tone.State.Started){
					//correct the time
					this._nextTick = event.time;
					if (!this.isUndef(event.offset)){
						this.ticks = event.offset;
					}
					this.emit("start", event.time, this.ticks);
				} else if (currentState === Tone.State.Stopped){
					this.ticks = 0;

					this.emit("stop", event.time);
				} else if (currentState === Tone.State.Paused){
					this.emit("pause", event.time);
				}
			}
			var tickTime = this._nextTick;
			if (this.frequency){
				this._nextTick += 1 / this.frequency.getValueAtTime(this._nextTick);
				if (currentState === Tone.State.Started){
					this.callback(tickTime);
					this.ticks++;
				}
			}
		}
	};

	/**
	 *  Returns the scheduled state at the given time.
	 *  @param  {Time}  time  The time to query.
	 *  @return  {String}  The name of the state input in setStateAtTime.
	 *  @example
	 * clock.start("+0.1");
	 * clock.getStateAtTime("+0.1"); //returns "started"
	 */
	Tone.Clock.prototype.getStateAtTime = function(time){
		time = this.toSeconds(time);
		return this._state.getValueAtTime(time);
	};

	/**
	 *  Clean up
	 *  @returns {Tone.Clock} this
	 */
	Tone.Clock.prototype.dispose = function(){
		Tone.Emitter.prototype.dispose.call(this);
		this.context.off("tick", this._boundLoop);
		this._writable("frequency");
		this.frequency.dispose();
		this.frequency = null;
		this._boundLoop = null;
		this._nextTick = Infinity;
		this.callback = null;
		this._state.dispose();
		this._state = null;
	};

	return Tone.Clock;
});
var metro;
'use strict';
metro = function () {
    var p5sound = master;
    var Clock = Tone_core_Clock;
    p5.Metro = function () {
        this.clock = new Clock({ 'callback': this.ontick.bind(this) });
        this.syncedParts = [];
        this.bpm = 120;
        this._init();
        this.prevTick = 0;
        this.tatumTime = 0;
        this.tickCallback = function () {
        };
    };
    p5.Metro.prototype.ontick = function (tickTime) {
        var elapsedTime = tickTime - this.prevTick;
        var secondsFromNow = tickTime - p5sound.audiocontext.currentTime;
        if (elapsedTime - this.tatumTime <= -0.02) {
            return;
        } else {
            this.prevTick = tickTime;
            var self = this;
            this.syncedParts.forEach(function (thisPart) {
                if (!thisPart.isPlaying)
                    return;
                thisPart.incrementStep(secondsFromNow);
                thisPart.phrases.forEach(function (thisPhrase) {
                    var phraseArray = thisPhrase.sequence;
                    var bNum = self.metroTicks % phraseArray.length;
                    if (phraseArray[bNum] !== 0 && (self.metroTicks < phraseArray.length || !thisPhrase.looping)) {
                        thisPhrase.callback(secondsFromNow, phraseArray[bNum]);
                    }
                });
            });
            this.metroTicks += 1;
            this.tickCallback(secondsFromNow);
        }
    };
    p5.Metro.prototype.setBPM = function (bpm, rampTime) {
        var beatTime = 60 / (bpm * this.tatums);
        var now = p5sound.audiocontext.currentTime;
        this.tatumTime = beatTime;
        var rampTime = rampTime || 0;
        this.clock.frequency.setValueAtTime(this.clock.frequency.value, now);
        this.clock.frequency.linearRampToValueAtTime(bpm, now + rampTime);
        this.bpm = bpm;
    };
    p5.Metro.prototype.getBPM = function () {
        return this.clock.getRate() / this.tatums * 60;
    };
    p5.Metro.prototype._init = function () {
        this.metroTicks = 0;
    };
    p5.Metro.prototype.resetSync = function (part) {
        this.syncedParts = [part];
    };
    p5.Metro.prototype.pushSync = function (part) {
        this.syncedParts.push(part);
    };
    p5.Metro.prototype.start = function (timeFromNow) {
        var t = timeFromNow || 0;
        var now = p5sound.audiocontext.currentTime;
        this.clock.start(now + t);
        this.setBPM(this.bpm);
    };
    p5.Metro.prototype.stop = function (timeFromNow) {
        var t = timeFromNow || 0;
        var now = p5sound.audiocontext.currentTime;
        this.clock.stop(now + t);
    };
    p5.Metro.prototype.beatLength = function (tatums) {
        this.tatums = 1 / tatums / 4;
    };
}(master, Tone_core_Clock);
var looper;
'use strict';
looper = function () {
    var p5sound = master;
    var BPM = 120;
    p5.prototype.setBPM = function (bpm, rampTime) {
        BPM = bpm;
        for (var i in p5sound.parts) {
            if (p5sound.parts[i]) {
                p5sound.parts[i].setBPM(bpm, rampTime);
            }
        }
    };
    p5.Phrase = function (name, callback, sequence) {
        this.phraseStep = 0;
        this.name = name;
        this.callback = callback;
        this.sequence = sequence;
    };
    p5.Part = function (steps, bLength) {
        this.length = steps || 0;
        this.partStep = 0;
        this.phrases = [];
        this.isPlaying = false;
        this.noLoop();
        this.tatums = bLength || 0.0625;
        this.metro = new p5.Metro();
        this.metro._init();
        this.metro.beatLength(this.tatums);
        this.metro.setBPM(BPM);
        p5sound.parts.push(this);
        this.callback = function () {
        };
    };
    p5.Part.prototype.setBPM = function (tempo, rampTime) {
        this.metro.setBPM(tempo, rampTime);
    };
    p5.Part.prototype.getBPM = function () {
        return this.metro.getBPM();
    };
    p5.Part.prototype.start = function (time) {
        if (!this.isPlaying) {
            this.isPlaying = true;
            this.metro.resetSync(this);
            var t = time || 0;
            this.metro.start(t);
        }
    };
    p5.Part.prototype.loop = function (time) {
        this.looping = true;
        this.onended = function () {
            this.partStep = 0;
        };
        var t = time || 0;
        this.start(t);
    };
    p5.Part.prototype.noLoop = function () {
        this.looping = false;
        this.onended = function () {
            this.stop();
        };
    };
    p5.Part.prototype.stop = function (time) {
        this.partStep = 0;
        this.pause(time);
    };
    p5.Part.prototype.pause = function (time) {
        this.isPlaying = false;
        var t = time || 0;
        this.metro.stop(t);
    };
    p5.Part.prototype.addPhrase = function (name, callback, array) {
        var p;
        if (arguments.length === 3) {
            p = new p5.Phrase(name, callback, array);
        } else if (arguments[0] instanceof p5.Phrase) {
            p = arguments[0];
        } else {
            throw 'invalid input. addPhrase accepts name, callback, array or a p5.Phrase';
        }
        this.phrases.push(p);
        if (p.sequence.length > this.length) {
            this.length = p.sequence.length;
        }
    };
    p5.Part.prototype.removePhrase = function (name) {
        for (var i in this.phrases) {
            if (this.phrases[i].name === name) {
                this.phrases.splice(i, 1);
            }
        }
    };
    p5.Part.prototype.getPhrase = function (name) {
        for (var i in this.phrases) {
            if (this.phrases[i].name === name) {
                return this.phrases[i];
            }
        }
    };
    p5.Part.prototype.replaceSequence = function (name, array) {
        for (var i in this.phrases) {
            if (this.phrases[i].name === name) {
                this.phrases[i].sequence = array;
            }
        }
    };
    p5.Part.prototype.incrementStep = function (time) {
        if (this.partStep < this.length - 1) {
            this.callback(time);
            this.partStep += 1;
        } else {
            if (!this.looping && this.partStep === this.length - 1) {
                console.log('done');
                this.onended();
            }
        }
    };
    p5.Part.prototype.onStep = function (callback) {
        this.callback = callback;
    };
    p5.Score = function () {
        this.parts = [];
        this.currentPart = 0;
        var thisScore = this;
        for (var i in arguments) {
            if (arguments[i] && this.parts[i]) {
                this.parts[i] = arguments[i];
                this.parts[i].nextPart = this.parts[i + 1];
                this.parts[i].onended = function () {
                    thisScore.resetPart(i);
                    playNextPart(thisScore);
                };
            }
        }
        this.looping = false;
    };
    p5.Score.prototype.onended = function () {
        if (this.looping) {
            this.parts[0].start();
        } else {
            this.parts[this.parts.length - 1].onended = function () {
                this.stop();
                this.resetParts();
            };
        }
        this.currentPart = 0;
    };
    p5.Score.prototype.start = function () {
        this.parts[this.currentPart].start();
        this.scoreStep = 0;
    };
    p5.Score.prototype.stop = function () {
        this.parts[this.currentPart].stop();
        this.currentPart = 0;
        this.scoreStep = 0;
    };
    p5.Score.prototype.pause = function () {
        this.parts[this.currentPart].stop();
    };
    p5.Score.prototype.loop = function () {
        this.looping = true;
        this.start();
    };
    p5.Score.prototype.noLoop = function () {
        this.looping = false;
    };
    p5.Score.prototype.resetParts = function () {
        var self = this;
        this.parts.forEach(function (part) {
            self.resetParts[part];
        });
    };
    p5.Score.prototype.resetPart = function (i) {
        this.parts[i].stop();
        this.parts[i].partStep = 0;
        for (var p in this.parts[i].phrases) {
            if (this.parts[i]) {
                this.parts[i].phrases[p].phraseStep = 0;
            }
        }
    };
    p5.Score.prototype.setBPM = function (bpm, rampTime) {
        for (var i in this.parts) {
            if (this.parts[i]) {
                this.parts[i].setBPM(bpm, rampTime);
            }
        }
    };
    function playNextPart(aScore) {
        aScore.currentPart++;
        if (aScore.currentPart >= aScore.parts.length) {
            aScore.scoreStep = 0;
            aScore.onended();
        } else {
            aScore.scoreStep = 0;
            aScore.parts[aScore.currentPart - 1].stop();
            aScore.parts[aScore.currentPart].start();
        }
    }
}(master);
var soundloop;
'use strict';
soundloop = function () {
    var p5sound = master;
    var Clock = Tone_core_Clock;
    p5.SoundLoop = function (callback, interval) {
        this.callback = callback;
        this.musicalTimeMode = typeof this._interval === 'number' ? false : true;
        this._interval = interval || 1;
        this._timeSignature = 4;
        this._bpm = 60;
        this.isPlaying = false;
        this.maxIterations = Infinity;
        var self = this;
        this.clock = new Clock({
            'callback': function (time) {
                var timeFromNow = time - p5sound.audiocontext.currentTime;
                if (timeFromNow > 0 && self.iterations <= self.maxIterations) {
                    self.callback(timeFromNow);
                }
            },
            'frequency': this._calcFreq()
        });
    };
    p5.SoundLoop.prototype.start = function (timeFromNow) {
        var t = timeFromNow || 0;
        var now = p5sound.audiocontext.currentTime;
        if (!this.isPlaying) {
            this.clock.start(now + t);
            this.isPlaying = true;
        }
    };
    p5.SoundLoop.prototype.stop = function (timeFromNow) {
        var t = timeFromNow || 0;
        var now = p5sound.audiocontext.currentTime;
        if (this.isPlaying) {
            this.clock.stop(now + t);
            this.isPlaying = false;
        }
    };
    p5.SoundLoop.prototype.pause = function (timeFromNow) {
        var t = timeFromNow || 0;
        var now = p5sound.audiocontext.currentTime;
        if (this.isPlaying) {
            this.clock.pause(now + t);
            this.isPlaying = false;
        }
    };
    p5.SoundLoop.prototype.syncedStart = function (otherLoop, timeFromNow) {
        var t = timeFromNow || 0;
        var now = p5sound.audiocontext.currentTime;
        if (!otherLoop.isPlaying) {
            otherLoop.clock.start(now + t);
            otherLoop.isPlaying = true;
            this.clock.start(now + t);
            this.isPlaying = true;
        } else if (otherLoop.isPlaying) {
            var time = otherLoop.clock._nextTick - p5sound.audiocontext.currentTime;
            this.clock.start(now + time);
            this.isPlaying = true;
        }
    };
    p5.SoundLoop.prototype._update = function () {
        this.clock.frequency.value = this._calcFreq();
    };
    p5.SoundLoop.prototype._calcFreq = function () {
        if (typeof this._interval === 'number') {
            this.musicalTimeMode = false;
            return 1 / this._interval;
        } else if (typeof this._interval === 'string') {
            this.musicalTimeMode = true;
            return this._bpm / 60 / this._convertNotation(this._interval) * (this._timeSignature / 4);
        }
    };
    p5.SoundLoop.prototype._convertNotation = function (value) {
        var type = value.slice(-1);
        value = Number(value.slice(0, -1));
        switch (type) {
        case 'm':
            return this._measure(value);
        case 'n':
            return this._note(value);
        default:
            console.warn('Specified interval is not formatted correctly. See Tone.js ' + 'timing reference for more info: https://github.com/Tonejs/Tone.js/wiki/Time');
        }
    };
    p5.SoundLoop.prototype._measure = function (value) {
        return value * this._timeSignature;
    };
    p5.SoundLoop.prototype._note = function (value) {
        return this._timeSignature / value;
    };
    Object.defineProperty(p5.SoundLoop.prototype, 'bpm', {
        get: function () {
            return this._bpm;
        },
        set: function (bpm) {
            if (!this.musicalTimeMode) {
                console.warn('Changing the BPM in "seconds" mode has no effect. ' + 'BPM is only relevant in musicalTimeMode ' + 'when the interval is specified as a string ' + '("2n", "4n", "1m"...etc)');
            }
            this._bpm = bpm;
            this._update();
        }
    });
    Object.defineProperty(p5.SoundLoop.prototype, 'timeSignature', {
        get: function () {
            return this._timeSignature;
        },
        set: function (timeSig) {
            if (!this.musicalTimeMode) {
                console.warn('Changing the timeSignature in "seconds" mode has no effect. ' + 'BPM is only relevant in musicalTimeMode ' + 'when the interval is specified as a string ' + '("2n", "4n", "1m"...etc)');
            }
            this._timeSignature = timeSig;
            this._update();
        }
    });
    Object.defineProperty(p5.SoundLoop.prototype, 'interval', {
        get: function () {
            return this._interval;
        },
        set: function (interval) {
            this.musicalTimeMode = typeof interval === 'Number' ? false : true;
            this._interval = interval;
            this._update();
        }
    });
    Object.defineProperty(p5.SoundLoop.prototype, 'iterations', {
        get: function () {
            return this.clock.ticks;
        }
    });
    return p5.SoundLoop;
}(master, Tone_core_Clock);
var compressor;
compressor = function () {
    'use strict';
    var p5sound = master;
    var Effect = effect;
    var CustomError = errorHandler;
    p5.Compressor = function () {
        Effect.call(this);
        this.compressor = this.ac.createDynamicsCompressor();
        this.input.connect(this.compressor);
        this.compressor.connect(this.wet);
    };
    p5.Compressor.prototype = Object.create(Effect.prototype);
    p5.Compressor.prototype.process = function (src, attack, knee, ratio, threshold, release) {
        src.connect(this.input);
        this.set(attack, knee, ratio, threshold, release);
    };
    p5.Compressor.prototype.set = function (attack, knee, ratio, threshold, release) {
        if (typeof attack !== 'undefined') {
            this.attack(attack);
        }
        if (typeof knee !== 'undefined') {
            this.knee(knee);
        }
        if (typeof ratio !== 'undefined') {
            this.ratio(ratio);
        }
        if (typeof threshold !== 'undefined') {
            this.threshold(threshold);
        }
        if (typeof release !== 'undefined') {
            this.release(release);
        }
    };
    p5.Compressor.prototype.attack = function (attack, time) {
        var t = time || 0;
        if (typeof attack == 'number') {
            this.compressor.attack.value = attack;
            this.compressor.attack.cancelScheduledValues(this.ac.currentTime + 0.01 + t);
            this.compressor.attack.linearRampToValueAtTime(attack, this.ac.currentTime + 0.02 + t);
        } else if (typeof attack !== 'undefined') {
            attack.connect(this.compressor.attack);
        }
        return this.compressor.attack.value;
    };
    p5.Compressor.prototype.knee = function (knee, time) {
        var t = time || 0;
        if (typeof knee == 'number') {
            this.compressor.knee.value = knee;
            this.compressor.knee.cancelScheduledValues(this.ac.currentTime + 0.01 + t);
            this.compressor.knee.linearRampToValueAtTime(knee, this.ac.currentTime + 0.02 + t);
        } else if (typeof knee !== 'undefined') {
            knee.connect(this.compressor.knee);
        }
        return this.compressor.knee.value;
    };
    p5.Compressor.prototype.ratio = function (ratio, time) {
        var t = time || 0;
        if (typeof ratio == 'number') {
            this.compressor.ratio.value = ratio;
            this.compressor.ratio.cancelScheduledValues(this.ac.currentTime + 0.01 + t);
            this.compressor.ratio.linearRampToValueAtTime(ratio, this.ac.currentTime + 0.02 + t);
        } else if (typeof ratio !== 'undefined') {
            ratio.connect(this.compressor.ratio);
        }
        return this.compressor.ratio.value;
    };
    p5.Compressor.prototype.threshold = function (threshold, time) {
        var t = time || 0;
        if (typeof threshold == 'number') {
            this.compressor.threshold.value = threshold;
            this.compressor.threshold.cancelScheduledValues(this.ac.currentTime + 0.01 + t);
            this.compressor.threshold.linearRampToValueAtTime(threshold, this.ac.currentTime + 0.02 + t);
        } else if (typeof threshold !== 'undefined') {
            threshold.connect(this.compressor.threshold);
        }
        return this.compressor.threshold.value;
    };
    p5.Compressor.prototype.release = function (release, time) {
        var t = time || 0;
        if (typeof release == 'number') {
            this.compressor.release.value = release;
            this.compressor.release.cancelScheduledValues(this.ac.currentTime + 0.01 + t);
            this.compressor.release.linearRampToValueAtTime(release, this.ac.currentTime + 0.02 + t);
        } else if (typeof number !== 'undefined') {
            release.connect(this.compressor.release);
        }
        return this.compressor.release.value;
    };
    p5.Compressor.prototype.reduction = function () {
        return this.compressor.reduction.value;
    };
    p5.Compressor.prototype.dispose = function () {
        Effect.prototype.dispose.apply(this);
        if (this.compressor) {
            this.compressor.disconnect();
            delete this.compressor;
        }
    };
    return p5.Compressor;
}(master, effect, errorHandler);
var soundRecorder;
'use strict';
soundRecorder = function () {
    var p5sound = master;
    var convertToWav = helpers.convertToWav;
    var ac = p5sound.audiocontext;
    p5.SoundRecorder = function () {
        this.input = ac.createGain();
        this.output = ac.createGain();
        this.recording = false;
        this.bufferSize = 1024;
        this._channels = 2;
        this._clear();
        this._jsNode = ac.createScriptProcessor(this.bufferSize, this._channels, 2);
        this._jsNode.onaudioprocess = this._audioprocess.bind(this);
        this._callback = function () {
        };
        this._jsNode.connect(p5.soundOut._silentNode);
        this.setInput();
        p5sound.soundArray.push(this);
    };
    p5.SoundRecorder.prototype.setInput = function (unit) {
        this.input.disconnect();
        this.input = null;
        this.input = ac.createGain();
        this.input.connect(this._jsNode);
        this.input.connect(this.output);
        if (unit) {
            unit.connect(this.input);
        } else {
            p5.soundOut.output.connect(this.input);
        }
    };
    p5.SoundRecorder.prototype.record = function (sFile, duration, callback) {
        this.recording = true;
        if (duration) {
            this.sampleLimit = Math.round(duration * ac.sampleRate);
        }
        if (sFile && callback) {
            this._callback = function () {
                this.buffer = this._getBuffer();
                sFile.setBuffer(this.buffer);
                callback();
            };
        } else if (sFile) {
            this._callback = function () {
                this.buffer = this._getBuffer();
                sFile.setBuffer(this.buffer);
            };
        }
    };
    p5.SoundRecorder.prototype.stop = function () {
        this.recording = false;
        this._callback();
        this._clear();
    };
    p5.SoundRecorder.prototype._clear = function () {
        this._leftBuffers = [];
        this._rightBuffers = [];
        this.recordedSamples = 0;
        this.sampleLimit = null;
    };
    p5.SoundRecorder.prototype._audioprocess = function (event) {
        if (this.recording === false) {
            return;
        } else if (this.recording === true) {
            if (this.sampleLimit && this.recordedSamples >= this.sampleLimit) {
                this.stop();
            } else {
                var left = event.inputBuffer.getChannelData(0);
                var right = event.inputBuffer.getChannelData(1);
                this._leftBuffers.push(new Float32Array(left));
                this._rightBuffers.push(new Float32Array(right));
                this.recordedSamples += this.bufferSize;
            }
        }
    };
    p5.SoundRecorder.prototype._getBuffer = function () {
        var buffers = [];
        buffers.push(this._mergeBuffers(this._leftBuffers));
        buffers.push(this._mergeBuffers(this._rightBuffers));
        return buffers;
    };
    p5.SoundRecorder.prototype._mergeBuffers = function (channelBuffer) {
        var result = new Float32Array(this.recordedSamples);
        var offset = 0;
        var lng = channelBuffer.length;
        for (var i = 0; i < lng; i++) {
            var buffer = channelBuffer[i];
            result.set(buffer, offset);
            offset += buffer.length;
        }
        return result;
    };
    p5.SoundRecorder.prototype.dispose = function () {
        this._clear();
        var index = p5sound.soundArray.indexOf(this);
        p5sound.soundArray.splice(index, 1);
        this._callback = function () {
        };
        if (this.input) {
            this.input.disconnect();
        }
        this.input = null;
        this._jsNode = null;
    };
    p5.prototype.saveSound = function (soundFile, fileName) {
        const dataView = convertToWav(soundFile.buffer);
        p5.prototype.writeFile([dataView], fileName, 'wav');
    };
}(master, helpers);
var peakdetect;
'use strict';
peakdetect = function () {
    p5.PeakDetect = function (freq1, freq2, threshold, _framesPerPeak) {
        this.framesPerPeak = _framesPerPeak || 20;
        this.framesSinceLastPeak = 0;
        this.decayRate = 0.95;
        this.threshold = threshold || 0.35;
        this.cutoff = 0;
        this.cutoffMult = 1.5;
        this.energy = 0;
        this.penergy = 0;
        this.currentValue = 0;
        this.isDetected = false;
        this.f1 = freq1 || 40;
        this.f2 = freq2 || 20000;
        this._onPeak = function () {
        };
    };
    p5.PeakDetect.prototype.update = function (fftObject) {
        var nrg = this.energy = fftObject.getEnergy(this.f1, this.f2) / 255;
        if (nrg > this.cutoff && nrg > this.threshold && nrg - this.penergy > 0) {
            this._onPeak();
            this.isDetected = true;
            this.cutoff = nrg * this.cutoffMult;
            this.framesSinceLastPeak = 0;
        } else {
            this.isDetected = false;
            if (this.framesSinceLastPeak <= this.framesPerPeak) {
                this.framesSinceLastPeak++;
            } else {
                this.cutoff *= this.decayRate;
                this.cutoff = Math.max(this.cutoff, this.threshold);
            }
        }
        this.currentValue = nrg;
        this.penergy = nrg;
    };
    p5.PeakDetect.prototype.onPeak = function (callback, val) {
        var self = this;
        self._onPeak = function () {
            callback(self.energy, val);
        };
    };
}();
var gain;
'use strict';
gain = function () {
    var p5sound = master;
    p5.Gain = function () {
        this.ac = p5sound.audiocontext;
        this.input = this.ac.createGain();
        this.output = this.ac.createGain();
        this.input.gain.value = 0.5;
        this.input.connect(this.output);
        p5sound.soundArray.push(this);
    };
    p5.Gain.prototype.setInput = function (src) {
        src.connect(this.input);
    };
    p5.Gain.prototype.connect = function (unit) {
        var u = unit || p5.soundOut.input;
        this.output.connect(u.input ? u.input : u);
    };
    p5.Gain.prototype.disconnect = function () {
        if (this.output) {
            this.output.disconnect();
        }
    };
    p5.Gain.prototype.amp = function (vol, rampTime, tFromNow) {
        var rampTime = rampTime || 0;
        var tFromNow = tFromNow || 0;
        var now = p5sound.audiocontext.currentTime;
        var currentVol = this.output.gain.value;
        this.output.gain.cancelScheduledValues(now);
        this.output.gain.linearRampToValueAtTime(currentVol, now + tFromNow);
        this.output.gain.linearRampToValueAtTime(vol, now + tFromNow + rampTime);
    };
    p5.Gain.prototype.dispose = function () {
        var index = p5sound.soundArray.indexOf(this);
        p5sound.soundArray.splice(index, 1);
        if (this.output) {
            this.output.disconnect();
            delete this.output;
        }
        if (this.input) {
            this.input.disconnect();
            delete this.input;
        }
    };
}(master);
var audioVoice;
'use strict';
audioVoice = function () {
    var p5sound = master;
    p5.AudioVoice = function () {
        this.ac = p5sound.audiocontext;
        this.output = this.ac.createGain();
        this.connect();
        p5sound.soundArray.push(this);
    };
    p5.AudioVoice.prototype.play = function (note, velocity, secondsFromNow, sustime) {
    };
    p5.AudioVoice.prototype.triggerAttack = function (note, velocity, secondsFromNow) {
    };
    p5.AudioVoice.prototype.triggerRelease = function (secondsFromNow) {
    };
    p5.AudioVoice.prototype.amp = function (vol, rampTime) {
    };
    p5.AudioVoice.prototype.connect = function (unit) {
        var u = unit || p5sound.input;
        this.output.connect(u.input ? u.input : u);
    };
    p5.AudioVoice.prototype.disconnect = function () {
        this.output.disconnect();
    };
    p5.AudioVoice.prototype.dispose = function () {
        if (this.output) {
            this.output.disconnect();
            delete this.output;
        }
    };
    return p5.AudioVoice;
}(master);
var monosynth;
'use strict';
monosynth = function () {
    var p5sound = master;
    var AudioVoice = audioVoice;
    var noteToFreq = helpers.noteToFreq;
    var DEFAULT_SUSTAIN = 0.15;
    p5.MonoSynth = function () {
        AudioVoice.call(this);
        this.oscillator = new p5.Oscillator();
        this.env = new p5.Envelope();
        this.env.setRange(1, 0);
        this.env.setExp(true);
        this.setADSR(0.02, 0.25, 0.05, 0.35);
        this.oscillator.disconnect();
        this.oscillator.connect(this.output);
        this.env.disconnect();
        this.env.setInput(this.output.gain);
        this.oscillator.output.gain.value = 1;
        this.oscillator.start();
        this.connect();
        p5sound.soundArray.push(this);
    };
    p5.MonoSynth.prototype = Object.create(p5.AudioVoice.prototype);
    p5.MonoSynth.prototype.play = function (note, velocity, secondsFromNow, susTime) {
        this.triggerAttack(note, velocity, ~~secondsFromNow);
        this.triggerRelease(~~secondsFromNow + (susTime || DEFAULT_SUSTAIN));
    };
    p5.MonoSynth.prototype.triggerAttack = function (note, velocity, secondsFromNow) {
        var secondsFromNow = ~~secondsFromNow;
        var freq = noteToFreq(note);
        var vel = velocity || 0.1;
        this.oscillator.freq(freq, 0, secondsFromNow);
        this.env.ramp(this.output.gain, secondsFromNow, vel);
    };
    p5.MonoSynth.prototype.triggerRelease = function (secondsFromNow) {
        var secondsFromNow = secondsFromNow || 0;
        this.env.ramp(this.output.gain, secondsFromNow, 0);
    };
    p5.MonoSynth.prototype.setADSR = function (attack, decay, sustain, release) {
        this.env.setADSR(attack, decay, sustain, release);
    };
    Object.defineProperties(p5.MonoSynth.prototype, {
        'attack': {
            get: function () {
                return this.env.aTime;
            },
            set: function (attack) {
                this.env.setADSR(attack, this.env.dTime, this.env.sPercent, this.env.rTime);
            }
        },
        'decay': {
            get: function () {
                return this.env.dTime;
            },
            set: function (decay) {
                this.env.setADSR(this.env.aTime, decay, this.env.sPercent, this.env.rTime);
            }
        },
        'sustain': {
            get: function () {
                return this.env.sPercent;
            },
            set: function (sustain) {
                this.env.setADSR(this.env.aTime, this.env.dTime, sustain, this.env.rTime);
            }
        },
        'release': {
            get: function () {
                return this.env.rTime;
            },
            set: function (release) {
                this.env.setADSR(this.env.aTime, this.env.dTime, this.env.sPercent, release);
            }
        }
    });
    p5.MonoSynth.prototype.amp = function (vol, rampTime) {
        var t = rampTime || 0;
        if (typeof vol !== 'undefined') {
            this.oscillator.amp(vol, t);
        }
        return this.oscillator.amp().value;
    };
    p5.MonoSynth.prototype.connect = function (unit) {
        var u = unit || p5sound.input;
        this.output.connect(u.input ? u.input : u);
    };
    p5.MonoSynth.prototype.disconnect = function () {
        if (this.output) {
            this.output.disconnect();
        }
    };
    p5.MonoSynth.prototype.dispose = function () {
        AudioVoice.prototype.dispose.apply(this);
        if (this.env) {
            this.env.dispose();
        }
        if (this.oscillator) {
            this.oscillator.dispose();
        }
    };
}(master, audioVoice, helpers);
var polysynth;
'use strict';
polysynth = function () {
    var p5sound = master;
    var TimelineSignal = Tone_signal_TimelineSignal;
    var noteToFreq = helpers.noteToFreq;
    p5.PolySynth = function (audioVoice, maxVoices) {
        this.audiovoices = [];
        this.notes = {};
        this._newest = 0;
        this._oldest = 0;
        this.maxVoices = maxVoices || 8;
        this.AudioVoice = audioVoice === undefined ? p5.MonoSynth : audioVoice;
        this._voicesInUse = new TimelineSignal(0);
        this.output = p5sound.audiocontext.createGain();
        this.connect();
        this._allocateVoices();
        p5sound.soundArray.push(this);
    };
    p5.PolySynth.prototype._allocateVoices = function () {
        for (var i = 0; i < this.maxVoices; i++) {
            this.audiovoices.push(new this.AudioVoice());
            this.audiovoices[i].disconnect();
            this.audiovoices[i].connect(this.output);
        }
    };
    p5.PolySynth.prototype.play = function (note, velocity, secondsFromNow, susTime) {
        var susTime = susTime || 1;
        this.noteAttack(note, velocity, secondsFromNow);
        this.noteRelease(note, secondsFromNow + susTime);
    };
    p5.PolySynth.prototype.noteADSR = function (note, a, d, s, r, timeFromNow) {
        var now = p5sound.audiocontext.currentTime;
        var timeFromNow = timeFromNow || 0;
        var t = now + timeFromNow;
        this.audiovoices[this.notes[note].getValueAtTime(t)].setADSR(a, d, s, r);
    };
    p5.PolySynth.prototype.setADSR = function (a, d, s, r) {
        this.audiovoices.forEach(function (voice) {
            voice.setADSR(a, d, s, r);
        });
    };
    p5.PolySynth.prototype.noteAttack = function (_note, _velocity, secondsFromNow) {
        var secondsFromNow = ~~secondsFromNow;
        var acTime = p5sound.audiocontext.currentTime + secondsFromNow;
        var note = noteToFreq(_note);
        var velocity = _velocity || 0.1;
        var currentVoice;
        if (this.notes[note] && this.notes[note].getValueAtTime(acTime) !== null) {
            this.noteRelease(note, 0);
        }
        if (this._voicesInUse.getValueAtTime(acTime) < this.maxVoices) {
            currentVoice = Math.max(~~this._voicesInUse.getValueAtTime(acTime), 0);
        } else {
            currentVoice = this._oldest;
            var oldestNote = p5.prototype.freqToMidi(this.audiovoices[this._oldest].oscillator.freq().value);
            this.noteRelease(oldestNote);
            this._oldest = (this._oldest + 1) % (this.maxVoices - 1);
        }
        this.notes[note] = new TimelineSignal();
        this.notes[note].setValueAtTime(currentVoice, acTime);
        var previousVal = this._voicesInUse._searchBefore(acTime) === null ? 0 : this._voicesInUse._searchBefore(acTime).value;
        this._voicesInUse.setValueAtTime(previousVal + 1, acTime);
        this._updateAfter(acTime, 1);
        this._newest = currentVoice;
        if (typeof velocity === 'number') {
            var maxRange = 1 / this._voicesInUse.getValueAtTime(acTime) * 2;
            velocity = velocity > maxRange ? maxRange : velocity;
        }
        this.audiovoices[currentVoice].triggerAttack(note, velocity, secondsFromNow);
    };
    p5.PolySynth.prototype._updateAfter = function (time, value) {
        if (this._voicesInUse._searchAfter(time) === null) {
            return;
        } else {
            this._voicesInUse._searchAfter(time).value += value;
            var nextTime = this._voicesInUse._searchAfter(time).time;
            this._updateAfter(nextTime, value);
        }
    };
    p5.PolySynth.prototype.noteRelease = function (_note, secondsFromNow) {
        var now = p5sound.audiocontext.currentTime;
        var tFromNow = secondsFromNow || 0;
        var t = now + tFromNow;
        if (!_note) {
            this.audiovoices.forEach(function (voice) {
                voice.triggerRelease(tFromNow);
            });
            this._voicesInUse.setValueAtTime(0, t);
            for (var n in this.notes) {
                this.notes[n].dispose();
                delete this.notes[n];
            }
            return;
        }
        var note = noteToFreq(_note);
        if (!this.notes[note] || this.notes[note].getValueAtTime(t) === null) {
            console.warn('Cannot release a note that is not already playing');
        } else {
            var previousVal = Math.max(~~this._voicesInUse.getValueAtTime(t).value, 1);
            this._voicesInUse.setValueAtTime(previousVal - 1, t);
            if (previousVal > 0) {
                this._updateAfter(t, -1);
            }
            this.audiovoices[this.notes[note].getValueAtTime(t)].triggerRelease(tFromNow);
            this.notes[note].dispose();
            delete this.notes[note];
            this._newest = this._newest === 0 ? 0 : (this._newest - 1) % (this.maxVoices - 1);
        }
    };
    p5.PolySynth.prototype.connect = function (unit) {
        var u = unit || p5sound.input;
        this.output.connect(u.input ? u.input : u);
    };
    p5.PolySynth.prototype.disconnect = function () {
        if (this.output) {
            this.output.disconnect();
        }
    };
    p5.PolySynth.prototype.dispose = function () {
        this.audiovoices.forEach(function (voice) {
            voice.dispose();
        });
        if (this.output) {
            this.output.disconnect();
            delete this.output;
        }
    };
}(master, Tone_signal_TimelineSignal, helpers);
var distortion;
'use strict';
distortion = function () {
    var Effect = effect;
    function makeDistortionCurve(amount) {
        var k = typeof amount === 'number' ? amount : 50;
        var numSamples = 44100;
        var curve = new Float32Array(numSamples);
        var deg = Math.PI / 180;
        var i = 0;
        var x;
        for (; i < numSamples; ++i) {
            x = i * 2 / numSamples - 1;
            curve[i] = (3 + k) * x * 20 * deg / (Math.PI + k * Math.abs(x));
        }
        return curve;
    }
    p5.Distortion = function (amount, oversample) {
        Effect.call(this);
        if (typeof amount === 'undefined') {
            amount = 0.25;
        }
        if (typeof amount !== 'number') {
            throw new Error('amount must be a number');
        }
        if (typeof oversample === 'undefined') {
            oversample = '2x';
        }
        if (typeof oversample !== 'string') {
            throw new Error('oversample must be a String');
        }
        var curveAmount = p5.prototype.map(amount, 0, 1, 0, 2000);
        this.waveShaperNode = this.ac.createWaveShaper();
        this.amount = curveAmount;
        this.waveShaperNode.curve = makeDistortionCurve(curveAmount);
        this.waveShaperNode.oversample = oversample;
        this.input.connect(this.waveShaperNode);
        this.waveShaperNode.connect(this.wet);
    };
    p5.Distortion.prototype = Object.create(Effect.prototype);
    p5.Distortion.prototype.process = function (src, amount, oversample) {
        src.connect(this.input);
        this.set(amount, oversample);
    };
    p5.Distortion.prototype.set = function (amount, oversample) {
        if (amount) {
            var curveAmount = p5.prototype.map(amount, 0, 1, 0, 2000);
            this.amount = curveAmount;
            this.waveShaperNode.curve = makeDistortionCurve(curveAmount);
        }
        if (oversample) {
            this.waveShaperNode.oversample = oversample;
        }
    };
    p5.Distortion.prototype.getAmount = function () {
        return this.amount;
    };
    p5.Distortion.prototype.getOversample = function () {
        return this.waveShaperNode.oversample;
    };
    p5.Distortion.prototype.dispose = function () {
        Effect.prototype.dispose.apply(this);
        if (this.waveShaperNode) {
            this.waveShaperNode.disconnect();
            this.waveShaperNode = null;
        }
    };
}(effect);
var src_app;
'use strict';
src_app = function () {
    var p5SOUND = master;
    return p5SOUND;
}(shims, audiocontext, master, helpers, errorHandler, panner, soundfile, amplitude, fft, signal, oscillator, envelope, pulse, noise, audioin, filter, eq, panner3d, listener3d, delay, reverb, metro, looper, soundloop, compressor, soundRecorder, peakdetect, gain, monosynth, polysynth, distortion, audioVoice, monosynth, polysynth);
}));